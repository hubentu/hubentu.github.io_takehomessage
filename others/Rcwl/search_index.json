[
["index.html", "Bioinformatics tools and pipelines using R and CWL Preface 0.1 R package installation 0.2 System requirements 0.3 Docker 0.4 Structure of the book 0.5 R session information", " Bioinformatics tools and pipelines using R and CWL Qiang Hu Qian Liu 2019-10-11 Preface This short book introduces the R packages, Rcwl and RcwlPipelines, to improve the way of building, managing and running Bioinformatics tools and pipelines. The Rcwl package is built on top of the Common Workflow Language (CWL), and provides a simple and user-friendly way to wrap command line tools into data analysis pipelines in R. The RcwlPipelines package is a collection of Bioinformatics tools and pipelines based on Rcwl. 0.1 R package installation The Rcwl and RcwlPipelines packages can be installed from Bioconductor or Github: BiocManager::install(c(&quot;Rcwl&quot;, &quot;RcwlPipelines&quot;)) # or the development version BiocManager::install(c(&quot;hubentu/Rcwl&quot;, &quot;hubentu/RcwlPipelines&quot;)) To load the packages into R session: library(Rcwl) library(RcwlPipelines) 0.2 System requirements In addition to the R packages, the following tools are required to be installed to run the examples in this book. python (&gt;= 2.7) cwltool (&gt;= 1.0.2018) nodejs The cwltool is the reference implementation of the Common Workflow Language, which is used to run the CWL scripts. The nodejs is required when the CWL scripts use JavaScript. You can find instructions to install these tools here: https://github.com/common-workflow-language/cwltool#install https://nodejs.org 0.3 Docker The Docker container simplifies software installation and management, especially for bioinformatics tools/pipelines requiring different runtime environments and library dependencies. A CWL runner can perform this work automatically by pulling the Docker containers and mounting the paths of input files. The Docker requirement is optional, as CWL scripts can also be run locally with all the dependencies pre-installed. 0.4 Structure of the book Introduction Components Build CWL workflows Run approaches Case study 0.5 R session information The R session information for compiling this mannual is shown below: sessionInfo() ## R version 3.6.1 (2019-07-05) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 7 (Core) ## ## Matrix products: default ## BLAS/LAPACK: /home/qhu/.linuxbrew/Cellar/openblas/0.3.7/lib/libopenblasp-r0.3.7.so ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] parallel stats4 stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] bookdown_0.14 RcwlPipelines_1.1.12 testthat_2.2.1 ## [4] BiocFileCache_1.8.0 dbplyr_1.4.2 Rcwl_1.1.13 ## [7] S4Vectors_0.22.1 BiocGenerics_0.30.0 yaml_2.2.0 ## [10] devtools_2.2.1 usethis_1.5.1 ## ## loaded via a namespace (and not attached): ## [1] fs_1.3.1 bit64_0.9-7 httr_1.4.1 ## [4] RColorBrewer_1.1-2 progress_1.2.2 rprojroot_1.3-2 ## [7] tools_3.6.1 backports_1.1.4 R6_2.4.0 ## [10] DBI_1.0.0 lazyeval_0.2.2 colorspace_1.4-1 ## [13] withr_2.1.2 tidyselect_0.2.5 gridExtra_2.3 ## [16] prettyunits_1.0.2 processx_3.4.1 curl_4.2 ## [19] bit_1.1-14 compiler_3.6.1 cli_1.1.0 ## [22] influenceR_0.1.0 desc_1.2.0 scales_1.0.0 ## [25] checkmate_1.9.4 readr_1.3.1 callr_3.3.2 ## [28] rappdirs_0.3.1 stringr_1.4.0 digest_0.6.21 ## [31] rmarkdown_1.16 R.utils_2.9.0 pkgconfig_2.0.3 ## [34] htmltools_0.3.6 sessioninfo_1.1.1 htmlwidgets_1.3 ## [37] rlang_0.4.0 rstudioapi_0.10 RSQLite_2.1.2 ## [40] shiny_1.3.2 visNetwork_2.0.8 jsonlite_1.6 ## [43] BiocParallel_1.18.1 dplyr_0.8.3 rgexf_0.15.3 ## [46] R.oo_1.22.0 magrittr_1.5 Rcpp_1.0.2 ## [49] munsell_0.5.0 viridis_0.5.1 lifecycle_0.1.0 ## [52] R.methodsS3_1.7.1 stringi_1.4.3 pkgbuild_1.0.5 ## [55] blob_1.2.0 grid_3.6.1 promises_1.0.1 ## [58] crayon_1.3.4 hms_0.5.1 batchtools_0.9.11 ## [61] knitr_1.25 zeallot_0.1.0 ps_1.3.0 ## [64] pillar_1.4.2 igraph_1.2.4.1 base64url_1.4 ## [67] codetools_0.2-16 pkgload_1.0.2 XML_3.98-1.20 ## [70] glue_1.3.1 evaluate_0.14 downloader_0.4 ## [73] data.table_1.12.2 remotes_2.1.0 vctrs_0.2.0 ## [76] httpuv_1.5.2 gtable_0.3.0 purrr_0.3.2 ## [79] tidyr_1.0.0 assertthat_0.2.1 ggplot2_3.2.1 ## [82] xfun_0.10 mime_0.7 xtable_1.8-4 ## [85] later_0.8.0 viridisLite_0.3.0 tibble_2.1.3 ## [88] memoise_1.1.0 Rook_1.1-1 DiagrammeR_1.0.1 ## [91] ellipsis_0.3.0 brew_1.0-6 "],
["intro.html", "Chapter 1 Introduction 1.1 Common Workflow Language 1.2 First example 1.3 Test run", " Chapter 1 Introduction 1.1 Common Workflow Language ‚ÄúThe Common Workflow Language (CWL) is a specification for describing analysis workflows and tools in a way that makes them portable and scalable across a variety of software and hardware environments, from workstations to cluster, cloud, and high performance computing (HPC) environments.‚Äù https://www.commonwl.org/ To wrap tool and workflow parameters in a standard format Capable of invoking tools from Docker containers Widely used‚Ä¶ 1.2 First example The main class and constructor function is cwlParam, which wraps a command line tool and its parameters in a cwlParam object. Let‚Äôs start with a simple example, echo hello world. First, we load the package and define the input parameter for ‚Äúecho‚Äù, a string without a prefix. Just an id option required here: input1 &lt;- InputParam(id = &quot;sth&quot;) Second, we create a cwlParam object with baseCommand for the command to execute and InputParamList for the input parameters. echo &lt;- cwlParam(baseCommand = &quot;echo&quot;, inputs = InputParamList(input1)) Now we have a command object to run. Let‚Äôs send a string ‚ÄúHello World!‚Äù to the object. Without defining the outputs, it will stream standard output to a temporary file by default. echo$sth &lt;- &quot;Hello World!&quot; echo ## class: cwlParam ## cwlClass: CommandLineTool ## cwlVersion: v1.0 ## baseCommand: echo ## inputs: ## sth (string): Hello World! ## outputs: ## output: ## type: stdout 1.3 Test run The function runCWL is used to run the CWL object by invoking the python tool cwltool. The return will be a list including the command executed, temporary output and logs. The output directory is the current folder by default, but it can be changed by setting outdir option. All standard out and standard error streams can also be printed by setting stderr = \"\". r1 &lt;- runCWL(echo, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r1 ## List of length 3 ## names(3): command output logs Here we can check the output to ensure the code did what we expected. r1$output ## [1] &quot;/tmp/RtmpgQiSSu/221c05daf0b429613fd6be335f6617718931e825&quot; readLines(r1$output) ## [1] &quot;Hello World!&quot; The executed command was returned in the result list. It shows the command that we have defined to execute. r1$command ## [1] &quot;\\033[1;30mINFO\\033[0m [job file33e1eacf49.cwl] /tmp/78s483pw$ echo \\\\&quot; ## [2] &quot; &#39;Hello World!&#39; &gt; /tmp/78s483pw/221c05daf0b429613fd6be335f6617718931e825&quot; The log shows the details of how the cwltool works with CWL scripts. r1$log ## [1] &quot;\\033[1;30mINFO\\033[0m /home/qhu/.linuxbrew/bin/cwltool 1.0.20190815141648&quot; ## [2] &quot;\\033[1;30mINFO\\033[0m Resolved &#39;/tmp/RtmpgQiSSu/file33e1eacf49.cwl&#39; to &#39;file:///tmp/RtmpgQiSSu/file33e1eacf49.cwl&#39;&quot; ## [3] &quot;\\033[1;30mINFO\\033[0m [job file33e1eacf49.cwl] /tmp/78s483pw$ echo \\\\&quot; ## [4] &quot; &#39;Hello World!&#39; &gt; /tmp/78s483pw/221c05daf0b429613fd6be335f6617718931e825&quot; ## [5] &quot;\\033[1;30mINFO\\033[0m [job file33e1eacf49.cwl] completed success&quot; ## [6] &quot;{&quot; ## [7] &quot; \\&quot;output\\&quot;: {&quot; ## [8] &quot; \\&quot;location\\&quot;: \\&quot;file:///tmp/RtmpgQiSSu/221c05daf0b429613fd6be335f6617718931e825\\&quot;,&quot; ## [9] &quot; \\&quot;basename\\&quot;: \\&quot;221c05daf0b429613fd6be335f6617718931e825\\&quot;,&quot; ## [10] &quot; \\&quot;class\\&quot;: \\&quot;File\\&quot;,&quot; ## [11] &quot; \\&quot;checksum\\&quot;: \\&quot;sha1$a0b65939670bc2c010f4d5d6a0b3e4e4590fb92b\\&quot;,&quot; ## [12] &quot; \\&quot;size\\&quot;: 13,&quot; ## [13] &quot; \\&quot;path\\&quot;: \\&quot;/tmp/RtmpgQiSSu/221c05daf0b429613fd6be335f6617718931e825\\&quot;&quot; ## [14] &quot; }&quot; ## [15] &quot;}&quot; ## [16] &quot;\\033[1;30mINFO\\033[0m Final process status is success&quot; The runCWL generated two scripts with the default tempfile prefix, the tool wrapper CWL file and the input YML file. The cwltool parses the two scripts and translates them into the command shown before. The output is not defined in the cwlParam object, so the command output was returned to stdout by default. "],
["components.html", "Chapter 2 Components 2.1 Input Parameters 2.2 Output Parameters", " Chapter 2 Components 2.1 Input Parameters 2.1.1 Essential Input parameters For the input parameters, we usually need to define three options, id, type, and prefix. The type can be string, int, long, float, double, and so on. More detail can be found at: https://www.commonwl.org/v1.0/CommandLineTool.html#CWLType. A InputParam constructor is used to define a list of input objects for the command tool, such as ‚Äúprefix‚Äù for the parameter flags and ‚Äúposition‚Äù for the paramter orders. More descriptions are available in the CWL specification https://www.commonwl.org/v1.0/CommandLineTool.html#CommandLineBinding. Here is an example from the CWL user guide(http://www.commonwl.org/user_guide/03-input/). We defined the echo with different type of input parameters by InputParam, and the stdout option can be used to caputre the standard output stream into a file: e1 &lt;- InputParam(id = &quot;flag&quot;, type = &quot;boolean&quot;, prefix = &quot;-f&quot;) e2 &lt;- InputParam(id = &quot;string&quot;, type = &quot;string&quot;, prefix = &quot;-s&quot;) e3 &lt;- InputParam(id = &quot;int&quot;, type = &quot;int&quot;, prefix = &quot;-i&quot;) e4 &lt;- InputParam(id = &quot;file&quot;, type = &quot;File&quot;, prefix = &quot;--file=&quot;, separate = FALSE) echoA &lt;- cwlParam(baseCommand = &quot;echo&quot;, inputs = InputParamList(e1, e2, e3, e4), stdout = &quot;output.txt&quot;) Then we give it a try by setting values for the inputs: echoA$flag &lt;- TRUE echoA$string &lt;- &quot;Hello&quot; echoA$int &lt;- 1 tmpfile &lt;- tempfile() write(&quot;World&quot;, tmpfile) echoA$file &lt;- tmpfile r2 &lt;- runCWL(echoA, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r2$command ## [1] &quot;\\033[1;30mINFO\\033[0m [job file33e119137d.cwl] /tmp/jy5_17oh$ echo \\\\&quot; ## [2] &quot; --file=/tmp/tmpfps825wz/stgda42f59e-bf3b-42da-a72b-3acfaad10160/file33e71c79690 \\\\&quot; ## [3] &quot; -f \\\\&quot; ## [4] &quot; -i \\\\&quot; ## [5] &quot; 1 \\\\&quot; ## [6] &quot; -s \\\\&quot; ## [7] &quot; Hello &gt; /tmp/jy5_17oh/output.txt&quot; 2.1.2 Array Inputs Taking a similar example to the CWL user guide described above, we can define three different type of array as inputs: a1 &lt;- InputParam(id = &quot;A&quot;, type = &quot;string[]&quot;, prefix = &quot;-A&quot;) a2 &lt;- InputParam(id = &quot;B&quot;, type = InputArrayParam(items = &quot;string&quot;, prefix=&quot;-B=&quot;, separate = FALSE)) a3 &lt;- InputParam(id = &quot;C&quot;, type = &quot;string[]&quot;, prefix = &quot;-C=&quot;, itemSeparator = &quot;,&quot;, separate = FALSE) echoB &lt;- cwlParam(baseCommand = &quot;echo&quot;, inputs = InputParamList(a1, a2, a3)) We then set values for the three inputs: echoB$A &lt;- letters[1:3] echoB$B &lt;- letters[4:6] echoB$C &lt;- letters[7:9] echoB ## class: cwlParam ## cwlClass: CommandLineTool ## cwlVersion: v1.0 ## baseCommand: echo ## inputs: ## A (string[]): -A a b c ## B: ## type: array ## prefix: -B= d e f ## C (string[]): -C= g h i ## outputs: ## output: ## type: stdout Now we can check whether the command behaves as we expected: r3 &lt;- runCWL(echoB, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r3$command ## [1] &quot;\\033[1;30mINFO\\033[0m [job file33e70b7881b.cwl] /tmp/y5c0n6ey$ echo \\\\&quot; ## [2] &quot; -A \\\\&quot; ## [3] &quot; a \\\\&quot; ## [4] &quot; b \\\\&quot; ## [5] &quot; c \\\\&quot; ## [6] &quot; -B=d \\\\&quot; ## [7] &quot; -B=e \\\\&quot; ## [8] &quot; -B=f \\\\&quot; ## [9] &quot; -C=g,h,i &gt; /tmp/y5c0n6ey/a42ab676393b853fed6cc21e1e301b73e8d537b9&quot; 2.2 Output Parameters 2.2.1 Capturing Output The outputs, similar to the inputs, is a list of output parameters. Three options, id, type and glob, can be defined. The glob option is used to define a pattern to find files relative to the output directory. Here is an example to unzip a compressed gz file. First, we generate a compressed R script file: zzfil &lt;- file.path(tempdir(), &quot;sample.R.gz&quot;) zz &lt;- gzfile(zzfil, &quot;w&quot;) cat(&quot;sample(1:10, 5)&quot;, file = zz, sep = &quot;\\n&quot;) close(zz) We then define a cwlParam object to use ‚Äúgzip‚Äù to uncompress an input file: ofile &lt;- &quot;sample.R&quot; z1 &lt;- InputParam(id = &quot;uncomp&quot;, type = &quot;boolean&quot;, prefix = &quot;-d&quot;) z2 &lt;- InputParam(id = &quot;out&quot;, type = &quot;boolean&quot;, prefix = &quot;-c&quot;) z3 &lt;- InputParam(id = &quot;zfile&quot;, type = &quot;File&quot;) o1 &lt;- OutputParam(id = &quot;rfile&quot;, type = &quot;File&quot;, glob = ofile) gz &lt;- cwlParam(baseCommand = &quot;gzip&quot;, inputs = InputParamList(z1, z2, z3), outputs = OutputParamList(o1), stdout = ofile) Now the gz object can be used to uncompress the previously generated compressed file: gz$uncomp &lt;- TRUE gz$out &lt;- TRUE gz$zfile &lt;- zzfil r4 &lt;- runCWL(gz, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r4$output ## [1] &quot;/tmp/RtmpgQiSSu/sample.R&quot; Or we can use arguments to set some default parameters: z1 &lt;- InputParam(id = &quot;zfile&quot;, type = &quot;File&quot;) o1 &lt;- OutputParam(id = &quot;rfile&quot;, type = &quot;File&quot;, glob = ofile) Gz &lt;- cwlParam(baseCommand = &quot;gzip&quot;, arguments = list(&quot;-d&quot;, &quot;-c&quot;), inputs = InputParamList(z1), outputs = OutputParamList(o1), stdout = ofile) Gz ## class: cwlParam ## cwlClass: CommandLineTool ## cwlVersion: v1.0 ## baseCommand: gzip ## arguments: -d -c ## inputs: ## zfile (File): ## outputs: ## rfile: ## type: File ## outputBinding: ## glob: sample.R ## stdout: sample.R Gz$zfile &lt;- zzfil r4a &lt;- runCWL(Gz, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success To make it for general usage, we can define a pattern with javascript to glob the output, which requires node to be installed in your system PATH: pfile &lt;- &quot;$(inputs.zfile.path.split(&#39;/&#39;).slice(-1)[0].split(&#39;.&#39;).slice(0,-1).join(&#39;.&#39;))&quot; Or we can directly use the CWL built in file property, nameroot: pfile &lt;- &quot;$(inputs.zfile.nameroot)&quot; o2 &lt;- OutputParam(id = &quot;rfile&quot;, type = &quot;File&quot;, glob = pfile) req1 &lt;- list(class = &quot;InlineJavascriptRequirement&quot;) GZ &lt;- cwlParam(baseCommand = c(&quot;gzip&quot;, &quot;-d&quot;, &quot;-c&quot;), requirements = list(), ## assign list(req1) if node installed. inputs = InputParamList(z1), outputs = OutputParamList(o2), stdout = pfile) GZ$zfile &lt;- zzfil r4b &lt;- runCWL(GZ, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success 2.2.2 Array Outputs We can also capture multiple output files with the glob pattern: a &lt;- InputParam(id = &quot;a&quot;, type = InputArrayParam(items = &quot;string&quot;)) b &lt;- OutputParam(id = &quot;b&quot;, type = OutputArrayParam(items = &quot;File&quot;), glob = &quot;*.txt&quot;) touch &lt;- cwlParam(baseCommand = &quot;touch&quot;, inputs = InputParamList(a), outputs = OutputParamList(b)) touch$a &lt;- c(&quot;a.txt&quot;, &quot;b.gz&quot;, &quot;c.txt&quot;) r5 &lt;- runCWL(touch, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r5$output ## [1] &quot;/tmp/RtmpgQiSSu/a.txt&quot; &quot;/tmp/RtmpgQiSSu/c.txt&quot; 2.2.3 Standard output Usually, the stdout option is a string or an expression of output file name from the command tool. The command‚Äôs standard output stream will be captured into a file written to the designated output directory. When the stdout field is defined, an output parameter with the type of ‚Äústdout‚Äù should be also assigned with no ‚ÄúoutputBinding‚Äù set. An example for command tool ‚Äúcat‚Äù is defined with stdout field in the output, with the name passed from the input parameter ‚Äúp2‚Äù: ## define Cat p1 &lt;- InputParam(id = &quot;infiles&quot;, type = &quot;File[]&quot;) p2 &lt;- InputParam(id = &quot;outfile&quot;, type = &quot;string&quot;, default = &quot;catout.txt&quot;, position = -1) Cat &lt;- cwlParam(baseCommand = &quot;cat&quot;, inputs = InputParamList(p1, p2), stdout = &quot;$(inputs.outfile)&quot;) ## assign inputs afile &lt;- file.path(tempdir(), &quot;a.txt&quot;) bfile &lt;- file.path(tempdir(), &quot;b.txt&quot;) write(&quot;a&quot;, afile) write(&quot;b&quot;, bfile) Cat$infiles &lt;- list(afile, bfile) ## run r6 &lt;- runCWL(Cat, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r6$command ## [1] &quot;\\033[1;30mINFO\\033[0m [job file33e6dd5ea8c.cwl] /tmp/cw55z3so$ cat \\\\&quot; ## [2] &quot; /tmp/tmpzpsel0g3/stgb15a5507-711c-4333-b2eb-631c6dc3f57c/a.txt \\\\&quot; ## [3] &quot; /tmp/tmpzpsel0g3/stg63b35434-34ca-43fe-96a7-98738e8efc65/b.txt &gt; /tmp/cw55z3so/catout.txt&quot; In this example, we used the parameter ‚Äúp2‚Äù to pass the name to the standard output. In the InputParam of ‚Äúp2‚Äù, the position is assigned to a negative value (-1), which means the parameters will not be used in the command and only uses for passing variable. To write the ‚ÄúCat‚Äù tool to a CWL file, the ‚ÄúinputBinding‚Äù field will be skipped for this parameter. "],
["writing-pipeline.html", "Chapter 3 Writing Pipeline 3.1 Scattering pipeline 3.2 Pipeline plot", " Chapter 3 Writing Pipeline We can connect multiple tools into a pipeline. Here is an example to uncompress an R script and execute it with Rscript. We first define a simple Rscript tool without using docker: d1 &lt;- InputParam(id = &quot;rfile&quot;, type = &quot;File&quot;) Rs &lt;- cwlParam(baseCommand = &quot;/usr/bin/Rscript&quot;, inputs = InputParamList(d1)) Rs ## class: cwlParam ## cwlClass: CommandLineTool ## cwlVersion: v1.0 ## baseCommand: /usr/bin/Rscript ## inputs: ## rfile (File): ## outputs: ## output: ## type: stdout Here is the test run: Rs$rfile &lt;- r4$output tres &lt;- runCWL(Rs, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success readLines(tres$output) ## [1] &quot;[1] 3 5 1 6 2&quot; The pipeline includes two steps, decompressed by GZ and compiled by Rs. The input file is a compressed file and the output file would be the output Rout from Rs. First we need to define the direct inputs and outputs from GZ and Rs, respectively: i1 &lt;- InputParam(id = &quot;cwl_zfile&quot;, type = &quot;File&quot;) o1 &lt;- OutputParam(id = &quot;cwl_cout&quot;, type = &quot;File&quot;, outputSource = &quot;Compile/output&quot;) For the input ‚Äúcwl_zifle‚Äù, it refers to the GZ input zfile. The output ‚Äúcwl_cout‚Äù will be the outcome of Rs output Rout. The cwlStepParam is used to define inputs and outputs, and the Step function is used to define the two steps. The run option refers to the corresponding cwlParam object and the In option should be linked to the input parameters defined by cwlStepParam. At the end, we use + to connect all steps: cwl &lt;- cwlStepParam(inputs = InputParamList(i1), outputs = OutputParamList(o1)) s1 &lt;- Step(id = &quot;Uncomp&quot;, run = GZ, In = list(zfile = &quot;cwl_zfile&quot;)) s2 &lt;- Step(id = &quot;Compile&quot;, run = Rs, In = list(rfile = &quot;Uncomp/rfile&quot;)) cwl &lt;- cwl + s1 + s2 cwl ## class: cwlStepParam ## cwlClass: Workflow ## cwlVersion: v1.0 ## inputs: ## cwl_zfile (File): ## outputs: ## cwl_cout: ## type: File ## outputSource: Compile/output ## steps: ## Uncomp: ## run: Uncomp.cwl ## zfile: cwl_zfile ## out: rfile ## Compile: ## run: Compile.cwl ## rfile: Uncomp/rfile ## out: output Let‚Äôs run the pipeline: cwl$cwl_zfile &lt;- zzfil r7 &lt;- runCWL(cwl, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success readLines(r7$output) ## [1] &quot;[1] 3 1 6 7 4&quot; 3.1 Scattering pipeline The scattering feature can specify the associated workflow steps or subworkflows to execute separately over a list of input elements. To use this feature, ScatterFeatureRequirement must be specified in the workflow requirement. Different scatter methods can be used in the associated steps to decompose the input into a discrete set of jobs. More details can be found at: https://www.commonwl.org/v1.0/Workflow.html#WorkflowStep. Here is an example to execute multiple R scripts. First, we need to set the input and output types to be an array of ‚ÄúFile‚Äù, and add the requirments. In the ‚ÄúCompile‚Äù step, the scattering input is required to be set with the scatter option: i2 &lt;- InputParam(id = &quot;cwl_rfiles&quot;, type = &quot;File[]&quot;) o2 &lt;- OutputParam(id = &quot;cwl_couts&quot;, type = &quot;File[]&quot;, outputSource = &quot;Compile/output&quot;) req1 &lt;- list(class = &quot;ScatterFeatureRequirement&quot;) cwl2 &lt;- cwlStepParam(requirements = list(req1), inputs = InputParamList(i2), outputs = OutputParamList(o2)) s1 &lt;- Step(id = &quot;Compile&quot;, run = Rs, In = list(rfile = &quot;cwl_rfiles&quot;), scatter = &quot;rfile&quot;) cwl2 &lt;- cwl2 + s1 cwl2 ## class: cwlStepParam ## cwlClass: Workflow ## cwlVersion: v1.0 ## requirements: ## - class: ScatterFeatureRequirement ## inputs: ## cwl_rfiles (File[]): ## outputs: ## cwl_couts: ## type: File[] ## outputSource: Compile/output ## steps: ## Compile: ## run: Compile.cwl ## rfile: cwl_rfiles ## out: output ## scatter: rfile Now multiple R scripts can be assigned to the workflow inputs and executed: cwl2$cwl_rfiles &lt;- c(r4b$output, r4b$output) r8 &lt;- runCWL(cwl2, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r8$output ## [1] &quot;/tmp/RtmpgQiSSu/5b8b39b99438145148ef01b46591c55f3a0be9ed&quot; ## [2] &quot;/tmp/RtmpgQiSSu/5b8b39b99438145148ef01b46591c55f3a0be9ed&quot; 3.2 Pipeline plot The function plotCWL can be used to visualize the relationship of inputs, outputs and the components for a tool or pipeline: plotCWL(cwl) "],
["run-approaches.html", "Chapter 4 Run approaches 4.1 Running Tools in Docker 4.2 Running Tools in Cluster server 4.3 Web Application", " Chapter 4 Run approaches 4.1 Running Tools in Docker The CWL can work with docker to simplify your software management and communicate files between host and container. The docker container can be defined by the hints or requirements option: d1 &lt;- InputParam(id = &quot;rfile&quot;, type = &quot;File&quot;) req1 &lt;- list(class = &quot;DockerRequirement&quot;, dockerPull = &quot;r-base&quot;) doc &lt;- cwlParam(baseCommand = &quot;Rscript&quot;, inputs = InputParamList(d1), stdout = &quot;output.txt&quot;, hints = list(req1)) doc$rfile &lt;- r4$output r6 &lt;- runCWL(doc) The tools defined with docker requirements can also be run locally by disabling the docker option. In case your Rscript depends some local libraries to run, an option from cwltools, ‚Äú‚Äìpreserve-entire-environment‚Äù, can be used to pass all environment variables. r6a &lt;- runCWL(doc, docker = FALSE, outdir = tempdir(), Args = &quot;--preserve-entire-environment&quot;) ## [1;30mINFO[0m Final process status is success 4.2 Running Tools in Cluster server The CWL can also work in high performance clusters with batch-queuing system, such as SGE, PBS, SLURM and so on, using the Bioconductor package BiocParallel. Here is an example to submit jobs with ‚ÄúMultiicore‚Äù and ‚ÄúSGE‚Äù, seperately: library(BiocParallel) sth.list &lt;- as.list(LETTERS) names(sth.list) &lt;- LETTERS ## submit with mutlicore result1 &lt;- runCWLBatch(cwl = echo, outdir = tempdir(), inputList = list(sth = sth.list), BPPARAM = MulticoreParam(26)) ## submit with SGE result2 &lt;- runCWLBatch(cwl = echo, outdir = tempdir(), inputList = list(sth = sth.list), BPPARAM = BatchtoolsParam(workers = 26, cluster = &quot;sge&quot;, resources = list(queue = &quot;all.q&quot;))) A more detailed example can be found (https://hubentu.github.io/others/Rcwl_RNASeq.html). 4.3 Web Application 4.3.1 cwlParam example Here we build a tool with different types of input parameters: e1 &lt;- InputParam(id = &quot;flag&quot;, type = &quot;boolean&quot;, prefix = &quot;-f&quot;, doc = &quot;boolean flag&quot;) e2 &lt;- InputParam(id = &quot;string&quot;, type = &quot;string&quot;, prefix = &quot;-s&quot;) e3 &lt;- InputParam(id = &quot;option&quot;, type = &quot;string&quot;, prefix = &quot;-o&quot;) e4 &lt;- InputParam(id = &quot;int&quot;, type = &quot;int&quot;, prefix = &quot;-i&quot;, default = 123) e5 &lt;- InputParam(id = &quot;file&quot;, type = &quot;File&quot;, prefix = &quot;--file=&quot;, separate = FALSE) e6 &lt;- InputParam(id = &quot;array&quot;, type = &quot;string[]&quot;, prefix = &quot;-A&quot;, doc = &quot;separated by comma&quot;) mulEcho &lt;- cwlParam(baseCommand = &quot;echo&quot;, id = &quot;mulEcho&quot;, label = &quot;Test parameter types&quot;, inputs = InputParamList(e1, e2, e3, e4, e5, e6), stdout = &quot;output.txt&quot;) mulEcho ## class: cwlParam ## cwlClass: CommandLineTool ## cwlVersion: v1.0 ## baseCommand: echo ## inputs: ## flag (boolean): -f ## string (string): -s ## option (string): -o ## int (int): -i 123 ## file (File): --file= ## array (string[]): -A ## outputs: ## output: ## type: stdout ## stdout: output.txt 4.3.2 cwlParam to Shiny App Some input parameters can be predefined in a list, which will be converted to selected options in the webapp. An upload parameter can be used to generate an upload interface for the file type option. If FALSE is set for upload, the upload field will be text input (file path) instead of file input. inputList &lt;- list(option = c(&quot;option1&quot;, &quot;option2&quot;)) app &lt;- cwlShiny(mulEcho, inputList, upload = TRUE) runApp(app) shinyApp "],
["application.html", "Chapter 5 Application 5.1 RcwlPipelines tools 5.2 RcwlPipelines summary 5.3 DNASeq alignment pipeline 5.4 RNASeq pipeline 5.5 MC3 somatic variant calling pipeline 5.6 GATK4 germline variant calling pipeline", " Chapter 5 Application 5.1 RcwlPipelines tools 5.1.1 Rcwl scripts The R scripts to build the CWL tools and pipelines based on the Rcwl package are stored in the ‚Äúsrc‚Äù folder with ‚Äútl_‚Äù and ‚Äúpl_‚Äù prefix respectively. The function cwlTools can be used to collect the available scripts. The cachePath can be your existing cache directory or a new folder. tools &lt;- cwlTools(cachePath = tempdir()) tools ## class: BiocFileCache ## bfccache: /tmp/RtmpgQiSSu ## bfccount: 77 ## For more information see: bfcinfo() or bfcquery() The full paths can be pulled from the ‚Äúfpath‚Äù column. The scripts can be viewed to demonstrate how the tools and pipelines were built. library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following object is masked from &#39;package:testthat&#39;: ## ## matches ## The following objects are masked from &#39;package:dbplyr&#39;: ## ## ident, sql ## The following objects are masked from &#39;package:S4Vectors&#39;: ## ## first, intersect, rename, setdiff, setequal, union ## The following objects are masked from &#39;package:BiocGenerics&#39;: ## ## combine, intersect, setdiff, union ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(conflicted) ## always use select from dplyr conflict_prefer(&quot;select&quot;, &quot;dplyr&quot;, quiet = TRUE) conflict_prefer(&quot;filter&quot;, &quot;dplyr&quot;, quiet = TRUE) bfcinfo(tools) %&gt;% select(rname, fpath) ## # A tibble: 77 x 2 ## rname fpath ## &lt;chr&gt; &lt;chr&gt; ## 1 ApplyBQSR /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## 2 BaseRecalibrator /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## 3 bcfview /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## 4 bgzip /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## 5 blastn /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## 6 bowtie2_build /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## 7 bowtie2 /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## 8 bwa_index /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## 9 bwa /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## 10 CalculateContamin‚Ä¶ /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## # ‚Ä¶ with 67 more rows The commands and docker containers from the wrapped tools are included in the metadata. tls &lt;- bfcinfo(tools) %&gt;% filter(Type == &quot;tool&quot;) %&gt;% select(rname, Command, Container) knitr::kable(tls) rname Command Container ApplyBQSR gatk ApplyBQSR broadinstitute/gatk:latest BaseRecalibrator gatk BaseRecalibrator broadinstitute/gatk:latest bcfview bcftools view biocontainers/bcftools:v1.5_cv3 bgzip bgzip -c biocontainers/tabix:v1.3.2-2-deb_cv1 blastn blastn biocontainers/blast:v2.2.31_cv2 bowtie2_build bowtie2-build biocontainers/bowtie2:v2.2.9_cv2 bowtie2 bowtie2 biocontainers/bowtie2:v2.2.9_cv2 bwa_index bwa index biocontainers/bwa:v0.7.17-3-deb_cv1 bwa bwa mem biocontainers/bwa:v0.7.17-3-deb_cv1 CalculateContamination gatk CalculateContamination broadinstitute/gatk:latest ColSeqArtifact gatk CollectSequencingArtifactMetrics broadinstitute/gatk:latest cutadapt cutadapt kfdrc/cutadapt fastqc fastqc hubentu/rcwl-rnaseq featureCounts featureCounts hubentu/rcwl-rnaseq FilterMutectCalls gatk FilterMutectCalls broadinstitute/gatk:latest FilterOBias gatk FilterByOrientationBias broadinstitute/gatk:latest Funcotator gatk Funcotator broadinstitute/gatk:latest geneBody_coverage geneBody_coverage.py hubentu/rcwl-rnaseq genePredToBed genePredToBed hubentu/rcwl-rnaseq GenomicsDB gatk GenomicsDBImport broadinstitute/gatk:latest GetPileupSummaries gatk GetPileupSummaries broadinstitute/gatk:latest gtfToGenePred gtfToGenePred hubentu/rcwl-rnaseq hisat2_align hisat2 biocontainers/hisat2:v2.0.5-1-deb_cv1 hisat2_build hisat2-build biocontainers/hisat2:v2.0.5-1-deb_cv1 htseq htseq-count genomicpariscentre/htseq lancet /lancet-1.0.7/lancet kfdrc/lancet:1.0.7 LoFreq lofreq somatic andreaswilm/lofreq:v2.1.2 makeblastdb makeblastdb biocontainers/blast:v2.2.31_cv2 manta configManta.py cmopipeline/strelka2_manta markdup java -jar /usr/picard/picard.jar MarkDuplicates broadinstitute/picard mergeBam java -jar /usr/picard/picard.jar MergeSamFiles broadinstitute/picard multiqc multiqc hubentu/rcwl-rnaseq MuSE MuSEv1.0rc_submission_c039ffa call marghoob/muse:1.0rc_c Mutect2 gatk Mutect2 broadinstitute/gatk:latest mvOut R function NA neusomatic_call python /opt/neusomatic/neusomatic/python/call.py msahraeian/neusomatic neusomatic_postprocess python /opt/neusomatic/neusomatic/python/postprocess.py msahraeian/neusomatic neusomatic_preprocess python /opt/neusomatic/neusomatic/python/preprocess.py msahraeian/neusomatic polysolver bash /home/polysolver/scripts/shell_call_hla_type sachet/polysolver:v4 PoN gatk CreateSomaticPanelOfNormals broadinstitute/gatk:latest read_distribution read_distribution.py hubentu/rcwl-rnaseq runWDL java NA salmon_index salmon index combinelab/salmon salmon_quant salmon quant combinelab/salmon sam2bam samtools view biocontainers/samtools:v1.7.0_cv3 samtools_flagstat samtools flagstat biocontainers/samtools:v1.7.0_cv3 samtools_index samtools index biocontainers/samtools:v1.7.0_cv3 samtools_mpileup samtools mpileup biocontainers/samtools:v1.7.0_cv3 samtools_stats samtools stats biocontainers/samtools:v1.7.0_cv3 SomaticSniper /opt/somatic-sniper/build/bin/bam-somaticsniper lethalfang/somaticsniper:1.0.5.0-2 sortBam samtools sort biocontainers/samtools:v1.7.0_cv3 STAR STAR hubentu/rcwl-rnaseq starFusion /usr/local/src/STAR-Fusion/STAR-Fusion trinityctat/ctatfusion strelka configureStrelkaSomaticWorkflow.py cmopipeline/strelka2_manta tabix_index tabix biocontainers/tabix:v1.3.2-2-deb_cv1 VarDict /opt/VarDict-1.5.1/bin/VarDict lethalfang/vardictjava:1.5.1 VarScan2_processSomatic java -jar /opt/varscan/VarScan.jar processSomatic mgibio/varscan-cwl:v2.4.2-samtools1.3.1 VarScan2_somatic java -jar /opt/varscan/VarScan.jar somatic mgibio/varscan-cwl:v2.4.2-samtools1.3.1 VarScan2_somaticFilter java -jar /opt/varscan/VarScan.jar somaticFilter mgibio/varscan-cwl:v2.4.2-samtools1.3.1 VarScan2 serge2016/varscan:v0.1.1 5.1.2 Build a pipeline We can develop a pipline by utilizing the available tools. For example, a simple alignment pipelines with mapping and marking duplicates can be built from the tools. First, we check whether the required tools (bwa, samtools and picard markduplicates) are available. bfcquery(tools, &quot;bwa|sam2bam|sortBam|samtools_index|markdup&quot;) %&gt;% filter(Type == &quot;tool&quot;) %&gt;% select(rname, Command, Container) ## # A tibble: 6 x 3 ## rname Command Container ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 bwa_index bwa index biocontainers/bwa:v0.7.17‚Ä¶ ## 2 bwa bwa mem biocontainers/bwa:v0.7.17‚Ä¶ ## 3 markdup java -jar /usr/picard/picard.jar ‚Ä¶ broadinstitute/picard ## 4 sam2bam samtools view biocontainers/samtools:v1‚Ä¶ ## 5 samtools_i‚Ä¶ samtools index biocontainers/samtools:v1‚Ä¶ ## 6 sortBam samtools sort biocontainers/samtools:v1‚Ä¶ Next, we define the input parameters: p1 &lt;- InputParam(id = &quot;threads&quot;, type = &quot;int&quot;) p2 &lt;- InputParam(id = &quot;RG&quot;, type = &quot;string&quot;) p3 &lt;- InputParam(id = &quot;Ref&quot;, type = &quot;string&quot;) p4 &lt;- InputParam(id = &quot;FQ1&quot;, type = &quot;File&quot;) p5 &lt;- InputParam(id = &quot;FQ2&quot;, type = &quot;File?&quot;) Then we define the pipeline steps, from raw fastqs to duplicates marked alignments: ## bwa s1 &lt;- Step(id = &quot;bwa&quot;, run = bwa, In = list(threads = &quot;threads&quot;, RG = &quot;RG&quot;, Ref = &quot;Ref&quot;, FQ1 = &quot;FQ1&quot;, FQ2 = &quot;FQ2&quot;)) ## sam to bam s2 &lt;- Step(id = &quot;sam2bam&quot;, run = sam2bam, In = list(sam = &quot;bwa/sam&quot;)) ## sort bam s3 &lt;- Step(id = &quot;sortBam&quot;, run = sortBam, In = list(bam = &quot;sam2bam/bam&quot;)) ## mark duplicates s4 &lt;- Step(id = &quot;markdup&quot;, run = markdup, In = list(ibam = &quot;sortBam/sbam&quot;, obam = list( valueFrom=&quot;$(inputs.ibam.nameroot).mdup.bam&quot;), matrix = list( valueFrom=&quot;$(inputs.ibam.nameroot).markdup.txt&quot;))) ## index bam s5 &lt;- Step(id = &quot;idxBam&quot;, run = samtools_index, In = list(bam = &quot;markdup/mBam&quot;)) Last, we define the outputs and connect the steps to a new pipeline: req1 &lt;- list(class = &quot;StepInputExpressionRequirement&quot;) req2 &lt;- list(class = &quot;InlineJavascriptRequirement&quot;) ## outputs o1 &lt;- OutputParam(id = &quot;Bam&quot;, type = &quot;File&quot;, outputSource = &quot;markdup/mBam&quot;) o2 &lt;- OutputParam(id = &quot;Idx&quot;, type = &quot;File&quot;, outputSource = &quot;idxBam/idx&quot;) ## stepParam Align &lt;- cwlStepParam(requirements = list(req1, req2), inputs = InputParamList(p1, p2, p3, p4, p5), outputs = OutputParamList(o1, o2)) ## build pipeline Align &lt;- Align + s1 + s2 + s3 + s4 + s5 The pipeline is ready for use. We can plot the pipeline with plotCWL from the Rcwl package. plotCWL(Align) 5.2 RcwlPipelines summary So far we have built 4 major pipelines in this package. Here is a brief introduction to these 4 pipelines. More pipelines and tools are expected to be included in the future. 5.3 DNASeq alignment pipeline The pipeline can be used to preprocess DNA sequences in fastq format. It can take paired fastqs and read groups from multiple batches as input. inputs(bwaMMRecal) ## inputs: ## outBam (string): ## RG (string[]): ## threads (int): ## Ref (File): ## FQ1s (File[]): ## FQ2s (File[]): ## knowSites: ## type: array ## prefix: The pipeline includes two steps and several jobs will be run in each step. bwaAlign: bwa alignment by read groups: runs(runs(bwaMMRecal)[[1]]) ## List of length 4 ## names(4): bwa sam2bam sortBam idxBam bwa: To align fastqs and read groups to reference genome with bwa. sam2bam: To convert the alignments in ‚Äúsam‚Äù format to ‚Äúbam‚Äù format with samtools. sortBam: To sort the ‚Äúbam‚Äù file by coordinates with samtools. idxBam: To index ‚Äúbam‚Äù file with samtools. mergeBamDup: To merge by samples and mark duplicates: runs(runs(bwaMMRecal)[[2]]) ## List of length 4 ## names(4): mergeBam markdup samtools_index samtools_flagstat mergeBam: To merge bam files from multiple batches with picard. markdup: To mark duplicates with picard. samtools_index: To index bam file with samtools. samtools_flagstat: To summarize flags in bam with samtools. BaseRecal: To apply TCGA BaseRecalibrator and ApplyBQSR. runs(runs(bwaMMRecal)[[3]]) ## List of length 5 ## names(5): BaseRecalibrator ApplyBQSR samtools_index samtools_flagstat samtools_stats BaseRecalibrator: To Generates recalibration table for Base Quality Score Recalibration with gatk BaseRecalibrator. ApplyBQSR: To Apply base quality score recalibration with gatk ApplyBQSR. samtools_index: To index bam file with samtools. samtools_flagstat: To summarize flags in bam with samtools. samtools_stats: To collects statistics from BAM file with samtools. The final bam files with duplicates marked and base quality recalibration, bam index, duplicates matrix, and statistics summaries will be in the output folder. outputs(bwaMMRecal) ## outputs: ## BAM: ## type: File ## outputSource: BaseRecal/rcBam ## matrix: ## type: File ## outputSource: mergeBamDup/matrix ## flagstat: ## type: File ## outputSource: BaseRecal/flagstat ## stats: ## type: File ## outputSource: BaseRecal/stats Here is the short summary and steps plot: short(bwaMMRecal) ## inputs: ## - outBam ## - RG ## - threads ## - Ref ## - FQ1s ## - FQ2s ## - knowSites ## outputs: ## - BAM ## - matrix ## - flagstat ## - stats ## steps: ## - bwaAlign ## - mergeBamDup ## - BaseRecal plotCWL(bwaMMRecal) 5.3.1 Prepare data Here is a simple example of two samples. The ‚Äúsample1‚Äù have two lanes of sequences and the ‚Äúsample2‚Äù has only one pair of reads. The lists of reads1 fq1, reads2 fq2, read groups and output BAM names are defined in the inputList. The reference genome and number of threads to run the job are defined in the shared options, paramList: fq1 &lt;- list(sample1 = list(&quot;apps/DNASeq/data/fq1_1.fq&quot;, &quot;apps/DNASeq/data/fq2_1.fq&quot;), sample2 = list(&quot;apps/DNASeq/data/fq1_1.fq&quot;)) fq2 &lt;- list(sample1 = list(&quot;apps/DNASeq/data/fq1_2.fq&quot;, &quot;apps/DNASeq/data/fq2_2.fq&quot;), sample2 = list(&quot;apps/DNASeq/data/fq1_2.fq&quot;)) rgs &lt;- list(sample1 = list(&quot;@RG\\\\tID:sample1.1\\\\tPL:Illumina\\\\tSM:sample1&quot;, &quot;@RG\\\\tID:sample1.2\\\\tPL:Illumina\\\\tSM:sample1&quot;), sample2 = list(&quot;@RG\\\\tID:sample2.1\\\\tPL:Illumina\\\\tSM:sample2&quot;)) samples &lt;- list(sample1 = &quot;sample1.bam&quot;, sample2 = &quot;sample2.bam&quot;) inputList &lt;- list(outBam = samples, RG = rgs, FQ1s = fq1, FQ2s = fq2) paramList &lt;- list(threads = 2, Ref = &quot;apps/data/hs37d5.fa&quot;, knowSites = list(&quot;apps/data/dbsnp_138.b37.vcf&quot;, &quot;apps/data/Mills_and_1000G_gold_standard.indels.b37.vcf&quot;)) 5.3.2 Run in cluster res &lt;- runCWLBatch(bwaMMRecal, outdir = &quot;apps/DNASeq/output/BAM&quot;, inputList = inputList, paramList = paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;/rpcc/bioinformatics/sge_centos7.tmpl&quot;, resources = list(jobname=&quot;bwa&quot;, threads = 2, queue = &quot;centos7.q&quot;), log=TRUE, logdir=&quot;.&quot;, progressbar = T), docker = FALSE, stderr = &quot;&quot;) List outputs: dir(&quot;apps/DNASeq/output/BAM/sample2&quot;) ## [1] &quot;sample2.bam&quot; &quot;sample2.bam.bai&quot; &quot;sample2.flagstat.txt&quot; ## [4] &quot;sample2.markdup.txt&quot; &quot;sample2.stats.txt&quot; 5.4 RNASeq pipeline The pipeline was built with reads quality summary, STAR alignment, quantification by featureCounts and RSeQC quality control. Here are the inputs: inputs(rnaseq_Sf) ## inputs: ## in_seqfiles (File[]): ## in_prefix (string): ## in_genomeDir (Directory): ## in_GTFfile (File): ## in_runThreadN (int): 1 The pipeline includes 6 steps: fastqc: To run quality summary for raw fastqs with fastqc. STAR: To align fastqs with STAR. samtools_index: To index aligned bam file. samtools_flagstat: To summarize alignment flags. featureCounts: To quantify gene abundances. RSeQC: Several steps included. gtfToGenePred: To convert GTF annotation to ‚ÄúgenePred‚Äù format. genePredToBed: To convert ‚ÄúgenePred‚Äù annotation to ‚Äúbed‚Äù format. r_distribution: To summarize reads distribution over genome features. gCoverage: To summarize read coverage over gene body. The outputs and logs from alignment, quantification and QC steps are collected together into the output folder. A final QC report could be generated by multiqc, which is also available in the data package. Here are the short summary and steps plot: short(rnaseq_Sf) ## inputs: ## - in_seqfiles ## - in_prefix ## - in_genomeDir ## - in_GTFfile ## - in_runThreadN ## outputs: ## - out_fastqc ## - out_BAM ## - out_Log ## - out_Count ## - out_stat ## - out_count ## - out_distribution ## - out_gCovP ## - out_gCovT ## steps: ## - fastqc ## - STAR ## - sortBam ## - samtools_index ## - samtools_flagstat ## - featureCounts ## - gtfToGenePred ## - genePredToBed ## - r_distribution ## - gCoverage plotCWL(rnaseq_Sf) 5.4.1 Prepare data An RNASeq test data set can be downloaded from genomedata, which includes paired-end fastqs for 6 samples. download.file(&quot;http://genomedata.org/rnaseq-tutorial/HBR_UHR_ERCC_ds_5pc.tar&quot;, &quot;apps/RNASeq/data/HBR_UHR_ERCC_ds_5pc.tar) untar(&quot;apps/RNASeq/data/HBR_UHR_ERCC_ds_5pc.tar&quot;, exdir = &quot;apps/RNASeq/data/&quot;) The input data must be in a named list, with the same names as the input list of the pipeline. For this pipeline, 5 inputs are required to be set, including in_seqfiles, in_prefix, in_genomeDir, in_GTFfile and in_runThreadN. There are two different input lists, inputList and paramList. The inputList is used to define the inputs for each sample and will be submitted to different cluster nodes. The paramList is used to define parameters which are shared in all jobs. Two following inputs should be listed in inputList: in_seqfiles: A list with the fastq files of each sample in each element. The names of the list are also required to be defined and can be the sample IDs. The length of the list will be the same as the number of samples, thus the list will be defined to inputList and assigned to different nodes for parallel computing. in_prefix is the same as in_seqfiles, which defines a list of sample IDs. files &lt;- normalizePath(list.files(&quot;apps/RNASeq/data/&quot;, &quot;.gz&quot;, full.names = TRUE)) files &lt;- tapply(files, substring(basename(files), 1, 8), as.list) inputList &lt;- list(in_seqfiles = files, in_prefix = as.list(names(files))) These 3 parameter will be defined in paramList: in_genomeDir: The reference genome indexes for STAR. in_GTFfile: The gene annotation file in GTF format. in_runThreadN: The number of threads to run for each job. paramList &lt;- list( in_genomeDir = &quot;apps/data/GRCh38_100/&quot;, in_GTFfile = &quot;apps/data/gencode.v25.annotation.gtf&quot;, in_runThreadN = 4 ) In some cases, we need to modify the default arguments in some steps of a pipeline. For example, arguments(rnaseq_Sf, &quot;STAR&quot;)[[2]] &lt;- &quot;2&quot; head(arguments(rnaseq_Sf, &quot;STAR&quot;)) ## [[1]] ## [1] &quot;--outFilterMultimapNmax&quot; ## ## [[2]] ## [1] &quot;2&quot; ## ## [[3]] ## [1] &quot;--outSAMunmapped&quot; ## ## [[4]] ## [1] &quot;Within&quot; ## ## [[5]] ## [1] &quot;--outFilterMismatchNmax&quot; ## ## [[6]] ## [1] &quot;2&quot; 5.4.2 Submit pipeline with SGE The function runCWLBatch is used to submit the pipeline to cluster server. In addition to defining inputList and paramList, we need to define parallel parameters from the BiocParallel package. Here is an example where we use ‚Äúsge‚Äù to submit the jobs. The ‚Äúsge‚Äù template is a bash script with some predefined parameters for ‚Äúqsub‚Äù. The nodes queue name and number of slots/threads are variables from the template and can be assigned by the resources list. res &lt;- runCWLBatch(cwl = rnaseq_Sf, outdir = &quot;apps/RNASeq/output/&quot;, inputList = inputList, paramList = paramList, BPPARAM = BatchtoolsParam( workers = lengths(inputList)[1], cluster = &quot;sge&quot;, template = &quot;apps/data/sge_centos7.tmpl&quot;, resources = list(queue = &quot;centos7.q&quot;, threads = 4))) That‚Äôs it! The fastqc files of each sample will be submitted to different nodes to run the whole pipeline automatically. All the results have been collected to output directory of each sample. For example, dir(&quot;apps/RNASeq/output/HBR_Rep1&quot;) ## [1] &quot;abundance.h5&quot; ## [2] &quot;abundance.tsv&quot; ## [3] &quot;HBR_Rep1_abundance.tsv&quot; ## [4] &quot;HBR_Rep1_ERCC-Mix2_Build37-ErccTranscripts-chr22.read1_fastqc.zip&quot; ## [5] &quot;HBR_Rep1_ERCC-Mix2_Build37-ErccTranscripts-chr22.read2_fastqc.zip&quot; ## [6] &quot;HBR_Rep1Aligned.sortedByCoord.out.bam&quot; ## [7] &quot;HBR_Rep1Aligned.sortedByCoord.out.bam.bai&quot; ## [8] &quot;HBR_Rep1Aligned.sortedByCoord.out.distribution.txt&quot; ## [9] &quot;HBR_Rep1Aligned.sortedByCoord.out.featureCounts.txt&quot; ## [10] &quot;HBR_Rep1Aligned.sortedByCoord.out.featureCounts.txt.summary&quot; ## [11] &quot;HBR_Rep1Aligned.sortedByCoord.out.flagstat.txt&quot; ## [12] &quot;HBR_Rep1Aligned.sortedByCoord.out.geneBodyCoverage.curves.pdf&quot; ## [13] &quot;HBR_Rep1Aligned.sortedByCoord.out.geneBodyCoverage.txt&quot; ## [14] &quot;HBR_Rep1Log.final.out&quot; ## [15] &quot;HBR_Rep1ReadsPerGene.out.tab&quot; ## [16] &quot;run_info.json&quot; 5.4.3 Summarize QC The tool ‚Äúmultiqc‚Äù can aggregate results from the multiple outputs of the pipeline and generate a single page report, which also was implemented in the RcwlPipelines package: multiqc$dir &lt;- &quot;apps/RNASeq/output&quot; multiqc We can also run the tool using Rcwl locally with the option docker = TRUE: runCWL(multiqc, stderr = &quot;&quot;, Args = &quot;--preserve-entire-environment&quot;, docker = FALSE) Here we got the QC report: https://hubentu.github.io/others/multiqc_report.html 5.5 MC3 somatic variant calling pipeline The Multi-Center Mutation Calling in Multiple Cancers project (MC3) pipeline was developed by TCGA to generate a comprehensive encyclopedia of somatic mutation calls. MC3 works by applying an ensemble of seven mutation-calling algorithms with scoring and artifact filtering. More details can be found in this paper: Scalable Open Science Approach for Mutation Calling of Tumor Exomes Using Multiple Genomic Pipelines The mc3 pipeline is available at https://github.com/OpenGenomics/mc3. All required software have been deployed in cloud with docker. The pipeline has been imported and contained in the RcwlPipelines pacakge, which contains two major steps (markID step was removed): Call variants by 7 pipelines Merge VCF and convert to MAF The steps of the pipeline was built on the CWL files from its github repository, which were also contained in the package. Thereforce, we need to load the pipleine by sourcing it from the script. bfcinfo(tools) %&gt;% filter(rname == &quot;mc3&quot;) %&gt;% pull(rpath) %&gt;% source short(mc3) ## inputs: ## - tumorID ## - normalID ## - tumor ## - normal ## - bed_file ## - centromere ## - cosmic ## - dbsnp ## - refFasta ## - vepData ## outputs: ## - outmaf ## - outvcf ## steps: ## - call_variants ## - convert plotCWL(mc3) Two steps are included. 1. call_variants: To call variants by 7 pipelines: callVar &lt;- readCWL(runs(mc3)$call_variants) plotCWL(callVar) covert: To merge VCFs and convert to MAF: conv &lt;- readCWL(runs(mc3)$convert) plotCWL(conv) The merged VCF and converted MAF files will be collected to the output folder: outputs(mc3) ## outputs: ## outmaf: ## type: File ## outputSource: convert/outmaf ## outvcf: ## type: File ## outputSource: convert/vepvcf 5.5.1 Prepare data Testing somatic mutation data can be download from: https://github.com/genome/somatic-snv-test-data. Input list inputList. The tumorID/normalID must be consistent with SM from BAM read group. inputList &lt;- list(tumorID=list(test=&quot;NA12892&quot;), normalID=list(test=&quot;NA12878&quot;), tumor=list(test=&quot;apps/DNASeq/data/tumor.bam&quot;), normal=list(test=&quot;apps/DNASeq/data/normal.bam&quot;)) Parameter list paramList. paramList &lt;- list(bed_file=&quot;apps/data/mc3/gaf_20111020+broad_wex_1.1_hg19.bed&quot;, centromere=&quot;apps/data/mc3/centromere_hg19.bed&quot;, cosmic=&quot;apps/data/mc3/hg19_cosmic_v54_120711.vcf.gz&quot;, dbsnp=&quot;apps/data/mc3/dbsnp_134_b37.leftAligned.vcf.gz&quot;, refFasta=&quot;apps/data/human_g1k_v37.fa.gz&quot;, vepData=&quot;apps/data/.vep/&quot;) 5.5.2 Run MC3 pipeline res &lt;- runCWLBatch(mc3, outdir = &quot;apps/DNASeq/output/mc3&quot;, inputList = inputList, paramList = paramList, BPPARAM = BatchtoolsParam(workers = 1, cluster = &quot;sge&quot;, template = &quot;apps/data/sge_centos7.tmpl&quot;, resources = list(threads = 2, queue = &quot;centos7.q&quot;))) The final VCF was filtered and merged from the outputs of different callers and annotated by VEP: dir(&quot;apps/DNASeq/output/mc3/test&quot;) ## [1] &quot;merged.vep.vcf&quot; &quot;vep.maf&quot; The merged VCF file was converted to MAF file: vcf &lt;- read.table(&quot;apps/DNASeq/output/mc3/test/merged.vep.vcf&quot;, sep=&quot;\\t&quot;) head(vcf) ## V1 V2 V3 V4 V5 V6 V7 ## 1 21 10400299 . A T 0.0 PASS ## 2 21 10400380 . C T . PASS ## 3 21 10402435 rs2948877 G A . PASS ## 4 21 10402715 . G A 0.0 PASS ## 5 21 10402795 rs148043841 G T . PASS ## 6 21 10402985 . G GA . PASS ## V8 ## 1 CENTERS=RADIA|VARSCANS|MUSE|SOMATICSNIPER;CSQ=T|intergenic_variant|MODIFIER|||||||||||||||rs370695467|1||||1|SNV|1||||||||||||||||||||||||||||||| ## 2 CENTERS=SOMATICSNIPER|RADIA|VARSCANS|MUSE;CSQ=T|intergenic_variant|MODIFIER||||||||||||||||1||||1|SNV|1||||||||||||||||||||||||||||||| ## 3 CENTERS=MUSE|RADIA|VARSCANS|SOMATICSNIPER;CSQ=A|intergenic_variant|MODIFIER|||||||||||||||rs2948877|1||||1|SNV|1||||||||||||||||A:0.3626|A:0.4266|A:0.3228|A:0.3075|A:0.2913|A:0.4346|||||||||| ## 4 CENTERS=RADIA|VARSCANS|MUSE;CSQ=A|intergenic_variant|MODIFIER|||||||||||||||rs2948878|1||||1|SNV|1||||||||||||||||||||||||||||||| ## 5 CENTERS=MUSE|RADIA|VARSCANS;CSQ=T|intergenic_variant|MODIFIER|||||||||||||||rs373568457|1||||1|SNV|1||||||||||||||||||||||||||||||| ## 6 CENTERS=VARSCANI*|PINDEL;CSQ=A|intergenic_variant|MODIFIER|||||||||||||||rs375209288|1||||1|insertion|1||||||||||||||||||||||||||||||| ## V9 V10 V11 ## 1 GT:DP:AD 0/0:140:140,0 0/1:92:71,20 ## 2 GT:DP:AD 0/0:160:160,0 0/1:117:99,18 ## 3 GT:DP:AD 0/0:167:167,0 0/1:124:97,27 ## 4 GT:DP:AD 0/0:145:145,0 0/1:117:97,20 ## 5 GT:DP:AD 0/0:163:161,2 0/1:127:108,19 ## 6 GT:DP:AD 0/0:88:88,0 0/1:82:75,7 5.6 GATK4 germline variant calling pipeline The GATK 4 best practice pipeline for germline variant calling was implemented with Workflow Description Language (WDL), which is similar to cwl and requires cromwell to run the pipeline. The details of the pipeline can be found here: https://software.broadinstitute.org/gatk/best-practices/workflow?id=11145 Germline short variant discovery (SNPs + Indels) The germline pipeline include 4 steps in WDL, paired fastq to ubam, GATK alignment, variant calling by HaplotypeCaller and joint genotyping. We wrapped the GATK pipeline into 3 steps using Rcwl for different numbers of computing nodes requirements. The wrapped pipeline can help to assign inputs to the input JSON templates and glob results from the cromwell outputs. GAlign GATK alignment. The fastqs, sample information and customized json files for WDL are required as inputs. Multiple steps will run in this step, including bwa alignment, mark duplicates and base quality recalibration. GATK ready BAM files will be collected into the output directory. hapCall HaplotypeCaller. The GATK ready BAM and customized json files are inputs in this step. The local paths of GATK bundle files are required to be modified in your json file. A ‚ÄúgVCF‚Äù files will be generated. jdCall Joint variant discovery This step will combine the ‚ÄúgVCF‚Äù files and then call germline variants in all samples. The paths of the local bundle files are also required to be changed in the json template file. The final VCF file of germline variants will be generated. 5.6.1 GATK Alignment We wrapped the steps from raw fastqs to analysis-ready BAM file into GAlign pipeline. Here is the short summary of the pipeline. short(GAlign) ## inputs: ## - fastq1 ## - fastq2 ## - readGroup ## - sampleName ## - library ## - platunit ## - platform ## - center ## - tmpl1 ## - wdl1 ## - tmpl2 ## - wdl2 ## - cromwell ## outputs: ## - bamlog ## - outdir ## steps: ## - fqJson ## - fq2ubam ## - ubam2bamJson ## - align ## - mvOut For the inputList, we need to assign the fastqs files and read groups for each sample. The inputs can be multiple items separated by comma if there are more than one read groups for each sample. The input templates and WDL scripts can be assigned in the paramList, and the reference and other GATK bundle files in the local json files should be changed accordingly to your local version of files. The path to the cromwell binary file is also required. Here is an example: tmpl1 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/seq-format-conversion/paired-fastq-to-unmapped-bam.inputs.json&quot;) tmpl2 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-data-processing/processing-for-variant-discovery-gatk4.hg38.wgs.inputs.local.json&quot;) wdl1 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/seq-format-conversion/paired-fastq-to-unmapped-bam.wdl&quot;) wdl2 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-data-processing/processing-for-variant-discovery-gatk4.wdl&quot;) inputList &lt;- list(fastq1=list(normal=&quot;apps/DNASeq/data/normal_1.fq&quot;, tumor=&quot;apps/DNASeq/data/tumor_1.fq&quot;), fastq2=list(normal=&quot;apps/DNASeq/data/normal_2.fq&quot;, tumor=&quot;apps/DNASeq/data/tumor_2.fq&quot;), readGroup=list(&quot;normal.1&quot;, &quot;tumor.1&quot;), sampleName=list(&quot;normal&quot;, &quot;tumor&quot;), library=list(&quot;normal&quot;, &quot;tumor&quot;), platunit=list(&quot;normal&quot;, &quot;tumor&quot;), platform=list(&quot;illumina&quot;, &quot;illumina&quot;), center=list(&quot;rpccc&quot;, &quot;rpccc&quot;)) paramList &lt;- list(tmpl1=tmpl1, wdl1=wdl1, tmpl2=tmpl2, wdl2=wdl2, cromwell=&quot;/software/cromwell-36.jar&quot;) r1 &lt;- runCWLBatch(GAlign, outdir=&quot;apps/DNASeq/output/BAM&quot;, inputList, paramList, BatchtoolsParam(workers = 2, cluster=&quot;sge&quot;, template = &quot;apps/data/sge_centos7.tmpl&quot;, resources = list(threads = 16, queue = &quot;centos7.q&quot;)), stderr=&quot;&quot;) The outputs were globbed from the cromwell execution folder: list.files(&quot;apps/DNASeq/output/BAM/normal&quot;, recursive = TRUE) ## [1] &quot;output/normal.hg38.bai&quot; ## [2] &quot;output/normal.hg38.bam&quot; ## [3] &quot;output/normal.hg38.bam.md5&quot; ## [4] &quot;output/normal.hg38.duplicate_metrics&quot; ## [5] &quot;output/normal.hg38.recal_data.csv&quot; ## [6] &quot;processing-for-variant-discovery-gatk4.wdl.log&quot; 5.6.2 HaplotypeCaller This step takes the BAM files as input and each BAM file will be assigned to different computing nodes. The json template file needs to be modified to include the correct GATK bundle paths first. wdl3 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-germline-snps-indels/haplotypecaller-gvcf-gatk4.wdl&quot;) tmpl3 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-germline-snps-indels/haplotypecaller-gvcf-gatk4.hg38.inputs.local.json&quot;) bams &lt;- list(normal = normalizePath(&quot;output/BAM/normal/output/normal.hg38.bam&quot;), tumor = normalizePath(&quot;output/BAM/tumor/output/tumor.hg38.bam&quot;)) inputList &lt;- list(bam = bams) paramList &lt;- list(intervals = normalizePath(&quot;output/interval.txt&quot;), cromwell = &quot;/software/cromwell-36.jar&quot;, wdl = wdl3, tmpl = tmpl3) r2 &lt;- runCWLBatch(hapCall, outdir=&quot;apps/DNASeq/output/GATK&quot;, inputList, paramList, BatchtoolsParam(workers = 2, cluster=&quot;sge&quot;, template = &quot;apps/data/sge_centos7.tmpl&quot;, resources = list(threads = 16, queue = &quot;centos7.q&quot;)), stderr=&quot;&quot;) Here are the outputs: list.files(&quot;apps/DNASeq/output/GATK/normal&quot;, recursive = TRUE) ## [1] &quot;haplotypecaller-gvcf-gatk4.wdl.log&quot; ## [2] &quot;output/normal.hg38.g.vcf.gz&quot; ## [3] &quot;output/normal.hg38.g.vcf.gz.tbi&quot; 5.6.3 Joint Discovery The joint genotyping step will combine the gvcf files and then call variants in all samples, so only one computing node is required. Multiple values or files of the samples will need to be seperated by comma for each input in the inputList. The paths of the local bundle files will also need to be added to the json template file. wdl4 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-germline-snps-indels/joint-discovery-gatk4-local.wdl&quot;) tmpl4 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-germline-snps-indels/joint-discovery-gatk4-local.hg38.wgs.inputs.json&quot;) inputList &lt;- list(sampleName = list(test=&quot;normal,tumor&quot;), gvcf = list(test=&quot;apps/DNASeq/output/GATK/normal/output/normal.hg38.g.vcf.gz,apps/DNASeq/output/GATK/tumor/output/tumor.hg38.g.vcf.gz&quot;)) paramList &lt;- list(callsetName = &quot;test&quot;, intervals = &quot;apps/DNASeq/output/interval.21.interval_list&quot;, unpadded_intervals = &quot;apps/DNASeq/output/interval.21.intervals&quot;, tmpl = tmpl4, cromwell = &quot;/software/cromwell-36.jar&quot;, wdl = wdl4) r3 &lt;- runCWLBatch(jdCall, outdir=&quot;apps/DNASeq/output/GATK&quot;, inputList, paramList, BatchtoolsParam(workers = 1, cluster=&quot;sge&quot;, template = &quot;apps/sge_centos7.tmpl&quot;, resources = list(threads = 16, queue = &quot;centos7.q&quot;)), stderr=&quot;&quot;) Here are the final outputs: list.files(&quot;apps/DNASeq/output/GATK/test&quot;, recursive = TRUE) ## [1] &quot;joint-discovery-gatk4-local.wdl.log&quot; ## [2] &quot;output/out.intervals&quot; ## [3] &quot;output/test.variant_calling_detail_metrics&quot; ## [4] &quot;output/test.variant_calling_summary_metrics&quot; ## [5] &quot;output/test.vcf.gz&quot; ## [6] &quot;output/test.vcf.gz.tbi&quot; "],
["dna-seq-variant-calling.html", "Chapter 6 DNA-Seq Variant calling 6.1 DNA alignment 6.2 Germline variant calling 6.3 Somatic mutation calling 6.4 Structural variation 6.5 Copy number variation", " Chapter 6 DNA-Seq Variant calling First, we load the required packages. library(RcwlPipelines) library(BiocParallel) library(fs) library(dplyr) library(jsonlite) library(conflicted) ## always use select from dplyr conflict_prefer(&quot;select&quot;, &quot;dplyr&quot;, quiet = TRUE) A collection of resource bundle files, including reference, and variants files are required in most of the variant calling steps by different tools and pipelines. We collected a bundle of files in the data folder. ref &lt;- &quot;apps/data/hs37d5.fa&quot; dbsnp &lt;- &quot;apps/data/bundle/dbsnp_138.b37.vcf.gz&quot; 6.1 DNA alignment We use the test data sets from the ICGC-TCGA DREAM Mutation Calling challenge for demonstration and performance test. The test sets contains two pairs of BAM files with SNVs and SVs in chr19 and chr20 separately. The ‚ÄòTruth‚Äô VCF files are also included. Here is the URL to download the test data. https://www.synapse.org/#!Synapse:syn2335184 list.files(&quot;apps/data/DREAM/&quot;) ## [1] &quot;chr19.normal.bam&quot; &quot;chr19.normal.bam.bai&quot; ## [3] &quot;chr19.truth.vcf.gz&quot; &quot;chr19.truth.vcf.gz.tbi&quot; ## [5] &quot;chr19.tumor.bam&quot; &quot;chr19.tumor.bam.bai&quot; ## [7] &quot;normal.chr20.bam&quot; &quot;truth.chr20.vcf.gz&quot; ## [9] &quot;tumor.chr20.bam&quot; dir_info(&quot;apps/data/DREAM&quot;) %&gt;% select(path, size) ## # A tibble: 9 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::bytes&gt; ## 1 apps/data/DREAM/chr19.normal.bam 3.31G ## 2 apps/data/DREAM/chr19.normal.bam.bai 171.64K ## 3 apps/data/DREAM/chr19.truth.vcf.gz 21.6K ## 4 apps/data/DREAM/chr19.truth.vcf.gz.tbi 11.27K ## 5 apps/data/DREAM/chr19.tumor.bam 3.38G ## 6 apps/data/DREAM/chr19.tumor.bam.bai 1.45M ## 7 apps/data/DREAM/normal.chr20.bam 2.93G ## 8 apps/data/DREAM/truth.chr20.vcf.gz 16.58K ## 9 apps/data/DREAM/tumor.chr20.bam 2.9G In order to show the variant calling workflow from the very beginning. We convert the BAM files back to fastqs using picard SamToFastq and treat the two BAM files as samples from two patients. inputs(SamToFastq) ## inputs: ## bam (File): I= ## fq1 (string): F= ## fq2 (string): F2= ## prepare inputs bams &lt;- list.files(&quot;apps/data/DREAM/&quot;, &quot;.bam$&quot;, full.names = TRUE) samples &lt;- c(&quot;normal19&quot;, &quot;tumor19&quot;, &quot;normal20&quot;, &quot;tumor20&quot;) Bams &lt;- tapply(bams, samples, as.list) fq1 &lt;- tapply(paste0(samples, &quot;_R1.fq&quot;), samples, as.list) fq2 &lt;- tapply(paste0(samples, &quot;_R2.fq&quot;), samples, as.list) inputList &lt;- list(bam = Bams, fq1 = fq1, fq2 = fq2) ## run in HPC using SGE res1 &lt;- runCWLBatch(SamToFastq, outdir = &quot;apps/variants/fastq/&quot;, inputList, BPPARAM = BatchtoolsParam(workers = length(samples), cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(jobname = &quot;sam2fq&quot;, queue = &quot;all.q&quot;, threads = 16), log=TRUE, logdir=&quot;.&quot;, progressbar = T), stderr = &quot;&quot;) Let‚Äôs check the outputs. dir_info(&quot;apps/variants/fastq/&quot;, recurse = TRUE, glob = &quot;*.fq&quot;) %&gt;% select(path, size) ## # A tibble: 8 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::bytes&gt; ## 1 apps/variants/fastq/normal19/normal19_R1.fq 2.17G ## 2 apps/variants/fastq/normal19/normal19_R2.fq 2.17G ## 3 apps/variants/fastq/normal20/normal20_R1.fq 2.14G ## 4 apps/variants/fastq/normal20/normal20_R2.fq 2.14G ## 5 apps/variants/fastq/tumor19/tumor19_R1.fq 2.18G ## 6 apps/variants/fastq/tumor19/tumor19_R2.fq 2.18G ## 7 apps/variants/fastq/tumor20/tumor20_R1.fq 2.14G ## 8 apps/variants/fastq/tumor20/tumor20_R2.fq 2.14G Now, we are ready to run the DNA alignment pipeline, bwaMRecal, including all necessary steps to prepare the analysis-ready BAM files. We can check the required inputs and steps. inputs(bwaMRecal) ## inputs: ## outBam (string): ## RG (string): ## threads (int): ## Ref (File): ## FQ1s (File): ## FQ2s (File): ## knowSites: ## type: array ## prefix: names(steps(bwaMRecal)) ## [1] &quot;bwaAlign&quot; &quot;markdup&quot; &quot;BaseRecal&quot; fqs &lt;- list.files(&quot;apps/variants/fastq&quot;, recursive = TRUE, full.names = TRUE) fq1 &lt;- fqs[grep(&quot;R1&quot;, fqs)] fq2 &lt;- fqs[grep(&quot;R2&quot;, fqs)] ids &lt;- sub(&quot;_.*&quot;, &quot;&quot;, basename(fq1)) fq1L &lt;- tapply(fq1, ids, as.list) fq2L &lt;- tapply(fq2, ids, as.list) RGs &lt;- paste(&quot;@RG&quot;, paste0(&quot;ID:&quot;, ids), paste0(&quot;LB:&quot;, ids), paste0(&quot;DT:&quot;, Sys.Date()), paste0(&quot;PL:&quot;, &quot;Illumina&quot;), &quot;CN:RCWL&quot;, paste0(&quot;SM:&quot;, ids), sep = &quot;\\\\t&quot;) RGL &lt;- tapply(RGs, ids, as.list) outBam &lt;- as.list(paste0(names(RGL), &quot;.bam&quot;)) inputList &lt;- list(RG = RGL, outBam = outBam, FQ1s = fq1L, FQ2s = fq2L) paramList &lt;- list(threads = 16, Ref =ref, knowSites = list( &quot;apps/data/bundle/dbsnp_138.b37.vcf&quot;, &quot;apps/data/bundle/Mills_and_1000G_gold_standard.indels.b37.vcf&quot; )) res2 &lt;- runCWLBatch(bwaMRecal, outdir = &quot;apps/variants/BAM&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = length(samples), cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;align&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) Here are the outputs: dir_info(&quot;apps/variants/BAM/&quot;, recurse = TRUE) %&gt;% select(path, size) ## # A tibble: 26 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::bytes&gt; ## 1 apps/variants/BAM/normal19 4K ## 2 apps/variants/BAM/normal19/normal19.bai 2.6M ## 3 apps/variants/BAM/normal19/normal19.bam 2.3G ## 4 apps/variants/BAM/normal19/normal19.bam.bai 2.6M ## 5 apps/variants/BAM/normal19/normal19.bam.markdup.txt 2.75K ## 6 apps/variants/BAM/normal19/normal19.flagstat.txt 448 ## 7 apps/variants/BAM/normal19/normal19.stats.txt 95.16K ## 8 apps/variants/BAM/normal20 4K ## 9 apps/variants/BAM/normal20/normal20.bai 2.45M ## 10 apps/variants/BAM/normal20/normal20.bam 2.23G ## # ‚Ä¶ with 16 more rows 6.2 Germline variant calling The GATK germline variant calling pipeline is one of the most popular method to call germline short variants. The latest best practice was implemented with the Workflow Description Language (WDL). The WDL scripts was simply wrapped with Rcwl in the RcwlPipelines package. https://github.com/gatk-workflows/gatk4-germline-snps-indels There are two steps to run the latest GATK pipeline if the BAMs are prepared. First the haplotypecaller step is used to call variants by samples. The ‚ÄúWDL‚Äù script and ‚Äújson‚Äù input for this step are also contained in the package. wdl1 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-germline-snps-indels/haplotypecaller-gvcf-gatk4.wdl&quot;) tmpl1 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-germline-snps-indels/haplotypecaller-gvcf-gatk4.hg38.inputs.local.json&quot;) We need to modify the reference from ‚Äúhg38‚Äù to ‚Äúb37‚Äù. Please note that all the file paths should be absolute paths for the ‚ÄúWDL‚Äù inputs. json1 &lt;- fromJSON(tmpl1) json1$HaplotypeCallerGvcf_GATK4.ref_dict &lt;- normalizePath(&quot;apps/data/hs37d5.dict&quot;) json1$HaplotypeCallerGvcf_GATK4.ref_fasta &lt;- normalizePath(&quot;apps/data/hs37d5.fa&quot;) json1$HaplotypeCallerGvcf_GATK4.ref_fasta_index &lt;- normalizePath(&quot;apps/data/hs37d5.fa.fai&quot;) dir.create(&quot;apps/variants/vcf&quot;) writeLines(jsonlite::toJSON(json1, pretty = TRUE, auto_unbox = T), &quot;apps/variants/vcf/tmpl1.json&quot;) A interval list is required to define the exome capture region. We couldn‚Äôt find one for the TCGA data, so here we just simply use the exome regions. library(TxDb.Hsapiens.UCSC.hg19.knownGene) options(scipen = 999) e1 &lt;- reduce(exons(TxDb.Hsapiens.UCSC.hg19.knownGene), ignore.strand = TRUE) e1 &lt;- e1[seqnames(e1) %in% c(&quot;chr19&quot;, &quot;chr20&quot;)] e1df &lt;- data.frame(e1) bed &lt;- data.frame(as.character(sub(&quot;chr&quot;, &quot;&quot;, e1df[,1])), e1df[,2] - 1, e1df[,3]) write.table(bed, &quot;apps/variants/vcf/intval.bed&quot;, sep = &quot;\\t&quot;, row.names = FALSE, col.names = FALSE, quote = FALSE) BedToIntervalList$bed &lt;- &quot;apps/variants/vcf/intval.bed&quot; BedToIntervalList$SD &lt;- &quot;apps/data/hs37d5.dict&quot; BedToIntervalList$out &lt;- &quot;region.interval_list&quot; r1 &lt;- runCWL(BedToIntervalList, outdir = &quot;apps/variants/vcf/&quot;) writeLines(normalizePath(&quot;apps/variants/vcf/region.interval_list&quot;), &quot;apps/variants/vcf/intval.txt&quot;) fai &lt;- read.table(&quot;apps/data/hs37d5.fa.fai&quot;) unpad &lt;- paste0(c(19, 20), &quot;:&quot;, 1, &quot;-&quot;, fai[19:20, 2]) writeLines(unpad, &quot;apps/variants/vcf/intval.unpad.txt&quot;) ## fix bai paths file.copy(&quot;apps/variants/BAM/normal19/normal19.bam.bai&quot;, &quot;apps/variants/BAM/normal19/normal19.bai&quot;) file.copy(&quot;apps/variants/BAM/normal20/normal20.bam.bai&quot;, &quot;apps/variants/BAM/normal20/normal20.bai&quot;) bams &lt;- normalizePath(list.files(&quot;apps/variants/BAM&quot;, &quot;normal.*.bam$&quot;, recursive = TRUE, full.names = TRUE)) bams &lt;- as.list(bams) names(bams) &lt;- c(&quot;normal19&quot;, &quot;normal20&quot;) inputList &lt;- list(bam = bams) paramList &lt;- list(intervals = normalizePath(&quot;apps/variants/vcf/intval.txt&quot;), cromwell = normalizePath(&quot;apps/cromwell-45.jar&quot;), wdl = wdl1, tmpl = normalizePath(&quot;apps/variants/vcf/tmpl1.json&quot;)) res3 &lt;- runCWLBatch(hapCall, outdir = &quot;apps/variants/vcf&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = length(bams), cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;hapCall&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;, cwlTemp=T) Here are the results. dir_info(&quot;apps/variants/vcf/&quot;, recurse = TRUE, glob = &quot;*.g.vcf.gz&quot;) %&gt;% select(path, size) ## # A tibble: 2 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::bytes&gt; ## 1 apps/variants/vcf/normal19/output/normal19.g.vcf.gz 192M ## 2 apps/variants/vcf/normal20/output/normal20.g.vcf.gz 199M Then we perform joint genotyping with jdCall. The reference genome bundles are also need to be changed to ‚Äúb37‚Äù. You can skip this step if you already have a ‚Äúb37‚Äù version of metadata file. wdl2 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-germline-snps-indels/joint-discovery-gatk4-local.wdl&quot;) tmpl2 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-germline-snps-indels/joint-discovery-gatk4-local.hg38.wgs.inputs.json&quot;) ## change to b37 json2 &lt;- fromJSON(tmpl2) json2$JointGenotyping.ref_dict &lt;- normalizePath(&quot;apps/data/hs37d5.dict&quot;) json2$JointGenotyping.ref_fasta &lt;- normalizePath(&quot;apps/data/hs37d5.fa&quot;) json2$JointGenotyping.ref_fasta_index &lt;- normalizePath(&quot;apps/data/hs37d5.fa.fai&quot;) json2$JointGenotyping.dbsnp_vcf &lt;- normalizePath(&quot;apps/data/bundle/dbsnp_138.b37.vcf&quot;) json2$JointGenotyping.dbsnp_vcf_index &lt;- normalizePath(&quot;apps/data/bundle/dbsnp_138.b37.vcf.idx&quot;) json2$JointGenotyping.one_thousand_genomes_resource_vcf &lt;- normalizePath(&quot;apps/data/bundle/1000G_phase1.snps.high_confidence.b37.vcf&quot;) json2$JointGenotyping.one_thousand_genomes_resource_vcf_index &lt;- normalizePath(&quot;apps/data/bundle/1000G_phase1.snps.high_confidence.b37.vcf.idx&quot;) json2$JointGenotyping.omni_resource_vcf &lt;- normalizePath(&quot;apps/data/bundle/1000G_omni2.5.b37.vcf&quot;) json2$JointGenotyping.omni_resource_vcf_index &lt;- normalizePath(&quot;apps/data/bundle/1000G_omni2.5.b37.vcf.idx&quot;) json2$JointGenotyping.mills_resource_vcf &lt;- normalizePath(&quot;apps/data/bundle/Mills_and_1000G_gold_standard.indels.b37.vcf&quot;) json2$JointGenotyping.mills_resource_vcf_index &lt;- normalizePath(&quot;apps/data/bundle/Mills_and_1000G_gold_standard.indels.b37.vcf.idx&quot;) json2$JointGenotyping.axiomPoly_resource_vcf &lt;- normalizePath(&quot;apps/data/bundle/Axiom_Exome_Plus.genotypes.all_populations.poly.vcf.gz&quot;) json2$JointGenotyping.axiomPoly_resource_vcf_index &lt;- normalizePath(&quot;apps/data/bundle/Axiom_Exome_Plus.genotypes.all_populations.poly.vcf.gz.tbi&quot;) json2$JointGenotyping.hapmap_resource_vcf &lt;- normalizePath(&quot;apps/data/bundle/hapmap_3.3.b37.vcf&quot;) json2$JointGenotyping.hapmap_resource_vcf_index &lt;- normalizePath(&quot;apps/data/bundle/hapmap_3.3.b37.vcf.idx&quot;) writeLines(toJSON(json2, pretty = TRUE, auto_unbox = T), &quot;apps/variants/vcf/tmpl2.json&quot;) The joint calling step takes the inputs from the previous step and run together. ## prepare inputs sampleName &lt;- paste(names(bams), collapse = &quot;,&quot;) gvcf &lt;- paste(normalizePath(list.files(&quot;apps/variants/vcf&quot;, &quot;g.vcf.gz$&quot;, recursive = TRUE, full.names = TRUE)), collapse = &quot;,&quot;) inputList &lt;- list(sampleName = list(res = sampleName), gvcf = list(res = gvcf)) paramList &lt;- list(callsetName = &quot;germline&quot;, intervals = normalizePath(&quot;apps/variants/vcf/region.interval_list&quot;), unpadded_intervals = normalizePath(&quot;apps/variants/vcf/intval.unpad.txt&quot;), tmpl = normalizePath(&quot;apps/variants/vcf/tmpl2.json&quot;), wdl = wdl2, cromwell = normalizePath(&quot;apps/cromwell-45.jar&quot;)) res4 &lt;- runCWLBatch(jdCall, outdir = &quot;apps/variants/vcf1&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 1, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;jdCall&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;, cwlTemp=T) Here are the final results: dir_info(&quot;apps/variants/vcf/res/output&quot;, recurse = TRUE) %&gt;% select(path, size) ## # A tibble: 5 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::byte&gt; ## 1 apps/variants/vcf/res/output/germline.variant_calling_detail_‚Ä¶ 1.82K ## 2 apps/variants/vcf/res/output/germline.variant_calling_summary‚Ä¶ 1.6K ## 3 apps/variants/vcf/res/output/germline.vcf.gz 13.65M ## 4 apps/variants/vcf/res/output/germline.vcf.gz.tbi 83.89K ## 5 apps/variants/vcf/res/output/out.intervals 27 6.3 Somatic mutation calling We have collected many somatic mutation callers, including MuTect2, strelka2, MuSe, VarDict, SomaticSniper, LoFreq, VarScan2, lancet and neusomatic. Recent research papers have reported that the combination of multiple callers could improve the sensitivity and specificity. 6.3.1 MuTect2 The MuTect2 was built based on the latest best practise from GATK 4. https://software.broadinstitute.org/gatk/best-practices/workflow?id=11146 The required resources files can be downloaded from its google storage. &lt;gs://gatk-best-practices&gt; Call variants on normal samples bams &lt;- list.files(&quot;apps/variants/BAM&quot;, &quot;.bam$&quot;, recursive = TRUE, full.names = TRUE) nbam &lt;- as.list(bams[1:2]) names(nbam) &lt;- c(&quot;normal19&quot;, &quot;normal20&quot;) ovcf &lt;- as.list(paste0(names(nbam), &quot;.vcf&quot;)) inputList &lt;- list(tbam = nbam, out = ovcf) paramList &lt;- list(Ref = ref, interval = &quot;apps/variants/vcf/intval.bed&quot;) ## avoid a bug in GenomicsDBImport arguments(Mutect2) &lt;- list(&quot;-max-mnp-distance&quot;, &quot;0&quot;) res5 &lt;- runCWLBatch(Mutect2, outdir = &quot;apps/variants/mutect2&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;mutect2&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) dir_info(&quot;apps/variants/mutect2&quot;, regexp = &quot;normal&quot;, recurse = TRUE) %&gt;% select(path, size) ## # A tibble: 14 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::byte&gt; ## 1 apps/variants/mutect2/normal19 4K ## 2 apps/variants/mutect2/normal19/normal19.vcf 15.96M ## 3 apps/variants/mutect2/normal19/normal19.vcf.idx 117.92K ## 4 apps/variants/mutect2/normal19/normal19.vcf.stats 37 ## 5 apps/variants/mutect2/normal20 4K ## 6 apps/variants/mutect2/normal20/normal20.vcf 14.59M ## 7 apps/variants/mutect2/normal20/normal20.vcf.idx 248.43K ## 8 apps/variants/mutect2/normal20/normal20.vcf.stats 37 ## 9 apps/variants/mutect2/pt19/normal19.tumor19.ctfiltered.obfil‚Ä¶ 123.43K ## 10 apps/variants/mutect2/pt19/normal19.tumor19.ctfiltered.obfil‚Ä¶ 542.26K ## 11 apps/variants/mutect2/pt19/normal19.tumor19.ctfiltered.obfil‚Ä¶ 1.04M ## 12 apps/variants/mutect2/pt20/normal20.tumor20.ctfiltered.obfil‚Ä¶ 211.87K ## 13 apps/variants/mutect2/pt20/normal20.tumor20.ctfiltered.obfil‚Ä¶ 517.15K ## 14 apps/variants/mutect2/pt20/normal20.tumor20.ctfiltered.obfil‚Ä¶ 990.28K Note that, we need to add ‚Äú-max-mnp-distance 0‚Äù to the arguments according to the Mutect2 documents to avoid a bug in ‚ÄúGenomicsDBImport‚Äù step. Create a panel of normals (PoN) GPoN$nvcf &lt;- as.list(list.files(&quot;apps/variants/mutect2/&quot;, &quot;.vcf$&quot;, recursive = TRUE, full.names = TRUE)) GPoN$Ref &lt;- ref GPoN$interval &lt;- &quot;apps/variants/vcf/intval.bed&quot; GPoN$pvcf &lt;- &quot;pon.vcf&quot; ##GPoN$gresource &lt;- &quot;apps/data/Mutect2/af-only-gnomad.raw.sites.b37.vcf&quot; runCWL(GPoN, outdir = &quot;apps/variants/mutect2/&quot;, stderr = &quot;&quot;, Args = &quot;--relax-path-checks&quot;) Here we add ‚Äú‚Äìrelax-path-checks‚Äù arugment to the ‚Äúcwltool‚Äù because the temporary files have special characters in their file names. Mutect2 pipeline We can visulize how the pipeline Mutect2PL was built based on the best practice guide. plotCWL(Mutect2PL) tbam &lt;- as.list(bams[3:4]) nbam &lt;- as.list(bams[1:2]) nid &lt;- as.list(sub(&quot;.bam&quot;, &quot;&quot;, basename(bams))[1:2]) tid &lt;- as.list(sub(&quot;.bam&quot;, &quot;&quot;, basename(bams))[3:4]) names(tbam) &lt;- names(nbam) &lt;- c(&quot;pt19&quot;, &quot;pt20&quot;) inputList &lt;- list(tbam = tbam, nbam = nbam, normal = nid, tumor = tid) paramList &lt;- list(Ref = ref, gresource = &quot;apps/data/Mutect2/af-only-gnomad.raw.sites.b37.vcf&quot;, pon = &quot;apps/variants/mutect2/pon.vcf&quot;, interval = &quot;apps/variants/vcf/intval.bed&quot;, comvcf = &quot;apps/data/Mutect2/GetPileupSummaries/small_exac_common_3_b37.vcf&quot;) res6 &lt;- runCWLBatch(Mutect2PL, outdir = &quot;apps/variants/mutect2&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;mutect2&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) Here are the final results for sample ‚Äúpt19‚Äù: list.files(&quot;apps/variants/mutect2/pt19&quot;) ## [1] &quot;normal19.tumor19.ctfiltered.obfiltered.PASS.u.vcf&quot; ## [2] &quot;normal19.tumor19.ctfiltered.obfiltered.PASS.vcf&quot; ## [3] &quot;normal19.tumor19.ctfiltered.obfiltered.vcf&quot; ## [4] &quot;t.contamination.table&quot; ## [5] &quot;tumor19.art.pre_adapter_detail_metrics.txt&quot; 6.3.2 MuSE Only one step is required to run MuSE. We only need to prepare the BAM files, reference genome, caputre region and the dbSNP vcf file. inputList &lt;- list(tbam = tbam, nbam = nbam, vcf = as.list(paste0(names(tbam), &quot;_MuSE.vcf&quot;))) paramList &lt;- list(ref = ref, region = &quot;apps/variants/vcf/intval.bed&quot;, dbsnp = dbsnp) res7 &lt;- runCWLBatch(MuSE, outdir = &quot;apps/variants/MuSE&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;MuSE&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) Here are the results: dir_info(&quot;apps/variants/MuSE&quot;, glob = &quot;*.vcf&quot;, recurse = TRUE) %&gt;% select(path, size) ## # A tibble: 2 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::bytes&gt; ## 1 apps/variants/MuSE/pt19/pt19_MuSE.vcf 89.8K ## 2 apps/variants/MuSE/pt20/pt20_MuSE.vcf 162.2K More details about the tool can be found: https://bioinformatics.mdanderson.org/public-software/muse/. 6.3.3 Strelka2 The tool recommended to use the indel candidates from manta as input for strelka2. We combined the two tools as mantaStrelka pipeline. The tool also recommended to use a indexed region file. bgzip$ifile &lt;- &quot;apps/variants/vcf/intval.bed&quot; runCWL(bgzip, outdir = &quot;apps/variants/vcf/&quot;, stderr = &quot;&quot;) tabix_index$tfile &lt;- &quot;apps/variants/vcf/intval.bed.gz&quot; tabix_index$type &lt;- &quot;bed&quot; runCWL(tabix_index, outdir = &quot;apps/variants/vcf/&quot;, stderr = &quot;&quot;) To prepare the inputs and run it. inputList &lt;- list(tbam = tbam, nbam = nbam) paramList &lt;- list(ref = ref, region = &quot;apps/variants/vcf/intval.bed.gz&quot;) res8 &lt;- runCWLBatch(mantaStrelka, outdir = &quot;apps/variants/strelka&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;strelka&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) Here are the results: dir_info(&quot;apps/variants/strelka&quot;, glob = &quot;*.vcf.gz*&quot;, recurse = TRUE) %&gt;% select(path, size) ## # A tibble: 8 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::bytes&gt; ## 1 apps/variants/strelka/pt19/somatic.indels.vcf.gz 75.81K ## 2 apps/variants/strelka/pt19/somatic.indels.vcf.gz.tbi 10.5K ## 3 apps/variants/strelka/pt19/somatic.snvs.vcf.gz 338.11K ## 4 apps/variants/strelka/pt19/somatic.snvs.vcf.gz.tbi 26.76K ## 5 apps/variants/strelka/pt20/somatic.indels.vcf.gz 26.31K ## 6 apps/variants/strelka/pt20/somatic.indels.vcf.gz.tbi 4.23K ## 7 apps/variants/strelka/pt20/somatic.snvs.vcf.gz 402.21K ## 8 apps/variants/strelka/pt20/somatic.snvs.vcf.gz.tbi 29.57K More details about the tool can be found: https://github.com/Illumina/strelka 6.3.4 SomaticSniper The SomaticSniper only requires bams and reference genome to run. inputList &lt;- list(tbam = tbam, nbam = nbam, vcf = as.list(paste0(names(tbam), &quot;_SomaticSniper.vcf&quot;))) paramList &lt;- list(ref = ref) res9 &lt;- runCWLBatch(SomaticSniper, outdir = &quot;apps/variants/SomaticSniper&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;SomaticSniper&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) Here are the results: dir_info(&quot;apps/variants/SomaticSniper&quot;, glob = &quot;*.vcf&quot;, recurse = TRUE) %&gt;% select(path, size) ## # A tibble: 2 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::bytes&gt; ## 1 apps/variants/SomaticSniper/pt19/pt19_SomaticSniper.vcf 671K ## 2 apps/variants/SomaticSniper/pt20/pt20_SomaticSniper.vcf 867K More details can be found: https://github.com/genome/somatic-sniper 6.3.5 VarDict Similar to the other tools, we only need to prepare BAM files, reference genome and the capture region file. inputList &lt;- list(tbam = tbam, nbam = nbam, vcf = as.list(paste0(names(tbam), &quot;_VarDict.vcf&quot;))) paramList &lt;- list(ref = ref, region = &quot;apps/variants/vcf/intval.bed&quot;) res10 &lt;- runCWLBatch(VarDict, outdir = &quot;apps/variants/VarDict&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;VarDict&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) Here are the results: dir_info(&quot;apps/variants/VarDict&quot;, glob = &quot;*.vcf&quot;, recurse = TRUE) %&gt;% select(path, size) ## # A tibble: 2 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::bytes&gt; ## 1 apps/variants/VarDict/pt19/pt19_VarDict.vcf 2.46M ## 2 apps/variants/VarDict/pt20/pt20_VarDict.vcf 985.92K More details can be found: https://github.com/AstraZeneca-NGS/VarDict 6.3.6 LoFreq The tools requires BAM files, reference genome, dbSNP and capture regions. inputList &lt;- list(tbam = tbam, nbam = nbam, out = as.list(paste0(names(tbam), &quot;_LoFreq&quot;))) paramList &lt;- list(ref = ref, region = &quot;apps/variants/vcf/intval.bed&quot;, dbsnp = dbsnp, threads = 16) res11 &lt;- runCWLBatch(LoFreq, outdir = &quot;apps/variants/LoFreq&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;LoFreq&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) Here are the results: dir_info(&quot;apps/variants/LoFreq&quot;, glob = &quot;*.vcf.gz&quot;, recurse = TRUE) %&gt;% select(path, size) ## # A tibble: 8 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::byte&gt; ## 1 apps/variants/LoFreq/pt19/pt19_LoFreqsomatic_final.indels.vcf‚Ä¶ 858 ## 2 apps/variants/LoFreq/pt19/pt19_LoFreqsomatic_final.snvs.vcf.gz 2.88K ## 3 apps/variants/LoFreq/pt19/pt19_LoFreqsomatic_final_minus-dbsn‚Ä¶ 858 ## 4 apps/variants/LoFreq/pt19/pt19_LoFreqsomatic_final_minus-dbsn‚Ä¶ 2.78K ## 5 apps/variants/LoFreq/pt20/pt20_LoFreqsomatic_final.indels.vcf‚Ä¶ 856 ## 6 apps/variants/LoFreq/pt20/pt20_LoFreqsomatic_final.snvs.vcf.gz 2.62K ## 7 apps/variants/LoFreq/pt20/pt20_LoFreqsomatic_final_minus-dbsn‚Ä¶ 856 ## 8 apps/variants/LoFreq/pt20/pt20_LoFreqsomatic_final_minus-dbsn‚Ä¶ 2.55K More details can be found: https://csb5.github.io/lofreq/ 6.3.7 VarScan2 We simply prepare inputs and run as before. inputList &lt;- list(tbam = tbam, nbam = nbam) paramList &lt;- list(ref = ref, region = &quot;apps/variants/vcf/intval.bed&quot;) res13 &lt;- runCWLBatch(VarScan2Somatic, outdir = &quot;apps/variants/VarScan2&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;VarScan2&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) Here are the results: dir_info(&quot;apps/variants/VarScan2&quot;, glob = &quot;*.vcf&quot;, recurse = TRUE) %&gt;% select(path, size) ## # A tibble: 6 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::bytes&gt; ## 1 apps/variants/VarScan2/pt19/tumor19.indel.vcf 80.7K ## 2 apps/variants/VarScan2/pt19/tumor19.normal19.somatic.vcf 14.2K ## 3 apps/variants/VarScan2/pt19/tumor19.snp.vcf 772.4K ## 4 apps/variants/VarScan2/pt20/tumor20.indel.vcf 28.4K ## 5 apps/variants/VarScan2/pt20/tumor20.normal20.somatic.vcf 12.1K ## 6 apps/variants/VarScan2/pt20/tumor20.snp.vcf 297.1K More details can be found: http://varscan.sourceforge.net/ 6.3.8 Lancet The tool requires BAM files, reference genome and capture region. inputList &lt;- list(tbam = tbam, nbam = nbam) paramList &lt;- list(ref = ref, region = &quot;apps/variants/vcf/intval.bed&quot;, threads = 16) res14 &lt;- runCWLBatch(lancet, outdir = &quot;apps/variants/lancet&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;lancet&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) Here are the results: dir_info(&quot;apps/variants/lancet&quot;, glob = &quot;*.vcf&quot;, recurse = TRUE) %&gt;% select(path, size) ## # A tibble: 2 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::bytes&gt; ## 1 apps/variants/lancet/pt19/tumor19_normal19.vcf 5.26M ## 2 apps/variants/lancet/pt20/tumor20_normal20.vcf 2.15M More details can be found: https://github.com/nygenome/lancet 6.3.9 Neusomatic It is recommended to combine the mutation results from multiple somatic mutation callers to increase both sensitivity and specificitiy by recent publications. The recent published tools neusomatic provides a emsembling mode to combine multiple existing methods to achieve the highest accuracy. First, we collect the outputs from previous somatic variant callers. mutect2Vcf &lt;- list.files(&quot;apps/variants/mutect2&quot;, &quot;obfiltered.vcf$&quot;, recursive = TRUE, full.names = TRUE) varscan2Snp &lt;- list.files(&quot;apps/variants/VarScan2&quot;, &quot;.snp.vcf$&quot;, recursive = TRUE, full.names = TRUE) varscan2Indel &lt;- list.files(&quot;apps/variants/VarScan2&quot;, &quot;.indel.vcf$&quot;, recursive = TRUE, full.names = TRUE) sniperVcf &lt;- list.files(&quot;apps/variants/SomaticSniper&quot;, &quot;vcf$&quot;, recursive = TRUE, full.names = TRUE) vardictVcf &lt;- list.files(&quot;apps/variants/VarDict&quot;, &quot;.vcf$&quot;, recursive = TRUE, full.names = TRUE) museVcf &lt;- list.files(&quot;apps/variants/MuSE&quot;, &quot;.vcf$&quot;, recursive = TRUE, full.names = TRUE) strelkaSNP &lt;- list.files(&quot;apps/variants/strelka&quot;, &quot;snvs.vcf.gz$&quot;, recursive = TRUE, full.names = TRUE) strelkaIndel &lt;- list.files(&quot;apps/variants/strelka&quot;, &quot;indels.vcf.gz$&quot;, recursive = TRUE, full.names = TRUE) lofreqSNP &lt;- list.files(&quot;apps/variants/LoFreq&quot;, &quot;final.snvs.vcf.gz$&quot;, recursive = TRUE, full.names = TRUE) lofreqIndel &lt;- list.files(&quot;apps/variants/LoFreq&quot;, &quot;final.indels.vcf.gz$&quot;, recursive = TRUE, full.names = TRUE) Here we use the wrapper script from somaticseq to essemble the results. inputList &lt;- list(tbam = tbam, nbam = nbam, mutect2 = as.list(mutect2Vcf), varscanSnv = as.list(varscan2Snp), varscanIndel = as.list(varscan2Indel), sniper = as.list(sniperVcf), vardict = as.list(vardictVcf), muse = as.list(museVcf), strelkaSnv = as.list(strelkaSNP), strelkaIndel = as.list(strelkaIndel), lofreqSnv = as.list(lofreqSNP), lofreqIndel = as.list(lofreqIndel)) paramList &lt;- list(ref = ref, region = &quot;apps/variants/vcf/intval.bed&quot;, dbsnp = dbsnp) res15 &lt;- runCWLBatch(SomaticSeq_Wrapper, outdir = &quot;apps/variants/Wrapper&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;mem.q&quot;, jobname = &quot;Wrapper&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) The neusomatic pipeline provided a ensemble mode to use outputs from different somatic callers as candidates and applied a pre-trained deep learning model to filter the variant candiates. First, we need to combine the SNV and INDEL candidates for the ensemble mode input. for(id in names(tbam)) { snv1 &lt;- read.table(paste0(&quot;apps/variants/Wrapper/&quot;, id, &quot;/Ensemble.sSNV.tsv&quot;), header = TRUE) indel1 &lt;- read.table(paste0(&quot;apps/variants/Wrapper/&quot;, id, &quot;/Ensemble.sINDEL.tsv&quot;), header = TRUE) var1 &lt;- rbind(snv1, indel1) var1[is.na(var1)] &lt;- 0 write.table(var1, file = paste0(&quot;apps/variants/Wrapper/&quot;, id, &quot;/Ensemble.sVar.tsv&quot;), row.names = FALSE, sep = &quot;\\t&quot;, quote = FALSE) } ensemble &lt;- list.files(&quot;apps/variants/Wrapper&quot;, &quot;Ensemble.sVar.tsv&quot;, recursive = TRUE, full.names = TRUE) Then we can prepare the inputs and run the neusomatic pipeline. inputList &lt;- list(tbam = tbam, nbam = nbam, ensemble = as.list(ensemble), ovcf = as.list(paste0(names(tbam), &quot;_neusomtic.vcf&quot;))) paramList &lt;- list(ref = ref, region = &quot;apps/variants/vcf/intval.bed&quot;, threads = 16) res16 &lt;- runCWLBatch(neusomatic, outdir = &quot;apps/variants/neusomatic&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;mem.q&quot;, jobname = &quot;neusomatic&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) That‚Äôs it! Here are the finnal results: dir_info(&quot;apps/variants/neusomatic&quot;, glob = &quot;*.vcf&quot;, recurse = TRUE) %&gt;% select(path, size) ## # A tibble: 2 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::bytes&gt; ## 1 apps/variants/neusomatic/pt19/pt19_neusomtic.vcf 19.18K ## 2 apps/variants/neusomatic/pt20/pt20_neusomtic.vcf 8.84K 6.3.10 Combined somatic caller pipeline We combined the previous multiple callers into a ensemble pipeline SomaticCallers. The detailed inputs, outputs and steps can be visualized by plotCWL. plotCWL(SomaticCallers) The ensemble callers can be performed in parallel by samples. We can use the same inputs to run all the tools in one batch. inputList &lt;- list(tbam = tbam, nbam = nbam) paramList &lt;- list(Ref = ref, interval = &quot;apps/variants/vcf/intval.bed&quot;, dbsnp = dbsnp, gresource = &quot;apps/data/Mutect2/af-only-gnomad.raw.sites.b37.vcf&quot;, comvcf = &quot;apps/data/Mutect2/GetPileupSummaries/small_exac_common_3_b37.vcf&quot;, pon = &quot;apps/variants/mutect2/pon.vcf&quot;, threads = 16) res17 &lt;- runCWLBatch(SomaticCallers, outdir = &quot;apps/variants/combined&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;mem.q&quot;, jobname = &quot;combined&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) Here are the final results: list.files(&quot;apps/variants/combined/pt19&quot;) ## [1] &quot;Consensus.sINDEL.vcf&quot; ## [2] &quot;Consensus.sSNV.vcf&quot; ## [3] &quot;Ensemble.sINDEL.tsv&quot; ## [4] &quot;Ensemble.sSNV.tsv&quot; ## [5] &quot;Ensemble.sVar.tsv&quot; ## [6] &quot;normal19.tumor19.ctfiltered.obfiltered.PASS.vcf&quot; ## [7] &quot;normal19.tumor19.ctfiltered.obfiltered.vcf&quot; ## [8] &quot;somatic.indels.vcf.gz&quot; ## [9] &quot;somatic.indels.vcf.gz.tbi&quot; ## [10] &quot;somatic.snvs.vcf.gz&quot; ## [11] &quot;somatic.snvs.vcf.gz.tbi&quot; ## [12] &quot;t.contamination.table&quot; ## [13] &quot;tumor19_LoFreq.vcfsomatic_final_minus-dbsnp.indels.vcf.gz&quot; ## [14] &quot;tumor19_LoFreq.vcfsomatic_final_minus-dbsnp.snvs.vcf.gz&quot; ## [15] &quot;tumor19_LoFreq.vcfsomatic_final.indels.vcf.gz&quot; ## [16] &quot;tumor19_LoFreq.vcfsomatic_final.snvs.vcf.gz&quot; ## [17] &quot;tumor19_MuSE.vcf&quot; ## [18] &quot;tumor19_neusomatic.vcf&quot; ## [19] &quot;tumor19_SomaticSniper.vcf&quot; ## [20] &quot;tumor19_VarDict.vcf&quot; ## [21] &quot;tumor19.art.pre_adapter_detail_metrics.txt&quot; ## [22] &quot;tumor19.indel.vcf&quot; ## [23] &quot;tumor19.normal19.somatic.vcf&quot; ## [24] &quot;tumor19.snp.vcf&quot; 6.4 Structural variation 6.4.1 Structural variation Engine 6.5 Copy number variation 6.5.1 cnvkit "],
["rna-seq-alignment-and-quantification.html", "Chapter 7 RNA-Seq alignment and quantification 7.1 bulk mRNA 7.2 transcriptome quantification 7.3 single cell RNAseq 7.4 miRNA", " Chapter 7 RNA-Seq alignment and quantification library(RcwlPipelines) library(BiocParallel) library(fs) library(dplyr) library(conflicted) ## always use select from dplyr conflict_prefer(&quot;select&quot;, &quot;dplyr&quot;, quiet = TRUE) 7.1 bulk mRNA The rnaseq_Sf pipeline was built with reads quality summary, STAR alignment, quantification by featureCounts and RSeQC quality control. Here are the inputs: inputs(rnaseq_Sf) ## inputs: ## in_seqfiles (File[]): ## in_prefix (string): ## in_genomeDir (Directory): ## in_GTFfile (File): ## in_runThreadN (int): 1 The pipeline includes 6 steps: fastqc: To run quality summary for raw fastqs with fastqc. STAR: To align fastqs with STAR. samtools_index: To index aligned bam file. samtools_flagstat: To summarize alignment flags. featureCounts: To quantify gene abundances. RSeQC: Several steps included. gtfToGenePred: To convert GTF annotation to ‚ÄúgenePred‚Äù format. genePredToBed: To convert ‚ÄúgenePred‚Äù annotation to ‚Äúbed‚Äù format. r_distribution: To summarize reads distribution over genome features. gCoverage: To summarize read coverage over gene body. The outputs and logs from alignment, quantification and QC steps are collected together into the output folder. A final QC report could be generated by multiqc, which is also available in the data package. Here are the short summary and steps plot: short(rnaseq_Sf) ## inputs: ## - in_seqfiles ## - in_prefix ## - in_genomeDir ## - in_GTFfile ## - in_runThreadN ## outputs: ## - out_fastqc ## - out_BAM ## - out_Log ## - out_Count ## - out_stat ## - out_count ## - out_distribution ## - out_gCovP ## - out_gCovT ## steps: ## - fastqc ## - STAR ## - sortBam ## - samtools_index ## - samtools_flagstat ## - featureCounts ## - gtfToGenePred ## - genePredToBed ## - r_distribution ## - gCoverage plotCWL(rnaseq_Sf) 7.1.1 Prepare data An RNASeq test data set can be downloaded from genomedata, which includes paired-end fastqs for 6 samples. download.file(&quot;http://genomedata.org/rnaseq-tutorial/HBR_UHR_ERCC_ds_5pc.tar&quot;, &quot;apps/RNASeq/data/HBR_UHR_ERCC_ds_5pc.tar) untar(&quot;apps/RNASeq/data/HBR_UHR_ERCC_ds_5pc.tar&quot;, exdir = &quot;apps/RNASeq/data/&quot;) The input data must be in a named list, with the same names as the input list of the pipeline. For this pipeline, 5 inputs are required to be set, including in_seqfiles, in_prefix, in_genomeDir, in_GTFfile and in_runThreadN. There are two different input lists, inputList and paramList. The inputList is used to define the inputs for each sample and will be submitted to different cluster nodes. The paramList is used to define parameters which are shared in all jobs. Two following inputs should be listed in inputList: in_seqfiles: A list with the fastq files of each sample in each element. The names of the list are also required to be defined and can be the sample IDs. The length of the list will be the same as the number of samples, thus the list will be defined to inputList and assigned to different nodes for parallel computing. in_prefix is the same as in_seqfiles, which defines a list of sample IDs. files &lt;- normalizePath(list.files(&quot;apps/RNASeq/data/&quot;, &quot;.gz&quot;, full.names = TRUE)) files &lt;- tapply(files, substring(basename(files), 1, 8), as.list) inputList &lt;- list(in_seqfiles = files, in_prefix = as.list(names(files))) These 3 parameter will be defined in paramList: in_genomeDir: The reference genome indexes for STAR. in_GTFfile: The gene annotation file in GTF format. in_runThreadN: The number of threads to run for each job. paramList &lt;- list( in_genomeDir = &quot;apps/data/GRCh38_100/&quot;, in_GTFfile = &quot;apps/data/gencode.v25.annotation.gtf&quot;, in_runThreadN = 4 ) In some cases, we need to modify the default arguments in some steps of a pipeline. For example, arguments(rnaseq_Sf, &quot;STAR&quot;)[[2]] &lt;- &quot;2&quot; head(arguments(rnaseq_Sf, &quot;STAR&quot;)) ## [[1]] ## [1] &quot;--outFilterMultimapNmax&quot; ## ## [[2]] ## [1] &quot;2&quot; ## ## [[3]] ## [1] &quot;--outSAMunmapped&quot; ## ## [[4]] ## [1] &quot;Within&quot; ## ## [[5]] ## [1] &quot;--outFilterMismatchNmax&quot; ## ## [[6]] ## [1] &quot;2&quot; 7.1.2 Submit pipeline with SGE The function runCWLBatch is used to submit the pipeline to cluster server. In addition to defining inputList and paramList, we need to define parallel parameters from the BiocParallel package. Here is an example where we use ‚Äúsge‚Äù to submit the jobs. The ‚Äúsge‚Äù template is a bash script with some predefined parameters for ‚Äúqsub‚Äù. The nodes queue name and number of slots/threads are variables from the template and can be assigned by the resources list. res &lt;- runCWLBatch(cwl = rnaseq_Sf, outdir = &quot;apps/RNASeq/output/&quot;, inputList = inputList, paramList = paramList, BPPARAM = BatchtoolsParam( workers = lengths(inputList)[1], cluster = &quot;sge&quot;, template = &quot;apps/data/sge_centos7.tmpl&quot;, resources = list(queue = &quot;centos7.q&quot;, threads = 4))) That‚Äôs it! The fastqc files of each sample will be submitted to different nodes to run the whole pipeline automatically. All the results have been collected to output directory of each sample. For example, dir(&quot;apps/RNASeq/output/HBR_Rep1&quot;) ## [1] &quot;abundance.h5&quot; ## [2] &quot;abundance.tsv&quot; ## [3] &quot;HBR_Rep1_abundance.tsv&quot; ## [4] &quot;HBR_Rep1_ERCC-Mix2_Build37-ErccTranscripts-chr22.read1_fastqc.zip&quot; ## [5] &quot;HBR_Rep1_ERCC-Mix2_Build37-ErccTranscripts-chr22.read2_fastqc.zip&quot; ## [6] &quot;HBR_Rep1Aligned.sortedByCoord.out.bam&quot; ## [7] &quot;HBR_Rep1Aligned.sortedByCoord.out.bam.bai&quot; ## [8] &quot;HBR_Rep1Aligned.sortedByCoord.out.distribution.txt&quot; ## [9] &quot;HBR_Rep1Aligned.sortedByCoord.out.featureCounts.txt&quot; ## [10] &quot;HBR_Rep1Aligned.sortedByCoord.out.featureCounts.txt.summary&quot; ## [11] &quot;HBR_Rep1Aligned.sortedByCoord.out.flagstat.txt&quot; ## [12] &quot;HBR_Rep1Aligned.sortedByCoord.out.geneBodyCoverage.curves.pdf&quot; ## [13] &quot;HBR_Rep1Aligned.sortedByCoord.out.geneBodyCoverage.txt&quot; ## [14] &quot;HBR_Rep1Log.final.out&quot; ## [15] &quot;HBR_Rep1ReadsPerGene.out.tab&quot; ## [16] &quot;run_info.json&quot; 7.1.3 QC Summary The tool ‚Äúmultiqc‚Äù can aggregate results from the multiple outputs of the pipeline and generate a single page report, which also was implemented in the RcwlPipelines package: multiqc$dir &lt;- &quot;apps/RNASeq/output&quot; multiqc We can also run the tool using Rcwl locally with the option docker = TRUE: runCWL(multiqc, stderr = &quot;&quot;, Args = &quot;--preserve-entire-environment&quot;, docker = FALSE) 7.1.4 Abundances summary The R/Bioconductor package edgeR can be used to calculate the RPKM and CPM abundances. countfiles &lt;- list.files(&quot;apps/RNASeq/output&quot;, &quot;out.featureCounts.txt$&quot;, recursive = TRUE, full.names = TRUE) samples &lt;- basename(dirname(countfiles)) rExp &lt;- function(countfile){ count1 &lt;- read.table(countfile, header = TRUE)[, c(1,6,7)] rpkm1 &lt;- edgeR::rpkm(count1[,3,drop=F], gene.length = count1$Length) cpm1 &lt;- edgeR::cpm(count1[,3]) count1 &lt;- data.frame(count1, rpkm1, cpm1) colnames(count1)[3:5] &lt;- c(&quot;count&quot;, &quot;rpkm&quot;, &quot;cpm&quot;) return(count1) } head(rExp(countfiles[1])) ## Geneid Length count rpkm cpm ## 1 ENSG00000223972.5 1735 0 0 0 ## 2 ENSG00000227232.5 1351 0 0 0 ## 3 ENSG00000278267.1 68 0 0 0 ## 4 ENSG00000243485.4 1021 0 0 0 ## 5 ENSG00000237613.2 1219 0 0 0 ## 6 ENSG00000268020.3 840 0 0 0 for(i in 1:length(samples)) { exp1 &lt;- rExp(countfiles[i]) write.table(exp1, file = paste0(&quot;apps/RNASeq/output/&quot;, samples[i], &quot;/&quot;, samples[i], &quot;_abundance.tsv&quot;), row.names = FALSE, quote = FALSE, sep = &quot;\\t&quot;) } We can also easily wrap the R function to a cwlParam object. rExp &lt;- function(countfile){ count1 &lt;- read.table(countfile, header = TRUE)[, c(1,6,7)] rpkm1 &lt;- edgeR::rpkm(count1[,3,drop=F], gene.length = count1$Length) cpm1 &lt;- edgeR::cpm(count1[,3]) count1 &lt;- data.frame(count1, rpkm1, cpm1) colnames(count1)[3:5] &lt;- c(&quot;count&quot;, &quot;rpkm&quot;, &quot;cpm&quot;) write.table(exp1, file = paste0(tools::file_path_sans_ext(basename(countfile)), &quot;_abundance.tsv&quot;), row.names = FALSE, quote = FALSE, sep = &quot;\\t&quot;) } p1 &lt;- InputParam(id = &quot;countfile&quot;, type = &quot;File&quot;, prefix = &quot;countfile=&quot;, separate = FALSE) o1 &lt;- OutputParam(id = &quot;exp&quot;, type = &quot;File&quot;, glob = &quot;*abundance.tsv&quot;) rExpr &lt;- cwlParam(baseCommand = rExp, inputs = InputParamList(p1), outputs = OutputParamList(o1)) countfiles &lt;- as.list(countfiles) names(countfiles) &lt;- samples inputList &lt;- list(countfile = countfiles) res1 &lt;- runCWLBatch(rExpr, outdir = &quot;apps/RNASeq/output&quot;, inputList, BPPARAM = BatchtoolsParam(workers = length(samples), cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;Exp&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) 7.2 transcriptome quantification There are many tools available for transcriptome quantification, such as kallisto, StringTie, salmon, Trinity and so on. 7.2.1 Kallisto The kallisto is a tool for quantifying abundances of transcripts with raw fastq reads and indexed reference transcriptomes. The kallisto_index is used to build an index file from reference transcriptome fasta. kallisto_index$fasta &lt;- &quot;apps/data/gencode.v25.transcripts.fa&quot; kallisto_index$index &lt;- &quot;gencode.v25.transcripts_kallisto&quot; runCWL(kallisto_index, outdir = &quot;apps/data/&quot;, stderr = &quot;&quot;) The kallisto_quant runs the quantification algorithm to estimate the transcripts expression abundances. inputList &lt;- list(fastq = files) paramList &lt;- list(index = &quot;apps/data/gencode.v25.transcripts_kallisto&quot;, threads = 16) res2 &lt;- runCWLBatch(kallisto_quant, outdir = &quot;apps/RNASeq/output&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = length(samples), cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;kallisto&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) Here are the results: list.files(&quot;apps/RNASeq/output/HBR_Rep1&quot;, &quot;abundance&quot;) ## [1] &quot;abundance.h5&quot; &quot;abundance.tsv&quot; ## [3] &quot;HBR_Rep1_abundance.tsv&quot; 7.3 single cell RNAseq 7.4 miRNA The miRDeep2 is one of the popular tools for discovering known and novel miRNAs from small RNA sequencing data. We wrapped the mapping and quantification steps into miRDeep2PL. Here is the instructions for miRDeep2: https://github.com/rajewsky-lab/mirdeep2. plotCWL(miRDeep2PL) We use the data from mirdeep2 github repository as an example. https://github.com/rajewsky-lab/mirdeep2/tree/master/tutorial_dir list.files(&quot;apps/miRNA/tutorial_dir&quot;) ## [1] &quot;cel_cluster.fa&quot; &quot;mature_ref_other_species.fa&quot; ## [3] &quot;mature_ref_this_species.fa&quot; &quot;precursors_ref_this_species.fa&quot; ## [5] &quot;reads_collapsed.fa&quot; &quot;reads.fa&quot; ## [7] &quot;run_tut.sh&quot; &quot;sample_result.html&quot; 7.4.1 Prepare reference First, we need to build indexes for the miRNA reference with bowtie-build. This is only required to be performed once for each refernce genome. bowtie_build$ref &lt;- &quot;apps/miRNA/tutorial_dir/cel_cluster.fa&quot; bowtie_build$outPrefix &lt;- &quot;cel_cluster&quot; idxRes &lt;- runCWL(bowtie_build, outdir = &quot;apps/miRNA/output/genome&quot;, stderr = &quot;&quot;) file.copy(&quot;apps/miRNA/tutorial_dir/cel_cluster.fa&quot;, &quot;apps/miRNA/output/genome/cel_cluster.fa&quot;) Here are the indexed reference files. dir_info(&quot;apps/miRNA/output/genome&quot;) %&gt;% select(path, size) ## # A tibble: 7 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::bytes&gt; ## 1 apps/miRNA/output/genome/cel_cluster.1.ebwt 4M ## 2 apps/miRNA/output/genome/cel_cluster.2.ebwt 812 ## 3 apps/miRNA/output/genome/cel_cluster.3.ebwt 26 ## 4 apps/miRNA/output/genome/cel_cluster.4.ebwt 1.57K ## 5 apps/miRNA/output/genome/cel_cluster.fa 6.47K ## 6 apps/miRNA/output/genome/cel_cluster.rev.1.ebwt 4M ## 7 apps/miRNA/output/genome/cel_cluster.rev.2.ebwt 812 7.4.2 Run miRDeep2 pipeline First we need to prepare the inputs into ‚ÄòinputList‚Äô and ‚ÄòparamList‚Äô for parallel execution. inputs(miRDeep2PL) ## inputs: ## reads (File): ## format (string): -c ## adapter (string): ## len (int): 18 ## genome (File): ## miRef ( File|string ): ## miOther ( File|string ): ## precursors ( File|string ): ## species (string): To mimic multiple samples analysis, here we just repeat to use the input reads. reads &lt;- list(sample1 = &quot;apps/miRNA/tutorial_dir/reads.fa&quot;, sample2 = &quot;apps/miRNA/tutorial_dir/reads.fa&quot;) inputList &lt;- list(reads = reads) paramList &lt;- list(adapter = &quot;TCGTATGCCGTCTTCTGCTTGT&quot;, genome = &quot;apps/miRNA/output/genome/cel_cluster.fa&quot;, miRef = &quot;apps/miRNA/tutorial_dir/mature_ref_this_species.fa&quot;, miOther = &quot;apps/miRNA/tutorial_dir/mature_ref_other_species.fa&quot;, precursors = &quot;apps/miRNA/tutorial_dir/precursors_ref_this_species.fa&quot;, species = &quot;C.elegans&quot;) Let‚Äôs run the pipeline with two computing nodes. mirRes &lt;- runCWLBatch(miRDeep2PL, outdir = &quot;apps/miRNA/output/&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(jobname = &quot;miRNA&quot;, queue = &quot;all.q&quot;, threads = 2), log=TRUE, logdir=&quot;.&quot;, progressbar = T), stderr = &quot;&quot;) Here are the results: dir_info(&quot;apps/miRNA/output/sample1&quot;) %&gt;% select(path, size) ## # A tibble: 10 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::byte&gt; ## 1 apps/miRNA/output/sample1/expression_26_09_2019_t_20_10_36.h‚Ä¶ 21.15K ## 2 apps/miRNA/output/sample1/expression_analyses 4K ## 3 apps/miRNA/output/sample1/miRNAs_expressed_all_samples_26_09‚Ä¶ 441 ## 4 apps/miRNA/output/sample1/mirna_results_26_09_2019_t_20_10_36 4K ## 5 apps/miRNA/output/sample1/pdfs_26_09_2019_t_20_10_36 4K ## 6 apps/miRNA/output/sample1/reads_collapsed.arf 61.36K ## 7 apps/miRNA/output/sample1/reads_collapsed.fa 59.31K ## 8 apps/miRNA/output/sample1/result_26_09_2019_t_20_10_36.bed 747 ## 9 apps/miRNA/output/sample1/result_26_09_2019_t_20_10_36.csv 4.39K ## 10 apps/miRNA/output/sample1/result_26_09_2019_t_20_10_36.html 42.73K "],
["neoantigen-prediction.html", "Chapter 8 Neoantigen prediction 8.1 Input file preparation 8.2 HLA typing 8.3 Neoantigen prediction by pVACseq", " Chapter 8 Neoantigen prediction The ‚ÄúpVACseq‚Äù toolkit is a comprehensive cancer immunotherapy pipeline for identification of personalized variant antigens by integrating with DNA mutations and mRNA expression data to filter and rank candicate neoepitopes. The ‚ÄúPOLYSOLVER‚Äù or ‚ÄúOptitype‚Äù is a tool for HLA typing. It can be used to limit the list of alleles. The full pipeline is shown as follows. Three major steps are built to run the full pipeline, including DNA variant calling, variant annotation and neoantigen prediction. DNA variant calling: somatic and germline variant calling Variant annotation: Adding DNA and RNA allele frequencies, transcript and gene level expressions. Neoantigen prediction: HLA typing, neoantigen filtering and ranking First of all, load the required packages. library(RcwlPipelines) library(BiocParallel) suppressPackageStartupMessages(library(VariantAnnotation)) library(fs) library(dplyr) library(conflicted) ## always use select from dplyr conflict_prefer(&quot;select&quot;, &quot;dplyr&quot;, quiet = TRUE) 8.1 Input file preparation 8.1.1 Annotating VCF First, we need to annotate somatic mutations using the tool ‚Äúvep‚Äù with ‚ÄúDownstream‚Äù and ‚ÄúWildtype‚Äù plugins. A cache of annotation sources is recommended to use ‚ÄúVEP‚Äù in the fastest and most efficient way. http://useast.ensembl.org/info/docs/tools/vep/script/vep_cache.html ref &lt;- &quot;apps/data/hs37d5.fa&quot; vcfs &lt;- as.list(list.files(&quot;apps/variants/combined&quot;, &quot;.neusomatic.vcf&quot;, recursive = TRUE, full.names = TRUE)) names(vcfs) &lt;- c(&quot;pt19&quot;, &quot;pt20&quot;) ovcfs &lt;- as.list(paste0(names(vcfs), &quot;_vep.vcf&quot;)) inputList &lt;- list(ivcf = vcfs, ovcf = ovcfs) paramList &lt;- list(ref = ref, cacheDir = &quot;~/.vep&quot;) res1 &lt;- runCWLBatch(vep, outdir = &quot;apps/variants/neoantigen&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;vep&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) Here are the annotated VCFs. dir_info(&quot;apps/variants/neoantigen&quot;, recurse = TRUE, glob = &quot;*vep.vcf&quot;) %&gt;% dplyr::select(path, size) ## # A tibble: 2 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::bytes&gt; ## 1 apps/variants/neoantigen/pt19/pt19_vep.vcf 642K ## 2 apps/variants/neoantigen/pt20/pt20_vep.vcf 217K 8.1.2 Adding coverage This step use bam-readcount to to retrieve the number of reads in given VCF positions. Then vcf-readcount-annotator is used to add the read counts for snvs and indels to the input VCF file. plotCWL(vcfCoverage) Let‚Äôs prepare the inputs for DNA samples and run the vcfCoverage pipeline. vcfs &lt;- as.list(list.files(&quot;apps/variants/neoantigen&quot;, &quot;*vep.vcf&quot;, recursive = TRUE, full.names = TRUE)) bams &lt;- as.list(list.files(&quot;apps/variants/BAM&quot;, &quot;tumor.*.bam$&quot;, recursive = TRUE, full.names = TRUE)) samples &lt;- as.list(c(&quot;SAMPLE&quot;, &quot;SAMPLE&quot;)) names(vcfs) &lt;- names(bams) &lt;- names(samples) &lt;- c(&quot;pt19&quot;, &quot;pt20&quot;) inputList &lt;- list(vcf = vcfs, sample = samples, bam = bams) paramList &lt;- list(ref = ref) res2 &lt;- runCWLBatch(vcfCoverage, outdir = &quot;apps/variants/neoantigen&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;coverage&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) The Allelic depths, ‚ÄúAD‚Äù, for the ref and alt alleles were added to the VCF file. vcf1 &lt;- readVcf(&quot;apps/variants/neoantigen/pt19/pt19_vep_dc_snv_indel.vcf&quot;) geno(vcf1) ## List of length 6 ## names(6): GT RO AO DP AD AF do.call(rbind, head(geno(vcf1)$AD)) ## [,1] [,2] ## [1,] 34 8 ## [2,] 37 11 ## [3,] 20 19 ## [4,] 32 16 ## [5,] 6 4 ## [6,] 18 18 We also could run the pipeline for RNA samples with ‚Äúntype=‚ÄòRNA‚Äô‚Äù. Here we don‚Äôt have their RNA BAM files, so the DNA BAM files are used for demonstration. vcfs &lt;- as.list(list.files(&quot;apps/variants/neoantigen&quot;, &quot;*vep_dc_snv_indel.vcf&quot;, recursive = TRUE, full.names = TRUE)) bams &lt;- as.list(list.files(&quot;apps/variants/BAM&quot;, &quot;tumor.*.bam$&quot;, recursive = TRUE, full.names = TRUE)) samples &lt;- as.list(c(&quot;SAMPLE&quot;, &quot;SAMPLE&quot;)) names(vcfs) &lt;- names(bams) &lt;- names(samples) &lt;- c(&quot;pt19&quot;, &quot;pt20&quot;) inputList &lt;- list(vcf = vcfs, sample = samples, bam = bams) paramList &lt;- list(ref = ref, ntype = &quot;RNA&quot;) res2a &lt;- runCWLBatch(vcfCoverage, outdir = &quot;apps/variants/neoantigen&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;coverage&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) The Allelic depths, ‚ÄúRAD‚Äù, for the ref and alt alleles were added to the VCF file. vcf1a &lt;- readVcf(&quot;apps/variants/neoantigen/pt19/pt19_vep_dc_snv_indel_dc_snv_indel.vcf&quot;) geno(vcf1a) ## List of length 9 ## names(9): GT RO AO DP AD AF RDP RAD RAF 8.1.3 Adding expression For demostration purpose, we use the same DNA fastq files as RNASeq inputs for transcriptome quantification with kallisto_quant. fqs &lt;- list.files(&quot;apps/variants/fastq&quot;, recursive = TRUE, full.names = TRUE) fqs &lt;- fqs[grep(&quot;tumor&quot;, fqs)] fqL &lt;- tapply(fqs, rep(c(&quot;pt19&quot;, &quot;pt20&quot;), each = 2), as.list) inputList &lt;- list(fastq = fqL) paramList &lt;- list(index = &quot;apps/data/gencode.v25.transcripts_kallisto&quot;, threads = 16) res3 &lt;- runCWLBatch(kallisto_quant, outdir = &quot;apps/variants/neoantigen&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = length(samples), cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;kallisto&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) The tool vcf_expression_annotator can be used to parse gene or transcript expression results and add to a given VCF. The abundance tables from kallisto quant have full transcript IDs with gene IDs annotation in the ‚Äútarget_id‚Äù column. We need to clean the ‚Äútarge_id‚Äù column by removing the annotation parts other than ‚Äútranscript_id‚Äù. cleanExp &lt;- function(afile) { exp1 &lt;- read.table(afile, header = TRUE, stringsAsFactors = FALSE) exp1[,1] &lt;- sub(&quot;\\\\|ENSG.*&quot;, &quot;&quot;, exp1[,1]) write.table(exp1, file = &quot;abundance_clean.tsv&quot;, row.names = FALSE, quote = FALSE, sep = &quot;\\t&quot;) } p1 &lt;- InputParam(id = &quot;afile&quot;, type = &quot;File&quot;, prefix = &quot;afile=&quot;, separate = FALSE) o1 &lt;- OutputParam(id = &quot;aout&quot;, type = &quot;File&quot;, glob = &quot;abundance_clean.tsv&quot;) CleanExp &lt;- cwlParam(baseCommand = cleanExp, inputs = InputParamList(p1), outputs = OutputParamList(o1)) exps &lt;- as.list(list.files(&quot;apps/variants/neoantigen&quot;, &quot;abundance.tsv&quot;, recursive = TRUE, full.names = TRUE)) names(exps) &lt;- c(&quot;pt19&quot;, &quot;pt20&quot;) inputList &lt;- list(afile = exps) res4 &lt;- runCWLBatch(CleanExp, outdir = &quot;apps/variants/neoantigen&quot;, inputList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;vep&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) Then the cleaned abundance file can be used to add expression values to the VEP annotated VCF file using the tool vcf_expression_annotator. vcfs &lt;- as.list(list.files(&quot;apps/variants/neoantigen&quot;, &quot;*indel_dc_snv_indel.vcf&quot;, recursive = TRUE, full.names = TRUE)) exps &lt;- as.list(list.files(&quot;apps/variants/neoantigen&quot;, &quot;abundance_clean.tsv&quot;, recursive = TRUE, full.names = TRUE)) ovcf &lt;- list(&quot;pt19_Ann.vcf&quot;, &quot;pt20_Ann.vcf&quot;) names(vcfs) &lt;- names(exps) &lt;- names(ovcf) &lt;- c(&quot;pt19&quot;, &quot;pt20&quot;) inputList &lt;- list(ivcf = vcfs, expression = exps, ovcf = ovcf) paramList &lt;- list(etype = &quot;kallisto&quot;, gtype = &quot;transcript&quot;) res5 &lt;- runCWLBatch(vcf_expression_annotator, outdir = &quot;apps/variants/neoantigen&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;vep&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) The transcript expression values, ‚ÄúTX‚Äù, were added to the VCF file. vcf2 &lt;- readVcf(&quot;apps/variants/neoantigen/pt19/pt19_Ann.vcf&quot;) geno(vcf2) ## List of length 7 ## names(7): GT RO AO DP AD AF TX geno(vcf2)$TX[[1]] ## [1] &quot;ENST00000264554|31.1948&quot; &quot;ENST00000590113|203.734&quot; ## [3] &quot;ENST00000590170|41.8456&quot; &quot;ENST00000590222|101.681&quot; The gene level expression library(tximport) t2gene &lt;- function(kexp){ e1 &lt;- read.table(kexp, header = TRUE, check.names = FALSE, stringsAsFactors = FALSE, sep = &quot;\\t&quot;) ids &lt;- do.call(rbind, base::strsplit(e1$target_id, split = &quot;\\\\|&quot;)) tx2gene &lt;- data.frame(ids[,1:2]) gexp &lt;- tximport::tximport(kexp, type = &quot;kallisto&quot;, tx2gene = tx2gene, ignoreAfterBar=TRUE) gExp &lt;- data.frame(gene = sub(&quot;\\\\..*&quot;, &quot;&quot;, rownames(gexp$abundance)), abundance = gexp$abundance) write.table(gExp, file = &quot;abundance_gene.tsv&quot;, row.names = FALSE, col.names = TRUE, quote = FALSE, sep = &quot;\\t&quot;) } p1 &lt;- InputParam(id = &quot;kexp&quot;, type = &quot;File&quot;, prefix = &quot;kexp=&quot;, separate = FALSE) o1 &lt;- OutputParam(id = &quot;gout&quot;, type = &quot;File&quot;, glob = &quot;abundance_gene.tsv&quot;) T2Gene &lt;- cwlParam(baseCommand = t2gene, inputs = InputParamList(p1), outputs = OutputParamList(o1)) ## run exps &lt;- as.list(list.files(&quot;apps/variants/neoantigen&quot;, &quot;abundance.tsv&quot;, recursive = TRUE, full.names = TRUE)) names(exps) &lt;- c(&quot;pt19&quot;, &quot;pt20&quot;) inputList &lt;- list(kexp = exps) res4g &lt;- runCWLBatch(T2Gene, outdir = &quot;apps/variants/neoantigen&quot;, inputList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;vep&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) Let‚Äôs annotate the VCFs with gene level expression values. vcfs &lt;- as.list(list.files(&quot;apps/variants/neoantigen&quot;, &quot;_Ann.vcf$&quot;, recursive = TRUE, full.names = TRUE)) exps &lt;- as.list(list.files(&quot;apps/variants/neoantigen&quot;, &quot;abundance_gene.tsv&quot;, recursive = TRUE, full.names = TRUE)) ovcf &lt;- list(&quot;pt19_ANN.vcf&quot;, &quot;pt20_ANN.vcf&quot;) names(vcfs) &lt;- names(exps) &lt;- names(ovcf) &lt;- c(&quot;pt19&quot;, &quot;pt20&quot;) inputList &lt;- list(ivcf = vcfs, expression = exps, ovcf = ovcf) paramList &lt;- list(etype = &quot;custom&quot;, gtype = &quot;gene&quot;, idCol = &quot;gene&quot;, expCol = &quot;abundance&quot;) res5g &lt;- runCWLBatch(vcf_expression_annotator, outdir = &quot;apps/variants/neoantigen&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;vep&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) The steps were also combined into an expression annotation pipelines, vcfExpression. By given RNASeq raw reads, the transcript expression levels will be added to the corresponding variants in the ‚Äúvep‚Äù annotated VCFs. plotCWL(vcfExpression) 8.1.4 Creating a phased VCF The germline variants and somatic variants were combined and phased in this step to calculated wildtype and mutant protein sequences more accurately. The picard and GATK tools were used to rename, combine, sort and phase the variants. plotCWL(phaseVcf) To create the pahsed VCF. svcfs &lt;- list(pt19 = &quot;apps/variants/neoantigen/pt19/pt19_Ann.vcf.gz&quot;, pt20 = &quot;apps/variants/neoantigen/pt20/pt20_Ann.vcf.gz&quot;) gvcfs &lt;- list(pt19 = &quot;apps/variants/vcf/res/output/germline.vcf.gz&quot;, pt20 = &quot;apps/variants/vcf/res/output/germline.vcf.gz&quot;) bam &lt;- list(pt19 = &quot;apps/variants/BAM/tumor19/tumor19.bam&quot;, pt20 = &quot;apps/variants/BAM/tumor20/tumor20.bam&quot;) outvcf &lt;- list(pt19 = &quot;pt19_phased.vcf&quot;, pt20 = &quot;pt20_phased.vcf&quot;) nsamples &lt;- list(&quot;normal19&quot;, &quot;normal20&quot;) tsamples &lt;- list(&quot;tumor19&quot;, &quot;tumor20&quot;) inputList &lt;- list(gvariant = gvcfs, svariant = svcfs, bam = bam, outvcf = outvcf, nsample = nsamples, tsample = tsamples) paramList &lt;- list(ref = ref) res6 &lt;- runCWLBatch(phaseVcf, outdir = &quot;apps/variants/neoantigen&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;phase&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) The phased VCF file using HP tags to link alleles. Here are the phased VCFs. dir_info(&quot;apps/variants/neoantigen&quot;, recurse = TRUE, glob = &quot;*phased.vcf*&quot;) %&gt;% dplyr::select(path, size) ## # A tibble: 4 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::bytes&gt; ## 1 apps/variants/neoantigen/pt19/tumor19_phased.vcf.gz 4.84M ## 2 apps/variants/neoantigen/pt19/tumor19_phased.vcf.gz.tbi 31.92K ## 3 apps/variants/neoantigen/pt20/tumor20_phased.vcf.gz 4.3M ## 4 apps/variants/neoantigen/pt20/tumor20_phased.vcf.gz.tbi 34.06K 8.1.5 Combined VCF preparing pipeline The previous 4 annotation steps have been intergrated into one VCF annotation pipeline. Thus all the required inputs can be prepared in just one step. plotCWL(AnnPhaseVcf) Here are the example to run the annotation and phasing pipeline. svcfs &lt;- as.list(list.files(&quot;apps/variants/combined&quot;, &quot;.neusomatic.vcf&quot;, recursive = TRUE, full.names = TRUE)) names(svcfs) &lt;- c(&quot;pt19&quot;, &quot;pt20&quot;) gvcfs &lt;- list(pt19 = &quot;apps/variants/vcf/res/output/germline.vcf.gz&quot;, pt20 = &quot;apps/variants/vcf/res/output/germline.vcf.gz&quot;) bam &lt;- list(pt19 = &quot;apps/variants/BAM/tumor19/tumor19.bam&quot;, pt20 = &quot;apps/variants/BAM/tumor20/tumor20.bam&quot;) ## use rnaseq BAM instead rbam &lt;- list(pt19 = &quot;apps/variants/BAM/tumor19/tumor19.bam&quot;, pt20 = &quot;apps/variants/BAM/tumor20/tumor20.bam&quot;) fqs &lt;- list.files(&quot;apps/variants/fastq&quot;, recursive = TRUE, full.names = TRUE) fqs &lt;- fqs[grep(&quot;tumor&quot;, fqs)] fqL &lt;- tapply(fqs, rep(c(&quot;pt19&quot;, &quot;pt20&quot;), each = 2), as.list) nsamples &lt;- list(&quot;normal19&quot;, &quot;normal20&quot;) tsamples &lt;- list(&quot;tumor19&quot;, &quot;tumor20&quot;) inputList &lt;- list(gvcf = gvcfs, svcf = svcfs, tbam = bam, nsample = nsamples, tsample = tsamples, rnaseqs = fqL, rbam = rbam) paramList &lt;- list(ref = ref, VepDir = &quot;~/.vep/&quot;, kallistoIdx = &quot;apps/data/gencode.v25.transcripts_kallisto&quot;, threads = 16) res7 &lt;- runCWLBatch(AnnPhaseVcf, outdir = &quot;apps/variants/neoantigen&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;AnnPhase&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) Here are the results: list.files(&quot;apps/variants/neoantigen/pt19&quot;, &quot;vcf.gz&quot;) ## [1] &quot;pt19_Ann.vcf.gz&quot; ## [2] &quot;pt19_Ann.vcf.gz.tbi&quot; ## [3] &quot;tumor19_neusomatic_vep_dc_snv_indel_dc_snv_indel_ExpAnn_gAnn.vcf.gz&quot; ## [4] &quot;tumor19_neusomatic_vep_dc_snv_indel_dc_snv_indel_ExpAnn_gAnn.vcf.gz.tbi&quot; ## [5] &quot;tumor19_neusomatic_vep_dc_snv_indel_ExpAnn.vcf.gz&quot; ## [6] &quot;tumor19_neusomatic_vep_dc_snv_indel_ExpAnn.vcf.gz.tbi&quot; ## [7] &quot;tumor19_phased.vcf.gz&quot; ## [8] &quot;tumor19_phased.vcf.gz.tbi&quot; 8.2 HLA typing 8.2.1 polysolver The polysolver is a tool for HLA typing based on whole exome sequencing data. The details to run the tool can be found: https://software.broadinstitute.org/cancer/cga/polysolver_run. inputList &lt;- list(bam = bam) res8 &lt;- runCWLBatch(polysolver, outdir = &quot;apps/variants/neoantigen&quot;, inputList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;polysolver&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;, cwlTemp = TRUE) 8.2.2 Optitype 8.3 Neoantigen prediction by pVACseq The pvacseq tool take the annotated somatic variants and phased combined variants as inputs. Multiple candidate alleles from hla typing and multiple epitope prediction algorithms can be used. vcfs &lt;- as.list(list.files(&quot;apps/variants/neoantigen&quot;, &quot;gAnn.vcf.gz$&quot;, recursive = TRUE, full.names = TRUE)) pvcfs &lt;- as.list(list.files(&quot;apps/variants/neoantigen&quot;, &quot;phased.vcf.gz$&quot;, recursive = TRUE, full.names = TRUE)) names(vcfs) &lt;- names(pvcfs) &lt;- c(&quot;pt19&quot;, &quot;pt20&quot;) alleles &lt;- list(pt19 = list(&quot;HLA-A*02:01&quot;, &quot;HLA-B*35:01&quot;), pt20 = list(&quot;HLA-A*02:01&quot;, &quot;HLA-B*35:01&quot;, &quot;DRB1*11:01&quot;)) inputList &lt;- list(ivcf = vcfs, phasedVcf = pvcfs, sample = tsamples, allele = alleles) paramList &lt;- list(algorithms = list(&quot;MHCflurry&quot;, &quot;MHCnuggetsI&quot;, &quot;MHCnuggetsII&quot;, &quot;NNalign&quot;, &quot;NetMHC&quot;)) res9 &lt;- runCWLBatch(pvacseq, outdir = &quot;apps/variants/neoantigen&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;pvacseq&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) Here are the filtered and ranked results: list.files(&quot;apps/variants/neoantigen/pt20/pvacseq_out/combined/&quot;) ## [1] &quot;tumor20.all_epitopes.tsv&quot; ## [2] &quot;tumor20.filtered.condensed.ranked.tsv&quot; ## [3] &quot;tumor20.filtered.tsv&quot; neo &lt;- read.table(&quot;apps/variants/neoantigen/pt20/pvacseq_out/combined/tumor20.filtered.condensed.ranked.tsv&quot;, header = TRUE, sep = &quot;\\t&quot;, check.names = FALSE) head(neo) ## Gene Name Mutation Protein Position HGVSc ## 1 GNAS K/M 876 ENST00000371100.4:c.2627A&gt;T ## 2 MACROD2 G/A 59 ENST00000407045.3:c.176G&gt;C ## 3 PLCG1 R/H 886 ENST00000373271.1:c.2657G&gt;A ## 4 RIN2 V/G 564 ENST00000255006.6:c.1691T&gt;G ## 5 SLC4A11 F/S 647 ENST00000380059.3:c.1940T&gt;C ## 6 SLC4A11 S/P 562 ENST00000474451.1:c.1684T&gt;C ## HGVSp HLA Allele Mutation Position ## 1 ENSP00000360141.3:p.Lys876Met HLA-A*02:01 2 ## 2 ENSP00000385516.3:p.Gly59Ala HLA-B*35:01 3 ## 3 ENSP00000362368.1:p.Arg886His HLA-B*35:01 9 ## 4 ENSP00000255006.6:p.Val564Gly DRB1*11:01 10 ## 5 ENSP00000369399.3:p.Phe647Ser HLA-B*35:01 8 ## 6 ENSP00000476859.1:p.Ser562Pro HLA-B*35:01 3 ## MT Epitope Seq Median MT Score Median WT Score Median Fold Change ## 1 RMWIQCFNDV 69.936 9047.261 129.364 ## 2 TPAPDVEM 47.965 276.192 5.758 ## 3 VPACQIAIH 346.080 3384.033 9.778 ## 4 SFMTPEKRMGRRIAE 30.461 19.712 0.647 ## 5 LPIAVLASSL 114.193 55.791 0.489 ## 6 SPPPSSAPM 111.499 11.532 0.103 ## Best MT Score Corresponding WT Score Corresponding Fold Change ## 1 42.920 7634.610 177.880 ## 2 39.085 276.192 7.066 ## 3 225.113 724.975 3.220 ## 4 13.200 12.400 0.939 ## 5 16.548 7.875 0.476 ## 6 52.980 9.080 0.171 ## Tumor DNA Depth Tumor DNA VAF Tumor RNA Depth Tumor RNA VAF ## 1 32 0.344 32 0.344 ## 2 16 0.375 16 0.375 ## 3 41 0.390 41 0.390 ## 4 28 0.393 28 0.393 ## 5 42 0.357 42 0.357 ## 6 42 0.357 42 0.357 ## Gene Expression Rank ## 1 1922.752 1 ## 2 1287.893 2 ## 3 2025.111 3 ## 4 1153.660 4 ## 5 935.994 5 ## 6 935.994 6 "],
["other-sequencing-pipelines.html", "Chapter 9 Other Sequencing pipelines 9.1 ChiP-Seq 9.2 ATAC-Seq 9.3 Microbiome Sequencing", " Chapter 9 Other Sequencing pipelines 9.1 ChiP-Seq 9.2 ATAC-Seq 9.3 Microbiome Sequencing "],
["references.html", "References", " References "]
]
