[
["index.html", "Bioinformatics tools and pipelines using R and CWL Preface 0.1 R package installation 0.2 System requirements 0.3 Docker 0.4 Structure of the book 0.5 R session information", " Bioinformatics tools and pipelines using R and CWL Qiang Hu Qian Liu 2019-09-26 Preface This short book introduces the R packages, Rcwl and RcwlPipelines, to improve the way of building, managing and running Bioinformatics tools and pipelines. The Rcwl package is built on top of the Common Workflow Language (CWL), and provides a simple and user-friendly way to wrap command line tools into data analysis pipelines in R. The RcwlPipelines package is a collection of Bioinformatics tools and pipelines based on Rcwl. 0.1 R package installation The Rcwl and RcwlPipelines packages can be installed from Bioconductor or Github: BiocManager::install(c(&quot;Rcwl&quot;, &quot;RcwlPipelines&quot;)) # or the development version BiocManager::install(c(&quot;hubentu/Rcwl&quot;, &quot;hubentu/RcwlPipelines&quot;)) To load the packages into R session: library(Rcwl) library(RcwlPipelines) 0.2 System requirements In addition to the R packages, the following tools are required to be installed to run the examples in this book. python (&gt;= 2.7) cwltool (&gt;= 1.0.2018) nodejs The cwltool is the reference implementation of the Common Workflow Language, which is used to run the CWL scripts. The nodejs is required when the CWL scripts use JavaScript. You can find instructions to install these tools here: https://github.com/common-workflow-language/cwltool#install https://nodejs.org 0.3 Docker The Docker container simplifies software installation and management, especially for bioinformatics tools/pipelines requiring different runtime environments and library dependencies. A CWL runner can perform this work automatically by pulling the Docker containers and mounting the paths of input files. The Docker requirement is optional, as CWL scripts can also be run locally with all the dependencies pre-installed. 0.4 Structure of the book Introduction Components Build CWL workflows Run approaches Case study 0.5 R session information The R session information for compiling this mannual is shown below: sessionInfo() ## R version 3.6.1 (2019-07-05) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: CentOS Linux 7 (Core) ## ## Matrix products: default ## BLAS/LAPACK: /home/qhu/.linuxbrew/Cellar/openblas/0.3.7/lib/libopenblasp-r0.3.7.so ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] parallel stats4 stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] jsonlite_1.6 dplyr_0.8.3 bookdown_0.13 ## [4] BiocParallel_1.18.1 fs_1.3.1 RcwlPipelines_1.1.12 ## [7] testthat_2.2.1 BiocFileCache_1.8.0 dbplyr_1.4.2 ## [10] Rcwl_1.1.13 S4Vectors_0.22.1 BiocGenerics_0.30.0 ## [13] yaml_2.2.0 devtools_2.2.1 usethis_1.5.1 ## ## loaded via a namespace (and not attached): ## [1] colorspace_1.4-1 ellipsis_0.3.0 rprojroot_1.3-2 ## [4] rstudioapi_0.10 roxygen2_6.1.1 remotes_2.1.0 ## [7] bit64_0.9-7 fansi_0.4.0 xml2_1.2.2 ## [10] codetools_0.2-16 R.methodsS3_1.7.1 knitr_1.25 ## [13] pkgload_1.0.2 zeallot_0.1.0 R.oo_1.22.0 ## [16] shiny_1.3.2 DiagrammeR_1.0.1 readr_1.3.1 ## [19] compiler_3.6.1 httr_1.4.1 backports_1.1.4 ## [22] assertthat_0.2.1 lazyeval_0.2.2 cli_1.1.0 ## [25] later_0.8.0 visNetwork_2.0.8 htmltools_0.3.6 ## [28] prettyunits_1.0.2 tools_3.6.1 igraph_1.2.4.1 ## [31] gtable_0.3.0 glue_1.3.1 batchtools_0.9.11 ## [34] rappdirs_0.3.1 Rcpp_1.0.2 rgexf_0.15.3 ## [37] xopen_1.0.0 vctrs_0.2.0 xfun_0.9 ## [40] stringr_1.4.0 ps_1.3.0 mime_0.7 ## [43] lifecycle_0.1.0 XML_3.98-1.20 scales_1.0.0 ## [46] hms_0.5.1 promises_1.0.1 RColorBrewer_1.1-2 ## [49] curl_4.2 memoise_1.1.0 gridExtra_2.3 ## [52] ggplot2_3.2.1 downloader_0.4 rcmdcheck_1.3.3 ## [55] stringi_1.4.3 RSQLite_2.1.2 highr_0.8 ## [58] Rook_1.1-1 desc_1.2.0 checkmate_1.9.4 ## [61] pkgbuild_1.0.5 rlang_0.4.0 pkgconfig_2.0.3 ## [64] commonmark_1.7 evaluate_0.14 purrr_0.3.2 ## [67] htmlwidgets_1.3 bit_1.1-14 processx_3.4.1 ## [70] tidyselect_0.2.5 magrittr_1.5 R6_2.4.0 ## [73] base64url_1.4 DBI_1.0.0 pillar_1.4.2 ## [76] withr_2.1.2 tibble_2.1.3 crayon_1.3.4 ## [79] utf8_1.1.4 rmarkdown_1.15 viridis_0.5.1 ## [82] progress_1.2.2 grid_3.6.1 data.table_1.12.2 ## [85] blob_1.2.0 callr_3.3.2 influenceR_0.1.0 ## [88] digest_0.6.21 xtable_1.8-4 tidyr_1.0.0 ## [91] httpuv_1.5.2 brew_1.0-6 R.utils_2.9.0 ## [94] munsell_0.5.0 viridisLite_0.3.0 sessioninfo_1.1.1 "],
["intro.html", "Chapter 1 Introduction 1.1 Common Workflow Language 1.2 First example 1.3 Test run", " Chapter 1 Introduction 1.1 Common Workflow Language ‚ÄúThe Common Workflow Language (CWL) is a specification for describing analysis workflows and tools in a way that makes them portable and scalable across a variety of software and hardware environments, from workstations to cluster, cloud, and high performance computing (HPC) environments.‚Äù https://www.commonwl.org/ To wrap tool and workflow parameters in a standard format Capable of invoking tools from Docker containers Widely used‚Ä¶ 1.2 First example The main class and constructor function is cwlParam, which wraps a command line tool and its parameters in a cwlParam object. Let‚Äôs start with a simple example, echo hello world. First, we load the package and define the input parameter for ‚Äúecho‚Äù, a string without a prefix. Just an id option required here: input1 &lt;- InputParam(id = &quot;sth&quot;) Second, we create a cwlParam object with baseCommand for the command to execute and InputParamList for the input parameters. echo &lt;- cwlParam(baseCommand = &quot;echo&quot;, inputs = InputParamList(input1)) Now we have a command object to run. Let‚Äôs send a string ‚ÄúHello World!‚Äù to the object. Without defining the outputs, it will stream standard output to a temporary file by default. echo$sth &lt;- &quot;Hello World!&quot; echo ## class: cwlParam ## cwlClass: CommandLineTool ## cwlVersion: v1.0 ## baseCommand: echo ## inputs: ## sth (string): Hello World! ## outputs: ## output: ## type: stdout 1.3 Test run The function runCWL is used to run the CWL object by invoking the python tool cwltool. The return will be a list including the command executed, temporary output and logs. The output directory is the current folder by default, but it can be changed by setting outdir option. All standard out and standard error streams can also be printed by setting stderr = \"\". r1 &lt;- runCWL(echo, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r1 ## List of length 3 ## names(3): command output logs Here we can check the output to ensure the code did what we expected. r1$output ## [1] &quot;/tmp/RtmpWSwswQ/15af4ea0a37f6f54b68c59d1ed80d811f10e20ba&quot; readLines(r1$output) ## [1] &quot;Hello World!&quot; The executed command was returned in the result list. It shows the command that we have defined to execute. r1$command ## [1] &quot;\\033[1;30mINFO\\033[0m [job file9ec636f0ad83.cwl] /tmp/rl779g32$ echo \\\\&quot; ## [2] &quot; &#39;Hello World!&#39; &gt; /tmp/rl779g32/15af4ea0a37f6f54b68c59d1ed80d811f10e20ba&quot; The log shows the details of how the cwltool works with CWL scripts. r1$log ## [1] &quot;\\033[1;30mINFO\\033[0m /home/qhu/.linuxbrew/bin/cwltool 1.0.20190815141648&quot; ## [2] &quot;\\033[1;30mINFO\\033[0m Resolved &#39;/tmp/RtmpWSwswQ/file9ec636f0ad83.cwl&#39; to &#39;file:///tmp/RtmpWSwswQ/file9ec636f0ad83.cwl&#39;&quot; ## [3] &quot;\\033[1;30mINFO\\033[0m [job file9ec636f0ad83.cwl] /tmp/rl779g32$ echo \\\\&quot; ## [4] &quot; &#39;Hello World!&#39; &gt; /tmp/rl779g32/15af4ea0a37f6f54b68c59d1ed80d811f10e20ba&quot; ## [5] &quot;\\033[1;30mINFO\\033[0m [job file9ec636f0ad83.cwl] completed success&quot; ## [6] &quot;{&quot; ## [7] &quot; \\&quot;output\\&quot;: {&quot; ## [8] &quot; \\&quot;location\\&quot;: \\&quot;file:///tmp/RtmpWSwswQ/15af4ea0a37f6f54b68c59d1ed80d811f10e20ba\\&quot;,&quot; ## [9] &quot; \\&quot;basename\\&quot;: \\&quot;15af4ea0a37f6f54b68c59d1ed80d811f10e20ba\\&quot;,&quot; ## [10] &quot; \\&quot;class\\&quot;: \\&quot;File\\&quot;,&quot; ## [11] &quot; \\&quot;checksum\\&quot;: \\&quot;sha1$a0b65939670bc2c010f4d5d6a0b3e4e4590fb92b\\&quot;,&quot; ## [12] &quot; \\&quot;size\\&quot;: 13,&quot; ## [13] &quot; \\&quot;path\\&quot;: \\&quot;/tmp/RtmpWSwswQ/15af4ea0a37f6f54b68c59d1ed80d811f10e20ba\\&quot;&quot; ## [14] &quot; }&quot; ## [15] &quot;}&quot; ## [16] &quot;\\033[1;30mINFO\\033[0m Final process status is success&quot; The runCWL generated two scripts with the default tempfile prefix, the tool wrapper CWL file and the input YML file. The cwltool parses the two scripts and translates them into the command shown before. The output is not defined in the cwlParam object, so the command output was returned to stdout by default. "],
["components.html", "Chapter 2 Components 2.1 Input Parameters 2.2 Output Parameters", " Chapter 2 Components 2.1 Input Parameters 2.1.1 Essential Input parameters For the input parameters, we usually need to define three options, id, type, and prefix. The type can be string, int, long, float, double, and so on. More detail can be found at: https://www.commonwl.org/v1.0/CommandLineTool.html#CWLType. A InputParam constructor is used to define a list of input objects for the command tool, such as ‚Äúprefix‚Äù for the parameter flags and ‚Äúposition‚Äù for the paramter orders. More descriptions are available in the CWL specification https://www.commonwl.org/v1.0/CommandLineTool.html#CommandLineBinding. Here is an example from the CWL user guide(http://www.commonwl.org/user_guide/03-input/). We defined the echo with different type of input parameters by InputParam, and the stdout option can be used to caputre the standard output stream into a file: e1 &lt;- InputParam(id = &quot;flag&quot;, type = &quot;boolean&quot;, prefix = &quot;-f&quot;) e2 &lt;- InputParam(id = &quot;string&quot;, type = &quot;string&quot;, prefix = &quot;-s&quot;) e3 &lt;- InputParam(id = &quot;int&quot;, type = &quot;int&quot;, prefix = &quot;-i&quot;) e4 &lt;- InputParam(id = &quot;file&quot;, type = &quot;File&quot;, prefix = &quot;--file=&quot;, separate = FALSE) echoA &lt;- cwlParam(baseCommand = &quot;echo&quot;, inputs = InputParamList(e1, e2, e3, e4), stdout = &quot;output.txt&quot;) Then we give it a try by setting values for the inputs: echoA$flag &lt;- TRUE echoA$string &lt;- &quot;Hello&quot; echoA$int &lt;- 1 tmpfile &lt;- tempfile() write(&quot;World&quot;, tmpfile) echoA$file &lt;- tmpfile r2 &lt;- runCWL(echoA, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r2$command ## [1] &quot;\\033[1;30mINFO\\033[0m [job file9ec64c0fe693.cwl] /tmp/xu0wuxpu$ echo \\\\&quot; ## [2] &quot; --file=/tmp/tmp9ryojtfo/stg93b9e7b2-7292-4e60-adca-7a3ed1bcbf92/file9ec66fe8ba62 \\\\&quot; ## [3] &quot; -f \\\\&quot; ## [4] &quot; -i \\\\&quot; ## [5] &quot; 1 \\\\&quot; ## [6] &quot; -s \\\\&quot; ## [7] &quot; Hello &gt; /tmp/xu0wuxpu/output.txt&quot; 2.1.2 Array Inputs Taking a similar example to the CWL user guide described above, we can define three different type of array as inputs: a1 &lt;- InputParam(id = &quot;A&quot;, type = &quot;string[]&quot;, prefix = &quot;-A&quot;) a2 &lt;- InputParam(id = &quot;B&quot;, type = InputArrayParam(items = &quot;string&quot;, prefix=&quot;-B=&quot;, separate = FALSE)) a3 &lt;- InputParam(id = &quot;C&quot;, type = &quot;string[]&quot;, prefix = &quot;-C=&quot;, itemSeparator = &quot;,&quot;, separate = FALSE) echoB &lt;- cwlParam(baseCommand = &quot;echo&quot;, inputs = InputParamList(a1, a2, a3)) We then set values for the three inputs: echoB$A &lt;- letters[1:3] echoB$B &lt;- letters[4:6] echoB$C &lt;- letters[7:9] echoB ## class: cwlParam ## cwlClass: CommandLineTool ## cwlVersion: v1.0 ## baseCommand: echo ## inputs: ## A (string[]): -A a b c ## B: ## type: array ## prefix: -B= d e f ## C (string[]): -C= g h i ## outputs: ## output: ## type: stdout Now we can check whether the command behaves as we expected: r3 &lt;- runCWL(echoB, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r3$command ## [1] &quot;\\033[1;30mINFO\\033[0m [job file9ec615883ce9.cwl] /tmp/u3b6uz3x$ echo \\\\&quot; ## [2] &quot; -A \\\\&quot; ## [3] &quot; a \\\\&quot; ## [4] &quot; b \\\\&quot; ## [5] &quot; c \\\\&quot; ## [6] &quot; -B=d \\\\&quot; ## [7] &quot; -B=e \\\\&quot; ## [8] &quot; -B=f \\\\&quot; ## [9] &quot; -C=g,h,i &gt; /tmp/u3b6uz3x/f9d8da775ce6fc6c567d2b6d5922a11cd41a3d9b&quot; 2.2 Output Parameters 2.2.1 Capturing Output The outputs, similar to the inputs, is a list of output parameters. Three options, id, type and glob, can be defined. The glob option is used to define a pattern to find files relative to the output directory. Here is an example to unzip a compressed gz file. First, we generate a compressed R script file: zzfil &lt;- file.path(tempdir(), &quot;sample.R.gz&quot;) zz &lt;- gzfile(zzfil, &quot;w&quot;) cat(&quot;sample(1:10, 5)&quot;, file = zz, sep = &quot;\\n&quot;) close(zz) We then define a cwlParam object to use ‚Äúgzip‚Äù to uncompress an input file: ofile &lt;- &quot;sample.R&quot; z1 &lt;- InputParam(id = &quot;uncomp&quot;, type = &quot;boolean&quot;, prefix = &quot;-d&quot;) z2 &lt;- InputParam(id = &quot;out&quot;, type = &quot;boolean&quot;, prefix = &quot;-c&quot;) z3 &lt;- InputParam(id = &quot;zfile&quot;, type = &quot;File&quot;) o1 &lt;- OutputParam(id = &quot;rfile&quot;, type = &quot;File&quot;, glob = ofile) gz &lt;- cwlParam(baseCommand = &quot;gzip&quot;, inputs = InputParamList(z1, z2, z3), outputs = OutputParamList(o1), stdout = ofile) Now the gz object can be used to uncompress the previously generated compressed file: gz$uncomp &lt;- TRUE gz$out &lt;- TRUE gz$zfile &lt;- zzfil r4 &lt;- runCWL(gz, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r4$output ## [1] &quot;/tmp/RtmpWSwswQ/sample.R&quot; Or we can use arguments to set some default parameters: z1 &lt;- InputParam(id = &quot;zfile&quot;, type = &quot;File&quot;) o1 &lt;- OutputParam(id = &quot;rfile&quot;, type = &quot;File&quot;, glob = ofile) Gz &lt;- cwlParam(baseCommand = &quot;gzip&quot;, arguments = list(&quot;-d&quot;, &quot;-c&quot;), inputs = InputParamList(z1), outputs = OutputParamList(o1), stdout = ofile) Gz ## class: cwlParam ## cwlClass: CommandLineTool ## cwlVersion: v1.0 ## baseCommand: gzip ## arguments: -d -c ## inputs: ## zfile (File): ## outputs: ## rfile: ## type: File ## outputBinding: ## glob: sample.R ## stdout: sample.R Gz$zfile &lt;- zzfil r4a &lt;- runCWL(Gz, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success To make it for general usage, we can define a pattern with javascript to glob the output, which requires node to be installed in your system PATH: pfile &lt;- &quot;$(inputs.zfile.path.split(&#39;/&#39;).slice(-1)[0].split(&#39;.&#39;).slice(0,-1).join(&#39;.&#39;))&quot; Or we can directly use the CWL built in file property, nameroot: pfile &lt;- &quot;$(inputs.zfile.nameroot)&quot; o2 &lt;- OutputParam(id = &quot;rfile&quot;, type = &quot;File&quot;, glob = pfile) req1 &lt;- list(class = &quot;InlineJavascriptRequirement&quot;) GZ &lt;- cwlParam(baseCommand = c(&quot;gzip&quot;, &quot;-d&quot;, &quot;-c&quot;), requirements = list(), ## assign list(req1) if node installed. inputs = InputParamList(z1), outputs = OutputParamList(o2), stdout = pfile) GZ$zfile &lt;- zzfil r4b &lt;- runCWL(GZ, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success 2.2.2 Array Outputs We can also capture multiple output files with the glob pattern: a &lt;- InputParam(id = &quot;a&quot;, type = InputArrayParam(items = &quot;string&quot;)) b &lt;- OutputParam(id = &quot;b&quot;, type = OutputArrayParam(items = &quot;File&quot;), glob = &quot;*.txt&quot;) touch &lt;- cwlParam(baseCommand = &quot;touch&quot;, inputs = InputParamList(a), outputs = OutputParamList(b)) touch$a &lt;- c(&quot;a.txt&quot;, &quot;b.gz&quot;, &quot;c.txt&quot;) r5 &lt;- runCWL(touch, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r5$output ## [1] &quot;/tmp/RtmpWSwswQ/a.txt&quot; &quot;/tmp/RtmpWSwswQ/c.txt&quot; 2.2.3 Standard output Usually, the stdout option is a string or an expression of output file name from the command tool. The command‚Äôs standard output stream will be captured into a file written to the designated output directory. When the stdout field is defined, an output parameter with the type of ‚Äústdout‚Äù should be also assigned with no ‚ÄúoutputBinding‚Äù set. An example for command tool ‚Äúcat‚Äù is defined with stdout field in the output, with the name passed from the input parameter ‚Äúp2‚Äù: ## define Cat p1 &lt;- InputParam(id = &quot;infiles&quot;, type = &quot;File[]&quot;) p2 &lt;- InputParam(id = &quot;outfile&quot;, type = &quot;string&quot;, default = &quot;catout.txt&quot;, position = -1) Cat &lt;- cwlParam(baseCommand = &quot;cat&quot;, inputs = InputParamList(p1, p2), stdout = &quot;$(inputs.outfile)&quot;) ## assign inputs afile &lt;- file.path(tempdir(), &quot;a.txt&quot;) bfile &lt;- file.path(tempdir(), &quot;b.txt&quot;) write(&quot;a&quot;, afile) write(&quot;b&quot;, bfile) Cat$infiles &lt;- list(afile, bfile) ## run r6 &lt;- runCWL(Cat, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r6$command ## [1] &quot;\\033[1;30mINFO\\033[0m [job file9ec62420ffd0.cwl] /tmp/nfu_xgwh$ cat \\\\&quot; ## [2] &quot; /tmp/tmp5yyr_wt_/stgcba80d66-ebc8-4458-bb3f-0a6d4af16452/a.txt \\\\&quot; ## [3] &quot; /tmp/tmp5yyr_wt_/stgc90fc446-9c53-470f-8418-b227f7649d11/b.txt &gt; /tmp/nfu_xgwh/catout.txt&quot; In this example, we used the parameter ‚Äúp2‚Äù to pass the name to the standard output. In the InputParam of ‚Äúp2‚Äù, the position is assigned to a negative value (-1), which means the parameters will not be used in the command and only uses for passing variable. To write the ‚ÄúCat‚Äù tool to a CWL file, the ‚ÄúinputBinding‚Äù field will be skipped for this parameter. "],
["writing-pipeline.html", "Chapter 3 Writing Pipeline 3.1 Scattering pipeline 3.2 Pipeline plot", " Chapter 3 Writing Pipeline We can connect multiple tools into a pipeline. Here is an example to uncompress an R script and execute it with Rscript. We first define a simple Rscript tool without using docker: d1 &lt;- InputParam(id = &quot;rfile&quot;, type = &quot;File&quot;) Rs &lt;- cwlParam(baseCommand = &quot;/usr/bin/Rscript&quot;, inputs = InputParamList(d1)) Rs ## class: cwlParam ## cwlClass: CommandLineTool ## cwlVersion: v1.0 ## baseCommand: /usr/bin/Rscript ## inputs: ## rfile (File): ## outputs: ## output: ## type: stdout Here is the test run: Rs$rfile &lt;- r4$output tres &lt;- runCWL(Rs, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success readLines(tres$output) ## [1] &quot;[1] 9 8 3 5 6&quot; The pipeline includes two steps, decompressed by GZ and compiled by Rs. The input file is a compressed file and the output file would be the output Rout from Rs. First we need to define the direct inputs and outputs from GZ and Rs, respectively: i1 &lt;- InputParam(id = &quot;cwl_zfile&quot;, type = &quot;File&quot;) o1 &lt;- OutputParam(id = &quot;cwl_cout&quot;, type = &quot;File&quot;, outputSource = &quot;Compile/output&quot;) For the input ‚Äúcwl_zifle‚Äù, it refers to the GZ input zfile. The output ‚Äúcwl_cout‚Äù will be the outcome of Rs output Rout. The cwlStepParam is used to define inputs and outputs, and the Step function is used to define the two steps. The run option refers to the corresponding cwlParam object and the In option should be linked to the input parameters defined by cwlStepParam. At the end, we use + to connect all steps: cwl &lt;- cwlStepParam(inputs = InputParamList(i1), outputs = OutputParamList(o1)) s1 &lt;- Step(id = &quot;Uncomp&quot;, run = GZ, In = list(zfile = &quot;cwl_zfile&quot;)) s2 &lt;- Step(id = &quot;Compile&quot;, run = Rs, In = list(rfile = &quot;Uncomp/rfile&quot;)) cwl &lt;- cwl + s1 + s2 cwl ## class: cwlStepParam ## cwlClass: Workflow ## cwlVersion: v1.0 ## inputs: ## cwl_zfile (File): ## outputs: ## cwl_cout: ## type: File ## outputSource: Compile/output ## steps: ## Uncomp: ## run: Uncomp.cwl ## zfile: cwl_zfile ## out: rfile ## Compile: ## run: Compile.cwl ## rfile: Uncomp/rfile ## out: output Let‚Äôs run the pipeline: cwl$cwl_zfile &lt;- zzfil r7 &lt;- runCWL(cwl, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success readLines(r7$output) ## [1] &quot;[1] 6 7 2 5 10&quot; 3.1 Scattering pipeline The scattering feature can specify the associated workflow steps or subworkflows to execute separately over a list of input elements. To use this feature, ScatterFeatureRequirement must be specified in the workflow requirement. Different scatter methods can be used in the associated steps to decompose the input into a discrete set of jobs. More details can be found at: https://www.commonwl.org/v1.0/Workflow.html#WorkflowStep. Here is an example to execute multiple R scripts. First, we need to set the input and output types to be an array of ‚ÄúFile‚Äù, and add the requirments. In the ‚ÄúCompile‚Äù step, the scattering input is required to be set with the scatter option: i2 &lt;- InputParam(id = &quot;cwl_rfiles&quot;, type = &quot;File[]&quot;) o2 &lt;- OutputParam(id = &quot;cwl_couts&quot;, type = &quot;File[]&quot;, outputSource = &quot;Compile/output&quot;) req1 &lt;- list(class = &quot;ScatterFeatureRequirement&quot;) cwl2 &lt;- cwlStepParam(requirements = list(req1), inputs = InputParamList(i2), outputs = OutputParamList(o2)) s1 &lt;- Step(id = &quot;Compile&quot;, run = Rs, In = list(rfile = &quot;cwl_rfiles&quot;), scatter = &quot;rfile&quot;) cwl2 &lt;- cwl2 + s1 cwl2 ## class: cwlStepParam ## cwlClass: Workflow ## cwlVersion: v1.0 ## requirements: ## - class: ScatterFeatureRequirement ## inputs: ## cwl_rfiles (File[]): ## outputs: ## cwl_couts: ## type: File[] ## outputSource: Compile/output ## steps: ## Compile: ## run: Compile.cwl ## rfile: cwl_rfiles ## out: output ## scatter: rfile Now multiple R scripts can be assigned to the workflow inputs and executed: cwl2$cwl_rfiles &lt;- c(r4b$output, r4b$output) r8 &lt;- runCWL(cwl2, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r8$output ## [1] &quot;/tmp/RtmpWSwswQ/68fa97dcf91845e69e01f25fd7c81504d8192b71&quot; ## [2] &quot;/tmp/RtmpWSwswQ/68fa97dcf91845e69e01f25fd7c81504d8192b71&quot; 3.2 Pipeline plot The function plotCWL can be used to visualize the relationship of inputs, outputs and the components for a tool or pipeline: plotCWL(cwl) "],
["run-approaches.html", "Chapter 4 Run approaches 4.1 Running Tools in Docker 4.2 Running Tools in Cluster server 4.3 Web Application", " Chapter 4 Run approaches 4.1 Running Tools in Docker The CWL can work with docker to simplify your software management and communicate files between host and container. The docker container can be defined by the hints or requirements option: d1 &lt;- InputParam(id = &quot;rfile&quot;, type = &quot;File&quot;) req1 &lt;- list(class = &quot;DockerRequirement&quot;, dockerPull = &quot;r-base&quot;) doc &lt;- cwlParam(baseCommand = &quot;Rscript&quot;, inputs = InputParamList(d1), stdout = &quot;output.txt&quot;, hints = list(req1)) doc$rfile &lt;- r4$output r6 &lt;- runCWL(doc) The tools defined with docker requirements can also be run locally by disabling the docker option. In case your Rscript depends some local libraries to run, an option from cwltools, ‚Äú‚Äìpreserve-entire-environment‚Äù, can be used to pass all environment variables. r6a &lt;- runCWL(doc, docker = FALSE, outdir = tempdir(), Args = &quot;--preserve-entire-environment&quot;) ## [1;30mINFO[0m Final process status is success 4.2 Running Tools in Cluster server The CWL can also work in high performance clusters with batch-queuing system, such as SGE, PBS, SLURM and so on, using the Bioconductor package BiocParallel. Here is an example to submit jobs with ‚ÄúMultiicore‚Äù and ‚ÄúSGE‚Äù, seperately: library(BiocParallel) sth.list &lt;- as.list(LETTERS) names(sth.list) &lt;- LETTERS ## submit with mutlicore result1 &lt;- runCWLBatch(cwl = echo, outdir = tempdir(), inputList = list(sth = sth.list), BPPARAM = MulticoreParam(26)) ## submit with SGE result2 &lt;- runCWLBatch(cwl = echo, outdir = tempdir(), inputList = list(sth = sth.list), BPPARAM = BatchtoolsParam(workers = 26, cluster = &quot;sge&quot;, resources = list(queue = &quot;all.q&quot;))) A more detailed example can be found (https://hubentu.github.io/others/Rcwl_RNASeq.html). 4.3 Web Application 4.3.1 cwlParam example Here we build a tool with different types of input parameters: e1 &lt;- InputParam(id = &quot;flag&quot;, type = &quot;boolean&quot;, prefix = &quot;-f&quot;, doc = &quot;boolean flag&quot;) e2 &lt;- InputParam(id = &quot;string&quot;, type = &quot;string&quot;, prefix = &quot;-s&quot;) e3 &lt;- InputParam(id = &quot;option&quot;, type = &quot;string&quot;, prefix = &quot;-o&quot;) e4 &lt;- InputParam(id = &quot;int&quot;, type = &quot;int&quot;, prefix = &quot;-i&quot;, default = 123) e5 &lt;- InputParam(id = &quot;file&quot;, type = &quot;File&quot;, prefix = &quot;--file=&quot;, separate = FALSE) e6 &lt;- InputParam(id = &quot;array&quot;, type = &quot;string[]&quot;, prefix = &quot;-A&quot;, doc = &quot;separated by comma&quot;) mulEcho &lt;- cwlParam(baseCommand = &quot;echo&quot;, id = &quot;mulEcho&quot;, label = &quot;Test parameter types&quot;, inputs = InputParamList(e1, e2, e3, e4, e5, e6), stdout = &quot;output.txt&quot;) mulEcho ## class: cwlParam ## cwlClass: CommandLineTool ## cwlVersion: v1.0 ## baseCommand: echo ## inputs: ## flag (boolean): -f ## string (string): -s ## option (string): -o ## int (int): -i 123 ## file (File): --file= ## array (string[]): -A ## outputs: ## output: ## type: stdout ## stdout: output.txt 4.3.2 cwlParam to Shiny App Some input parameters can be predefined in a list, which will be converted to selected options in the webapp. An upload parameter can be used to generate an upload interface for the file type option. If FALSE is set for upload, the upload field will be text input (file path) instead of file input. inputList &lt;- list(option = c(&quot;option1&quot;, &quot;option2&quot;)) app &lt;- cwlShiny(mulEcho, inputList, upload = TRUE) runApp(app) shinyApp "],
["application.html", "Chapter 5 Application 5.1 RcwlPipelines tools 5.2 RcwlPipelines summary 5.3 DNASeq alignment pipeline 5.4 RNASeq pipeline 5.5 MC3 somatic variant calling pipeline 5.6 GATK4 germline variant calling pipeline", " Chapter 5 Application 5.1 RcwlPipelines tools 5.1.1 Rcwl scripts The R scripts to build the CWL tools and pipelines based on the Rcwl package are stored in the ‚Äúsrc‚Äù folder with ‚Äútl_‚Äù and ‚Äúpl_‚Äù prefix respectively. The function cwlTools can be used to collect the available scripts. The cachePath can be your existing cache directory or a new folder. tools &lt;- cwlTools(cachePath = tempdir()) tools ## class: BiocFileCache ## bfccache: /tmp/RtmpWSwswQ ## bfccount: 77 ## For more information see: bfcinfo() or bfcquery() The full paths can be pulled from the ‚Äúfpath‚Äù column. The scripts can be viewed to demonstrate how the tools and pipelines were built. library(dplyr) bfcinfo(tools) %&gt;% select(rname, fpath) ## # A tibble: 77 x 2 ## rname fpath ## &lt;chr&gt; &lt;chr&gt; ## 1 ApplyBQSR /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## 2 BaseRecalibrator /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## 3 bcfview /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## 4 bgzip /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## 5 blastn /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## 6 bowtie2_build /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## 7 bowtie2 /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## 8 bwa_index /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## 9 bwa /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## 10 CalculateContamin‚Ä¶ /home/qhu/workspace/projects/RPipe/RcwlPipelines/ins‚Ä¶ ## # ‚Ä¶ with 67 more rows The commands and docker containers from the wrapped tools are included in the metadata. tls &lt;- bfcinfo(tools) %&gt;% filter(Type == &quot;tool&quot;) %&gt;% select(rname, Command, Container) knitr::kable(tls) rname Command Container ApplyBQSR gatk ApplyBQSR broadinstitute/gatk:latest BaseRecalibrator gatk BaseRecalibrator broadinstitute/gatk:latest bcfview bcftools view biocontainers/bcftools:v1.5_cv3 bgzip bgzip -c biocontainers/tabix:v1.3.2-2-deb_cv1 blastn blastn biocontainers/blast:v2.2.31_cv2 bowtie2_build bowtie2-build biocontainers/bowtie2:v2.2.9_cv2 bowtie2 bowtie2 biocontainers/bowtie2:v2.2.9_cv2 bwa_index bwa index biocontainers/bwa:v0.7.17-3-deb_cv1 bwa bwa mem biocontainers/bwa:v0.7.17-3-deb_cv1 CalculateContamination gatk CalculateContamination broadinstitute/gatk:latest ColSeqArtifact gatk CollectSequencingArtifactMetrics broadinstitute/gatk:latest cutadapt cutadapt kfdrc/cutadapt fastqc fastqc hubentu/rcwl-rnaseq featureCounts featureCounts hubentu/rcwl-rnaseq FilterMutectCalls gatk FilterMutectCalls broadinstitute/gatk:latest FilterOBias gatk FilterByOrientationBias broadinstitute/gatk:latest Funcotator gatk Funcotator broadinstitute/gatk:latest geneBody_coverage geneBody_coverage.py hubentu/rcwl-rnaseq genePredToBed genePredToBed hubentu/rcwl-rnaseq GenomicsDB gatk GenomicsDBImport broadinstitute/gatk:latest GetPileupSummaries gatk GetPileupSummaries broadinstitute/gatk:latest gtfToGenePred gtfToGenePred hubentu/rcwl-rnaseq hisat2_align hisat2 biocontainers/hisat2:v2.0.5-1-deb_cv1 hisat2_build hisat2-build biocontainers/hisat2:v2.0.5-1-deb_cv1 htseq htseq-count genomicpariscentre/htseq lancet /lancet-1.0.7/lancet kfdrc/lancet:1.0.7 LoFreq lofreq somatic andreaswilm/lofreq:v2.1.2 makeblastdb makeblastdb biocontainers/blast:v2.2.31_cv2 manta configManta.py cmopipeline/strelka2_manta markdup picard MarkDuplicates biocontainers/picard:2.3.0 mergeBam picard MergeSamFiles biocontainers/picard:2.3.0 multiqc multiqc hubentu/rcwl-rnaseq MuSE MuSEv1.0rc_submission_c039ffa call marghoob/muse:1.0rc_c Mutect2 gatk Mutect2 broadinstitute/gatk:latest mvOut R function NA neusomatic_call python /opt/neusomatic/neusomatic/python/call.py msahraeian/neusomatic neusomatic_postprocess python /opt/neusomatic/neusomatic/python/postprocess.py msahraeian/neusomatic neusomatic_preprocess python /opt/neusomatic/neusomatic/python/preprocess.py msahraeian/neusomatic polysolver bash /home/polysolver/scripts/shell_call_hla_type sachet/polysolver:v4 PoN gatk CreateSomaticPanelOfNormals broadinstitute/gatk:latest read_distribution read_distribution.py hubentu/rcwl-rnaseq runWDL java NA salmon_index salmon index combinelab/salmon salmon_quant salmon quant combinelab/salmon sam2bam samtools view biocontainers/samtools:v1.7.0_cv3 samtools_flagstat samtools flagstat biocontainers/samtools:v1.7.0_cv3 samtools_index samtools index biocontainers/samtools:v1.7.0_cv3 samtools_mpileup samtools mpileup biocontainers/samtools:v1.7.0_cv3 samtools_stats samtools stats biocontainers/samtools:v1.7.0_cv3 SomaticSniper /opt/somatic-sniper/build/bin/bam-somaticsniper lethalfang/somaticsniper:1.0.5.0-2 sortBam samtools sort biocontainers/samtools:v1.7.0_cv3 STAR STAR hubentu/rcwl-rnaseq starFusion /usr/local/src/STAR-Fusion/STAR-Fusion trinityctat/ctatfusion strelka configureStrelkaSomaticWorkflow.py cmopipeline/strelka2_manta tabix_index tabix biocontainers/tabix:v1.3.2-2-deb_cv1 VarDict /opt/VarDict-1.5.1/bin/VarDict lethalfang/vardictjava:1.5.1 VarScan2_processSomatic java -jar /opt/varscan/VarScan.jar processSomatic mgibio/varscan-cwl:v2.4.2-samtools1.3.1 VarScan2_somatic java -jar /opt/varscan/VarScan.jar somatic mgibio/varscan-cwl:v2.4.2-samtools1.3.1 VarScan2_somaticFilter java -jar /opt/varscan/VarScan.jar somaticFilter mgibio/varscan-cwl:v2.4.2-samtools1.3.1 VarScan2 serge2016/varscan:v0.1.1 5.1.2 Build a pipeline We can develop a pipline by utilizing the available tools. For example, a simple alignment pipelines with mapping and marking duplicates can be built from the tools. First, we check whether the required tools (bwa, samtools and picard markduplicates) are available. bfcquery(tools, &quot;bwa|sam2bam|sortBam|samtools_index|markdup&quot;) %&gt;% filter(Type == &quot;tool&quot;) %&gt;% select(rname, Command, Container) ## # A tibble: 6 x 3 ## rname Command Container ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 bwa_index bwa index biocontainers/bwa:v0.7.17-3-deb_cv1 ## 2 bwa bwa mem biocontainers/bwa:v0.7.17-3-deb_cv1 ## 3 markdup picard MarkDuplicates biocontainers/picard:2.3.0 ## 4 sam2bam samtools view biocontainers/samtools:v1.7.0_cv3 ## 5 samtools_index samtools index biocontainers/samtools:v1.7.0_cv3 ## 6 sortBam samtools sort biocontainers/samtools:v1.7.0_cv3 Next, we define the input parameters: p1 &lt;- InputParam(id = &quot;threads&quot;, type = &quot;int&quot;) p2 &lt;- InputParam(id = &quot;RG&quot;, type = &quot;string&quot;) p3 &lt;- InputParam(id = &quot;Ref&quot;, type = &quot;string&quot;) p4 &lt;- InputParam(id = &quot;FQ1&quot;, type = &quot;File&quot;) p5 &lt;- InputParam(id = &quot;FQ2&quot;, type = &quot;File?&quot;) Then we define the pipeline steps, from raw fastqs to duplicates marked alignments: ## bwa s1 &lt;- Step(id = &quot;bwa&quot;, run = bwa, In = list(threads = &quot;threads&quot;, RG = &quot;RG&quot;, Ref = &quot;Ref&quot;, FQ1 = &quot;FQ1&quot;, FQ2 = &quot;FQ2&quot;)) ## sam to bam s2 &lt;- Step(id = &quot;sam2bam&quot;, run = sam2bam, In = list(sam = &quot;bwa/sam&quot;)) ## sort bam s3 &lt;- Step(id = &quot;sortBam&quot;, run = sortBam, In = list(bam = &quot;sam2bam/bam&quot;)) ## mark duplicates s4 &lt;- Step(id = &quot;markdup&quot;, run = markdup, In = list(ibam = &quot;sortBam/sbam&quot;, obam = list( valueFrom=&quot;$(inputs.ibam.nameroot).mdup.bam&quot;), matrix = list( valueFrom=&quot;$(inputs.ibam.nameroot).markdup.txt&quot;))) ## index bam s5 &lt;- Step(id = &quot;idxBam&quot;, run = samtools_index, In = list(bam = &quot;markdup/mBam&quot;)) Last, we define the outputs and connect the steps to a new pipeline: req1 &lt;- list(class = &quot;StepInputExpressionRequirement&quot;) req2 &lt;- list(class = &quot;InlineJavascriptRequirement&quot;) ## outputs o1 &lt;- OutputParam(id = &quot;Bam&quot;, type = &quot;File&quot;, outputSource = &quot;markdup/mBam&quot;) o2 &lt;- OutputParam(id = &quot;Idx&quot;, type = &quot;File&quot;, outputSource = &quot;idxBam/idx&quot;) ## stepParam Align &lt;- cwlStepParam(requirements = list(req1, req2), inputs = InputParamList(p1, p2, p3, p4, p5), outputs = OutputParamList(o1, o2)) ## build pipeline Align &lt;- Align + s1 + s2 + s3 + s4 + s5 The pipeline is ready for use. We can plot the pipeline with plotCWL from the Rcwl package. plotCWL(Align) 5.2 RcwlPipelines summary So far we have built 4 major pipelines in this package. Here is a brief introduction to these 4 pipelines. More pipelines and tools are expected to be included in the future. 5.3 DNASeq alignment pipeline The pipeline can be used to preprocess DNA sequences in fastq format. It can take paired fastqs and read groups from multiple batches as input. inputs(bwaMMRecal) ## inputs: ## outBam (string): ## RG (string[]): ## threads (int): ## Ref (File): ## FQ1s (File[]): ## FQ2s (File[]): ## knowSites: ## type: array ## prefix: The pipeline includes two steps and several jobs will be run in each step. bwaAlign: bwa alignment by read groups: runs(runs(bwaMMRecal)[[1]]) ## List of length 4 ## names(4): bwa sam2bam sortBam idxBam bwa: To align fastqs and read groups to reference genome with bwa. sam2bam: To convert the alignments in ‚Äúsam‚Äù format to ‚Äúbam‚Äù format with samtools. sortBam: To sort the ‚Äúbam‚Äù file by coordinates with samtools. idxBam: To index ‚Äúbam‚Äù file with samtools. mergeBamDup: To merge by samples and mark duplicates: runs(runs(bwaMMRecal)[[2]]) ## List of length 4 ## names(4): mergeBam markdup samtools_index samtools_flagstat mergeBam: To merge bam files from multiple batches with picard. markdup: To mark duplicates with picard. samtools_index: To index bam file with samtools. samtools_flagstat: To summarize flags in bam with samtools. BaseRecal: To apply TCGA BaseRecalibrator and ApplyBQSR. runs(runs(bwaMMRecal)[[3]]) ## List of length 5 ## names(5): BaseRecalibrator ApplyBQSR samtools_index samtools_flagstat samtools_stats BaseRecalibrator: To Generates recalibration table for Base Quality Score Recalibration with gatk BaseRecalibrator. ApplyBQSR: To Apply base quality score recalibration with gatk ApplyBQSR. samtools_index: To index bam file with samtools. samtools_flagstat: To summarize flags in bam with samtools. samtools_stats: To collects statistics from BAM file with samtools. The final bam files with duplicates marked and base quality recalibration, bam index, duplicates matrix, and statistics summaries will be in the output folder. outputs(bwaMMRecal) ## outputs: ## BAM: ## type: File ## outputSource: BaseRecal/rcBam ## matrix: ## type: File ## outputSource: mergeBamDup/matrix ## flagstat: ## type: File ## outputSource: BaseRecal/flagstat ## stats: ## type: File ## outputSource: BaseRecal/stats Here is the short summary and steps plot: short(bwaMMRecal) ## inputs: ## - outBam ## - RG ## - threads ## - Ref ## - FQ1s ## - FQ2s ## - knowSites ## outputs: ## - BAM ## - matrix ## - flagstat ## - stats ## steps: ## - bwaAlign ## - mergeBamDup ## - BaseRecal plotCWL(bwaMMRecal) 5.3.1 Prepare data Here is a simple example of two samples. The ‚Äúsample1‚Äù have two lanes of sequences and the ‚Äúsample2‚Äù has only one pair of reads. The lists of reads1 fq1, reads2 fq2, read groups and output BAM names are defined in the inputList. The reference genome and number of threads to run the job are defined in the shared options, paramList: fq1 &lt;- list(sample1 = list(&quot;apps/DNASeq/data/fq1_1.fq&quot;, &quot;apps/DNASeq/data/fq2_1.fq&quot;), sample2 = list(&quot;apps/DNASeq/data/fq1_1.fq&quot;)) fq2 &lt;- list(sample1 = list(&quot;apps/DNASeq/data/fq1_2.fq&quot;, &quot;apps/DNASeq/data/fq2_2.fq&quot;), sample2 = list(&quot;apps/DNASeq/data/fq1_2.fq&quot;)) rgs &lt;- list(sample1 = list(&quot;@RG\\\\tID:sample1.1\\\\tPL:Illumina\\\\tSM:sample1&quot;, &quot;@RG\\\\tID:sample1.2\\\\tPL:Illumina\\\\tSM:sample1&quot;), sample2 = list(&quot;@RG\\\\tID:sample2.1\\\\tPL:Illumina\\\\tSM:sample2&quot;)) samples &lt;- list(sample1 = &quot;sample1.bam&quot;, sample2 = &quot;sample2.bam&quot;) inputList &lt;- list(outBam = samples, RG = rgs, FQ1s = fq1, FQ2s = fq2) paramList &lt;- list(threads = 2, Ref = &quot;apps/data/hs37d5.fa&quot;, knowSites = list(&quot;apps/data/dbsnp_138.b37.vcf&quot;, &quot;apps/data/Mills_and_1000G_gold_standard.indels.b37.vcf&quot;)) 5.3.2 Run in cluster res &lt;- runCWLBatch(bwaMMRecal, outdir = &quot;apps/DNASeq/output/BAM&quot;, inputList = inputList, paramList = paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;/rpcc/bioinformatics/sge_centos7.tmpl&quot;, resources = list(jobname=&quot;bwa&quot;, threads = 2, queue = &quot;centos7.q&quot;), log=TRUE, logdir=&quot;.&quot;, progressbar = T), docker = FALSE, stderr = &quot;&quot;) List outputs: dir(&quot;apps/DNASeq/output/BAM/sample2&quot;) ## [1] &quot;sample2.bam&quot; &quot;sample2.bam.bai&quot; &quot;sample2.flagstat.txt&quot; ## [4] &quot;sample2.markdup.txt&quot; &quot;sample2.stats.txt&quot; 5.4 RNASeq pipeline The pipeline was built with reads quality summary, STAR alignment, quantification by featureCounts and RSeQC quality control. Here are the inputs: inputs(rnaseq_Sf) ## inputs: ## in_seqfiles (File[]): ## in_prefix (string): ## in_genomeDir (Directory): ## in_GTFfile (File): ## in_runThreadN (int): 1 The pipeline includes 6 steps: fastqc: To run quality summary for raw fastqs with fastqc. STAR: To align fastqs with STAR. samtools_index: To index aligned bam file. samtools_flagstat: To summarize alignment flags. featureCounts: To quantify gene abundances. RSeQC: Several steps included. gtfToGenePred: To convert GTF annotation to ‚ÄúgenePred‚Äù format. genePredToBed: To convert ‚ÄúgenePred‚Äù annotation to ‚Äúbed‚Äù format. r_distribution: To summarize reads distribution over genome features. gCoverage: To summarize read coverage over gene body. The outputs and logs from alignment, quantification and QC steps are collected together into the output folder. A final QC report could be generated by multiqc, which is also available in the data package. Here are the short summary and steps plot: short(rnaseq_Sf) ## inputs: ## - in_seqfiles ## - in_prefix ## - in_genomeDir ## - in_GTFfile ## - in_runThreadN ## outputs: ## - out_fastqc ## - out_BAM ## - out_Log ## - out_Count ## - out_stat ## - out_count ## - out_distribution ## - out_gCovP ## - out_gCovT ## steps: ## - fastqc ## - STAR ## - sortBam ## - samtools_index ## - samtools_flagstat ## - featureCounts ## - gtfToGenePred ## - genePredToBed ## - r_distribution ## - gCoverage plotCWL(rnaseq_Sf) 5.4.1 Prepare data An RNASeq test data set can be downloaded from genomedata, which includes paired-end fastqs for 6 samples. download.file(&quot;http://genomedata.org/rnaseq-tutorial/HBR_UHR_ERCC_ds_5pc.tar&quot;, &quot;apps/RNASeq/data/HBR_UHR_ERCC_ds_5pc.tar) untar(&quot;apps/RNASeq/data/HBR_UHR_ERCC_ds_5pc.tar&quot;, exdir = &quot;apps/RNASeq/data/&quot;) The input data must be in a named list, with the same names as the input list of the pipeline. For this pipeline, 5 inputs are required to be set, including in_seqfiles, in_prefix, in_genomeDir, in_GTFfile and in_runThreadN. There are two different input lists, inputList and paramList. The inputList is used to define the inputs for each sample and will be submitted to different cluster nodes. The paramList is used to define parameters which are shared in all jobs. Two following inputs should be listed in inputList: in_seqfiles: A list with the fastq files of each sample in each element. The names of the list are also required to be defined and can be the sample IDs. The length of the list will be the same as the number of samples, thus the list will be defined to inputList and assigned to different nodes for parallel computing. in_prefix is the same as in_seqfiles, which defines a list of sample IDs. files &lt;- normalizePath(list.files(&quot;apps/RNASeq/data/&quot;, &quot;.gz&quot;, full.names = TRUE)) files &lt;- tapply(files, substring(basename(files), 1, 8), as.list) inputList &lt;- list(in_seqfiles = files, in_prefix = as.list(names(files))) These 3 parameter will be defined in paramList: in_genomeDir: The reference genome indexes for STAR. in_GTFfile: The gene annotation file in GTF format. in_runThreadN: The number of threads to run for each job. paramList &lt;- list( in_genomeDir = &quot;apps/data/GRCh38_100/&quot;, in_GTFfile = &quot;apps/data/gencode.v25.annotation.gtf&quot;, in_runThreadN = 4 ) In some cases, we need to modify the default arguments in some steps of a pipeline. For example, arguments(rnaseq_Sf, &quot;STAR&quot;)[[2]] &lt;- &quot;2&quot; head(arguments(rnaseq_Sf, &quot;STAR&quot;)) ## [[1]] ## [1] &quot;--outFilterMultimapNmax&quot; ## ## [[2]] ## [1] &quot;2&quot; ## ## [[3]] ## [1] &quot;--outSAMunmapped&quot; ## ## [[4]] ## [1] &quot;Within&quot; ## ## [[5]] ## [1] &quot;--outFilterMismatchNmax&quot; ## ## [[6]] ## [1] &quot;2&quot; 5.4.2 Submit pipeline with SGE The function runCWLBatch is used to submit the pipeline to cluster server. In addition to defining inputList and paramList, we need to define parallel parameters from the BiocParallel package. Here is an example where we use ‚Äúsge‚Äù to submit the jobs. The ‚Äúsge‚Äù template is a bash script with some predefined parameters for ‚Äúqsub‚Äù. The nodes queue name and number of slots/threads are variables from the template and can be assigned by the resources list. res &lt;- runCWLBatch(cwl = rnaseq_Sf, outdir = &quot;apps/RNASeq/output/&quot;, inputList = inputList, paramList = paramList, BPPARAM = BatchtoolsParam( workers = lengths(inputList)[1], cluster = &quot;sge&quot;, template = &quot;apps/data/sge_centos7.tmpl&quot;, resources = list(queue = &quot;centos7.q&quot;, threads = 4))) That‚Äôs it! The fastqc files of each sample will be submitted to different nodes to run the whole pipeline automatically. All the results have been collected to output directory of each sample. For example, dir(&quot;apps/RNASeq/output/HBR_Rep1&quot;) ## [1] &quot;HBR_Rep1_ERCC-Mix2_Build37-ErccTranscripts-chr22.read1_fastqc.zip&quot; ## [2] &quot;HBR_Rep1_ERCC-Mix2_Build37-ErccTranscripts-chr22.read2_fastqc.zip&quot; ## [3] &quot;HBR_Rep1Aligned.sortedByCoord.out.bam&quot; ## [4] &quot;HBR_Rep1Aligned.sortedByCoord.out.bam.bai&quot; ## [5] &quot;HBR_Rep1Aligned.sortedByCoord.out.distribution.txt&quot; ## [6] &quot;HBR_Rep1Aligned.sortedByCoord.out.featureCounts.txt&quot; ## [7] &quot;HBR_Rep1Aligned.sortedByCoord.out.featureCounts.txt.summary&quot; ## [8] &quot;HBR_Rep1Aligned.sortedByCoord.out.flagstat.txt&quot; ## [9] &quot;HBR_Rep1Aligned.sortedByCoord.out.geneBodyCoverage.curves.pdf&quot; ## [10] &quot;HBR_Rep1Aligned.sortedByCoord.out.geneBodyCoverage.txt&quot; ## [11] &quot;HBR_Rep1Log.final.out&quot; ## [12] &quot;HBR_Rep1ReadsPerGene.out.tab&quot; 5.4.3 Summarize QC The tool ‚Äúmultiqc‚Äù can aggregate results from the multiple outputs of the pipeline and generate a single page report, which also was implemented in the RcwlPipelines package: multiqc$dir &lt;- &quot;apps/RNASeq/output&quot; multiqc We can also run the tool using Rcwl locally with the option docker = TRUE: runCWL(multiqc, stderr = &quot;&quot;, Args = &quot;--preserve-entire-environment&quot;, docker = FALSE) Here we got the QC report: https://hubentu.github.io/others/multiqc_report.html 5.5 MC3 somatic variant calling pipeline The Multi-Center Mutation Calling in Multiple Cancers project (MC3) pipeline was developed by TCGA to generate a comprehensive encyclopedia of somatic mutation calls. MC3 works by applying an ensemble of seven mutation-calling algorithms with scoring and artifact filtering. More details can be found in this paper: Scalable Open Science Approach for Mutation Calling of Tumor Exomes Using Multiple Genomic Pipelines The mc3 pipeline is available at https://github.com/OpenGenomics/mc3. All required software have been deployed in cloud with docker. The pipeline has been imported and contained in the RcwlPipelines pacakge, which contains two major steps (markID step was removed): Call variants by 7 pipelines Merge VCF and convert to MAF The steps of the pipeline was built on the CWL files from its github repository, which were also contained in the package. Thereforce, we need to load the pipleine by sourcing it from the script. bfcinfo(tools) %&gt;% filter(rname == &quot;mc3&quot;) %&gt;% pull(rpath) %&gt;% source short(mc3) ## inputs: ## - tumorID ## - normalID ## - tumor ## - normal ## - bed_file ## - centromere ## - cosmic ## - dbsnp ## - refFasta ## - vepData ## outputs: ## - outmaf ## - outvcf ## steps: ## - call_variants ## - convert plotCWL(mc3) Two steps are included. 1. call_variants: To call variants by 7 pipelines: callVar &lt;- readCWL(runs(mc3)$call_variants) plotCWL(callVar) covert: To merge VCFs and convert to MAF: conv &lt;- readCWL(runs(mc3)$convert) plotCWL(conv) The merged VCF and converted MAF files will be collected to the output folder: outputs(mc3) ## outputs: ## outmaf: ## type: File ## outputSource: convert/outmaf ## outvcf: ## type: File ## outputSource: convert/vepvcf 5.5.1 Prepare data Testing somatic mutation data can be download from: https://github.com/genome/somatic-snv-test-data. Input list inputList. The tumorID/normalID must be consistent with SM from BAM read group. inputList &lt;- list(tumorID=list(test=&quot;NA12892&quot;), normalID=list(test=&quot;NA12878&quot;), tumor=list(test=&quot;apps/DNASeq/data/tumor.bam&quot;), normal=list(test=&quot;apps/DNASeq/data/normal.bam&quot;)) Parameter list paramList. paramList &lt;- list(bed_file=&quot;apps/data/mc3/gaf_20111020+broad_wex_1.1_hg19.bed&quot;, centromere=&quot;apps/data/mc3/centromere_hg19.bed&quot;, cosmic=&quot;apps/data/mc3/hg19_cosmic_v54_120711.vcf.gz&quot;, dbsnp=&quot;apps/data/mc3/dbsnp_134_b37.leftAligned.vcf.gz&quot;, refFasta=&quot;apps/data/human_g1k_v37.fa.gz&quot;, vepData=&quot;apps/data/.vep/&quot;) 5.5.2 Run MC3 pipeline res &lt;- runCWLBatch(mc3, outdir = &quot;apps/DNASeq/output/mc3&quot;, inputList = inputList, paramList = paramList, BPPARAM = BatchtoolsParam(workers = 1, cluster = &quot;sge&quot;, template = &quot;apps/data/sge_centos7.tmpl&quot;, resources = list(threads = 2, queue = &quot;centos7.q&quot;))) The final VCF was filtered and merged from the outputs of different callers and annotated by VEP: dir(&quot;apps/DNASeq/output/mc3/test&quot;) ## [1] &quot;merged.vep.vcf&quot; &quot;vep.maf&quot; The merged VCF file was converted to MAF file: vcf &lt;- read.table(&quot;apps/DNASeq/output/mc3/test/merged.vep.vcf&quot;, sep=&quot;\\t&quot;) head(vcf) ## V1 V2 V3 V4 V5 V6 V7 ## 1 21 10400299 . A T 0.0 PASS ## 2 21 10400380 . C T . PASS ## 3 21 10402435 rs2948877 G A . PASS ## 4 21 10402715 . G A 0.0 PASS ## 5 21 10402795 rs148043841 G T . PASS ## 6 21 10402985 . G GA . PASS ## V8 ## 1 CENTERS=RADIA|VARSCANS|MUSE|SOMATICSNIPER;CSQ=T|intergenic_variant|MODIFIER|||||||||||||||rs370695467|1||||1|SNV|1||||||||||||||||||||||||||||||| ## 2 CENTERS=SOMATICSNIPER|RADIA|VARSCANS|MUSE;CSQ=T|intergenic_variant|MODIFIER||||||||||||||||1||||1|SNV|1||||||||||||||||||||||||||||||| ## 3 CENTERS=MUSE|RADIA|VARSCANS|SOMATICSNIPER;CSQ=A|intergenic_variant|MODIFIER|||||||||||||||rs2948877|1||||1|SNV|1||||||||||||||||A:0.3626|A:0.4266|A:0.3228|A:0.3075|A:0.2913|A:0.4346|||||||||| ## 4 CENTERS=RADIA|VARSCANS|MUSE;CSQ=A|intergenic_variant|MODIFIER|||||||||||||||rs2948878|1||||1|SNV|1||||||||||||||||||||||||||||||| ## 5 CENTERS=MUSE|RADIA|VARSCANS;CSQ=T|intergenic_variant|MODIFIER|||||||||||||||rs373568457|1||||1|SNV|1||||||||||||||||||||||||||||||| ## 6 CENTERS=VARSCANI*|PINDEL;CSQ=A|intergenic_variant|MODIFIER|||||||||||||||rs375209288|1||||1|insertion|1||||||||||||||||||||||||||||||| ## V9 V10 V11 ## 1 GT:DP:AD 0/0:140:140,0 0/1:92:71,20 ## 2 GT:DP:AD 0/0:160:160,0 0/1:117:99,18 ## 3 GT:DP:AD 0/0:167:167,0 0/1:124:97,27 ## 4 GT:DP:AD 0/0:145:145,0 0/1:117:97,20 ## 5 GT:DP:AD 0/0:163:161,2 0/1:127:108,19 ## 6 GT:DP:AD 0/0:88:88,0 0/1:82:75,7 5.6 GATK4 germline variant calling pipeline The GATK 4 best practice pipeline for germline variant calling was implemented with Workflow Description Language (WDL), which is similar to cwl and requires cromwell to run the pipeline. The details of the pipeline can be found here: https://software.broadinstitute.org/gatk/best-practices/workflow?id=11145 Germline short variant discovery (SNPs + Indels) The germline pipeline include 4 steps in WDL, paired fastq to ubam, GATK alignment, variant calling by HaplotypeCaller and joint genotyping. We wrapped the GATK pipeline into 3 steps using Rcwl for different numbers of computing nodes requirements. The wrapped pipeline can help to assign inputs to the input JSON templates and glob results from the cromwell outputs. GAlign GATK alignment. The fastqs, sample information and customized json files for WDL are required as inputs. Multiple steps will run in this step, including bwa alignment, mark duplicates and base quality recalibration. GATK ready BAM files will be collected into the output directory. hapCall HaplotypeCaller. The GATK ready BAM and customized json files are inputs in this step. The local paths of GATK bundle files are required to be modified in your json file. A ‚ÄúgVCF‚Äù files will be generated. jdCall Joint variant discovery This step will combine the ‚ÄúgVCF‚Äù files and then call germline variants in all samples. The paths of the local bundle files are also required to be changed in the json template file. The final VCF file of germline variants will be generated. 5.6.1 GATK Alignment We wrapped the steps from raw fastqs to analysis-ready BAM file into GAlign pipeline. Here is the short summary of the pipeline. short(GAlign) ## inputs: ## - fastq1 ## - fastq2 ## - readGroup ## - sampleName ## - library ## - platunit ## - platform ## - center ## - tmpl1 ## - wdl1 ## - tmpl2 ## - wdl2 ## - cromwell ## outputs: ## - bamlog ## - outdir ## steps: ## - fqJson ## - fq2ubam ## - ubam2bamJson ## - align ## - mvOut For the inputList, we need to assign the fastqs files and read groups for each sample. The inputs can be multiple items separated by comma if there are more than one read groups for each sample. The input templates and WDL scripts can be assigned in the paramList, and the reference and other GATK bundle files in the local json files should be changed accordingly to your local version of files. The path to the cromwell binary file is also required. Here is an example: tmpl1 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/seq-format-conversion/paired-fastq-to-unmapped-bam.inputs.json&quot;) tmpl2 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-data-processing/processing-for-variant-discovery-gatk4.hg38.wgs.inputs.local.json&quot;) wdl1 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/seq-format-conversion/paired-fastq-to-unmapped-bam.wdl&quot;) wdl2 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-data-processing/processing-for-variant-discovery-gatk4.wdl&quot;) inputList &lt;- list(fastq1=list(normal=&quot;apps/DNASeq/data/normal_1.fq&quot;, tumor=&quot;apps/DNASeq/data/tumor_1.fq&quot;), fastq2=list(normal=&quot;apps/DNASeq/data/normal_2.fq&quot;, tumor=&quot;apps/DNASeq/data/tumor_2.fq&quot;), readGroup=list(&quot;normal.1&quot;, &quot;tumor.1&quot;), sampleName=list(&quot;normal&quot;, &quot;tumor&quot;), library=list(&quot;normal&quot;, &quot;tumor&quot;), platunit=list(&quot;normal&quot;, &quot;tumor&quot;), platform=list(&quot;illumina&quot;, &quot;illumina&quot;), center=list(&quot;rpccc&quot;, &quot;rpccc&quot;)) paramList &lt;- list(tmpl1=tmpl1, wdl1=wdl1, tmpl2=tmpl2, wdl2=wdl2, cromwell=&quot;/software/cromwell-36.jar&quot;) r1 &lt;- runCWLBatch(GAlign, outdir=&quot;apps/DNASeq/output/BAM&quot;, inputList, paramList, BatchtoolsParam(workers = 2, cluster=&quot;sge&quot;, template = &quot;apps/data/sge_centos7.tmpl&quot;, resources = list(threads = 16, queue = &quot;centos7.q&quot;)), stderr=&quot;&quot;) The outputs were globbed from the cromwell execution folder: list.files(&quot;apps/DNASeq/output/BAM/normal&quot;, recursive = TRUE) ## [1] &quot;output/normal.hg38.bai&quot; ## [2] &quot;output/normal.hg38.bam&quot; ## [3] &quot;output/normal.hg38.bam.md5&quot; ## [4] &quot;output/normal.hg38.duplicate_metrics&quot; ## [5] &quot;output/normal.hg38.recal_data.csv&quot; ## [6] &quot;processing-for-variant-discovery-gatk4.wdl.log&quot; 5.6.2 HaplotypeCaller This step takes the BAM files as input and each BAM file will be assigned to different computing nodes. The json template file needs to be modified to include the correct GATK bundle paths first. wdl3 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-germline-snps-indels/haplotypecaller-gvcf-gatk4.wdl&quot;) tmpl3 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-germline-snps-indels/haplotypecaller-gvcf-gatk4.hg38.inputs.local.json&quot;) bams &lt;- list(normal = normalizePath(&quot;output/BAM/normal/output/normal.hg38.bam&quot;), tumor = normalizePath(&quot;output/BAM/tumor/output/tumor.hg38.bam&quot;)) inputList &lt;- list(bam = bams) paramList &lt;- list(intervals = normalizePath(&quot;output/interval.txt&quot;), cromwell = &quot;/software/cromwell-36.jar&quot;, wdl = wdl3, tmpl = tmpl3) r2 &lt;- runCWLBatch(hapCall, outdir=&quot;apps/DNASeq/output/GATK&quot;, inputList, paramList, BatchtoolsParam(workers = 2, cluster=&quot;sge&quot;, template = &quot;apps/data/sge_centos7.tmpl&quot;, resources = list(threads = 16, queue = &quot;centos7.q&quot;)), stderr=&quot;&quot;) Here are the outputs: list.files(&quot;apps/DNASeq/output/GATK/normal&quot;, recursive = TRUE) ## [1] &quot;haplotypecaller-gvcf-gatk4.wdl.log&quot; ## [2] &quot;output/normal.hg38.g.vcf.gz&quot; ## [3] &quot;output/normal.hg38.g.vcf.gz.tbi&quot; 5.6.3 Joint Discovery The joint genotyping step will combine the gvcf files and then call variants in all samples, so only one computing node is required. Multiple values or files of the samples will need to be seperated by comma for each input in the inputList. The paths of the local bundle files will also need to be added to the json template file. wdl4 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-germline-snps-indels/joint-discovery-gatk4-local.wdl&quot;) tmpl4 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-germline-snps-indels/joint-discovery-gatk4-local.hg38.wgs.inputs.json&quot;) inputList &lt;- list(sampleName = list(test=&quot;normal,tumor&quot;), gvcf = list(test=&quot;apps/DNASeq/output/GATK/normal/output/normal.hg38.g.vcf.gz,apps/DNASeq/output/GATK/tumor/output/tumor.hg38.g.vcf.gz&quot;)) paramList &lt;- list(callsetName = &quot;test&quot;, intervals = &quot;apps/DNASeq/output/interval.21.interval_list&quot;, unpadded_intervals = &quot;apps/DNASeq/output/interval.21.intervals&quot;, tmpl = tmpl4, cromwell = &quot;/software/cromwell-36.jar&quot;, wdl = wdl4) r3 &lt;- runCWLBatch(jdCall, outdir=&quot;apps/DNASeq/output/GATK&quot;, inputList, paramList, BatchtoolsParam(workers = 1, cluster=&quot;sge&quot;, template = &quot;apps/sge_centos7.tmpl&quot;, resources = list(threads = 16, queue = &quot;centos7.q&quot;)), stderr=&quot;&quot;) Here are the final outputs: list.files(&quot;apps/DNASeq/output/GATK/test&quot;, recursive = TRUE) ## [1] &quot;joint-discovery-gatk4-local.wdl.log&quot; ## [2] &quot;output/out.intervals&quot; ## [3] &quot;output/test.variant_calling_detail_metrics&quot; ## [4] &quot;output/test.variant_calling_summary_metrics&quot; ## [5] &quot;output/test.vcf.gz&quot; ## [6] &quot;output/test.vcf.gz.tbi&quot; "],
["variant-calling.html", "Chapter 6 Variant calling 6.1 DNA alignment 6.2 Germline variant calling 6.3 Somatic mutation calling", " Chapter 6 Variant calling First, we load the required packages. library(RcwlPipelines) library(BiocParallel) library(fs) library(dplyr) library(jsonlite) 6.1 DNA alignment We use the test data sets from the ICGC-TCGA DREAM Mutation Calling challenge for demonstration and performance test. The test sets contains two pairs of BAM files with SNVs and SVs in chr19 and chr20 separately. The ‚ÄòTruth‚Äô VCF files are also included. Here is the URL to download the test data. https://www.synapse.org/#!Synapse:syn2335184 list.files(&quot;apps/data/DREAM/&quot;) ## [1] &quot;chr19.normal.bam&quot; &quot;chr19.normal.bam.bai&quot; ## [3] &quot;chr19.truth.vcf.gz&quot; &quot;chr19.truth.vcf.gz.tbi&quot; ## [5] &quot;chr19.tumor.bam&quot; &quot;chr19.tumor.bam.bai&quot; ## [7] &quot;normal.chr20.bam&quot; &quot;truth.chr20.vcf.gz&quot; ## [9] &quot;tumor.chr20.bam&quot; dir_info(&quot;apps/data/DREAM&quot;) %&gt;% select(path, size) ## # A tibble: 9 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::bytes&gt; ## 1 apps/data/DREAM/chr19.normal.bam 3.31G ## 2 apps/data/DREAM/chr19.normal.bam.bai 171.64K ## 3 apps/data/DREAM/chr19.truth.vcf.gz 21.6K ## 4 apps/data/DREAM/chr19.truth.vcf.gz.tbi 11.27K ## 5 apps/data/DREAM/chr19.tumor.bam 3.38G ## 6 apps/data/DREAM/chr19.tumor.bam.bai 1.45M ## 7 apps/data/DREAM/normal.chr20.bam 2.93G ## 8 apps/data/DREAM/truth.chr20.vcf.gz 16.58K ## 9 apps/data/DREAM/tumor.chr20.bam 2.9G In order to show the variant calling workflow from the very beginning. We convert the BAM files back to fastqs using picard SamToFastq and treat the two BAM files as samples from two patients. inputs(SamToFastq) ## inputs: ## bam (File): I= ## fq1 (string): F= ## fq2 (string): F2= ## prepare inputs bams &lt;- list.files(&quot;apps/data/DREAM/&quot;, &quot;.bam$&quot;, full.names = TRUE) samples &lt;- c(&quot;normal19&quot;, &quot;tumor19&quot;, &quot;normal20&quot;, &quot;tumor20&quot;) Bams &lt;- tapply(bams, samples, as.list) fq1 &lt;- tapply(paste0(samples, &quot;_R1.fq&quot;), samples, as.list) fq2 &lt;- tapply(paste0(samples, &quot;_R2.fq&quot;), samples, as.list) inputList &lt;- list(bam = Bams, fq1 = fq1, fq2 = fq2) ## run in HPC using SGE res1 &lt;- runCWLBatch(SamToFastq, outdir = &quot;apps/variants/fastq/&quot;, inputList, BPPARAM = BatchtoolsParam(workers = length(samples), cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(jobname = &quot;sam2fq&quot;, queue = &quot;all.q&quot;, threads = 16), log=TRUE, logdir=&quot;.&quot;, progressbar = T), stderr = &quot;&quot;) Let‚Äôs check the outputs. dir_info(&quot;apps/variants/fastq/&quot;, recurse = TRUE, glob = &quot;*.fq&quot;) %&gt;% select(path, size) ## # A tibble: 8 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::bytes&gt; ## 1 apps/variants/fastq/normal19/normal19_R1.fq 2.17G ## 2 apps/variants/fastq/normal19/normal19_R2.fq 2.17G ## 3 apps/variants/fastq/normal20/normal20_R1.fq 2.14G ## 4 apps/variants/fastq/normal20/normal20_R2.fq 2.14G ## 5 apps/variants/fastq/tumor19/tumor19_R1.fq 2.18G ## 6 apps/variants/fastq/tumor19/tumor19_R2.fq 2.18G ## 7 apps/variants/fastq/tumor20/tumor20_R1.fq 2.14G ## 8 apps/variants/fastq/tumor20/tumor20_R2.fq 2.14G Now, we are ready to run the DNA alignment pipeline, bwaMRecal, including all necessary steps to prepare the analysis-ready BAM files. We can check the required inputs and steps. inputs(bwaMRecal) ## inputs: ## outBam (string): ## RG (string): ## threads (int): ## Ref (File): ## FQ1s (File): ## FQ2s (File): ## knowSites: ## type: array ## prefix: names(steps(bwaMRecal)) ## [1] &quot;bwaAlign&quot; &quot;markdup&quot; &quot;BaseRecal&quot; fqs &lt;- list.files(&quot;apps/variants/fastq&quot;, recursive = TRUE, full.names = TRUE) fq1 &lt;- fqs[grep(&quot;R1&quot;, fqs)] fq2 &lt;- fqs[grep(&quot;R2&quot;, fqs)] ids &lt;- sub(&quot;_.*&quot;, &quot;&quot;, basename(fq1)) fq1L &lt;- tapply(fq1, ids, as.list) fq2L &lt;- tapply(fq2, ids, as.list) RGs &lt;- paste(&quot;@RG&quot;, paste0(&quot;ID:&quot;, ids), paste0(&quot;LB:&quot;, ids), paste0(&quot;DT:&quot;, Sys.Date()), paste0(&quot;PL:&quot;, &quot;Illumina&quot;), &quot;CN:RCWL&quot;, paste0(&quot;SM:&quot;, ids), sep = &quot;\\\\t&quot;) RGL &lt;- tapply(RGs, ids, as.list) outBam &lt;- as.list(paste0(names(RGL), &quot;.bam&quot;)) inputList &lt;- list(RG = RGL, outBam = outBam, FQ1s = fq1L, FQ2s = fq2L) paramList &lt;- list(threads = 16, Ref =&quot;apps/data/hs37d5.fa&quot;, knowSites = list( &quot;apps/data/bundle/dbsnp_138.b37.vcf&quot;, &quot;apps/data/bundle/Mills_and_1000G_gold_standard.indels.b37.vcf&quot; )) res2 &lt;- runCWLBatch(bwaMRecal, outdir = &quot;apps/variants/BAM&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = length(samples), cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;align&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) Here are the outputs: dir_info(&quot;apps/variants/BAM/&quot;, recurse = TRUE) %&gt;% select(path, size) ## # A tibble: 26 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::bytes&gt; ## 1 apps/variants/BAM/normal19 4K ## 2 apps/variants/BAM/normal19/normal19.bai 2.6M ## 3 apps/variants/BAM/normal19/normal19.bam 2.3G ## 4 apps/variants/BAM/normal19/normal19.bam.bai 2.6M ## 5 apps/variants/BAM/normal19/normal19.bam.markdup.txt 2.75K ## 6 apps/variants/BAM/normal19/normal19.flagstat.txt 448 ## 7 apps/variants/BAM/normal19/normal19.stats.txt 95.16K ## 8 apps/variants/BAM/normal20 4K ## 9 apps/variants/BAM/normal20/normal20.bai 2.45M ## 10 apps/variants/BAM/normal20/normal20.bam 2.23G ## # ‚Ä¶ with 16 more rows 6.2 Germline variant calling The GATK germline variant calling pipeline is one of the most popular method to call germline short variants. The latest best practice was implemented with the Workflow Description Language (WDL). The WDL scripts was simply wrapped with Rcwl in the RcwlPipelines package. https://github.com/gatk-workflows/gatk4-germline-snps-indels There are two steps to run the latest GATK pipeline if the BAMs are prepared. First the haplotypecaller step is used to call variants by samples. The ‚ÄúWDL‚Äù script and ‚Äújson‚Äù input for this step are also contained in the package. wdl1 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-germline-snps-indels/haplotypecaller-gvcf-gatk4.wdl&quot;) tmpl1 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-germline-snps-indels/haplotypecaller-gvcf-gatk4.hg38.inputs.local.json&quot;) We need to modify the reference from ‚Äúhg38‚Äù to ‚Äúb37‚Äù. Please note that all the file paths should be absolute paths for the ‚ÄúWDL‚Äù inputs. json1 &lt;- fromJSON(tmpl1) json1$HaplotypeCallerGvcf_GATK4.ref_dict &lt;- normalizePath(&quot;apps/data/hs37d5.dict&quot;) json1$HaplotypeCallerGvcf_GATK4.ref_fasta &lt;- normalizePath(&quot;apps/data/hs37d5.fa&quot;) json1$HaplotypeCallerGvcf_GATK4.ref_fasta_index &lt;- normalizePath(&quot;apps/data/hs37d5.fa.fai&quot;) dir.create(&quot;apps/variants/vcf&quot;) writeLines(jsonlite::toJSON(json1, pretty = TRUE, auto_unbox = T), &quot;apps/variants/vcf/tmpl1.json&quot;) A interval list is required to define the exome capture region. We couldn‚Äôt find one for the TCGA data, so here we just simply use the whole chromosome regions. fai &lt;- read.table(&quot;apps/data/hs37d5.fa.fai&quot;) fai &lt;- fai[fai[,1] %in% c(19, 20),] bed &lt;- cbind(as.character(fai[,1]), 1, fai[,2]) write.table(bed, &quot;apps/variants/vcf/intval.bed&quot;, row.names = FALSE, col.names = FALSE, quote = FALSE) BedToIntervalList$bed &lt;- &quot;apps/variants/vcf/intval.bed&quot; BedToIntervalList$SD &lt;- &quot;apps/data/hs37d5.dict&quot; BedToIntervalList$out &lt;- &quot;region.interval_list&quot; r1 &lt;- runCWL(BedToIntervalList, outdir = &quot;apps/variants/vcf/&quot;) writeLines(normalizePath(&quot;apps/variants/vcf/region.interval_list&quot;), &quot;apps/variants/vcf/intval.txt&quot;) writeLines(paste0(bed[,1], &quot;:&quot;, bed[,2], &quot;-&quot;, bed[,3]), &quot;apps/variants/vcf/intval.unpad.txt&quot;) ## fix bai paths file.copy(&quot;apps/variants/BAM/normal19/normal19.bam.bai&quot;, &quot;apps/variants/BAM/normal19/normal19.bai&quot;) file.copy(&quot;apps/variants/BAM/normal20/normal20.bam.bai&quot;, &quot;apps/variants/BAM/normal20/normal20.bai&quot;) bams &lt;- normalizePath(list.files(&quot;apps/variants/BAM&quot;, &quot;normal.*.bam$&quot;, recursive = TRUE, full.names = TRUE)) bams &lt;- as.list(bams) names(bams) &lt;- c(&quot;normal19&quot;, &quot;normal20&quot;) inputList &lt;- list(bam = bams) paramList &lt;- list(intervals = normalizePath(&quot;apps/variants/vcf/intval.txt&quot;), cromwell = normalizePath(&quot;apps/cromwell-45.jar&quot;), wdl = wdl1, tmpl = normalizePath(&quot;apps/variants/vcf/tmpl1.json&quot;)) res3 &lt;- runCWLBatch(hapCall, outdir = &quot;apps/variants/vcf&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = length(bams), cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;hapCall&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;, cwlTemp=T) Here are the results. dir_info(&quot;apps/variants/vcf/&quot;, recurse = TRUE, glob = &quot;*.g.vcf.gz&quot;) %&gt;% select(path, size) ## # A tibble: 2 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::bytes&gt; ## 1 apps/variants/vcf/normal19/output/normal19.g.vcf.gz 192M ## 2 apps/variants/vcf/normal20/output/normal20.g.vcf.gz 192M Then we perform joint genotyping with jdCall. The reference genome bundles are also need to be changed to ‚Äúb37‚Äù. You can skip this step if you already have a ‚Äúb37‚Äù version of metadata file. wdl2 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-germline-snps-indels/joint-discovery-gatk4-local.wdl&quot;) tmpl2 &lt;- system.file(package=&quot;RcwlPipelines&quot;, &quot;GATK4/gatk4-germline-snps-indels/joint-discovery-gatk4-local.hg38.wgs.inputs.json&quot;) ## change to b37 json2 &lt;- fromJSON(tmpl2) json2$JointGenotyping.ref_dict &lt;- normalizePath(&quot;apps/data/hs37d5.dict&quot;) json2$JointGenotyping.ref_fasta &lt;- normalizePath(&quot;apps/data/hs37d5.fa&quot;) json2$JointGenotyping.ref_fasta_index &lt;- normalizePath(&quot;apps/data/hs37d5.fa.fai&quot;) json2$JointGenotyping.dbsnp_vcf &lt;- normalizePath(&quot;apps/data/bundle/dbsnp_138.b37.vcf&quot;) json2$JointGenotyping.dbsnp_vcf_index &lt;- normalizePath(&quot;apps/data/bundle/dbsnp_138.b37.vcf.idx&quot;) json2$JointGenotyping.one_thousand_genomes_resource_vcf &lt;- normalizePath(&quot;apps/data/bundle/1000G_phase1.snps.high_confidence.b37.vcf&quot;) json2$JointGenotyping.one_thousand_genomes_resource_vcf_index &lt;- normalizePath(&quot;apps/data/bundle/1000G_phase1.snps.high_confidence.b37.vcf.idx&quot;) json2$JointGenotyping.omni_resource_vcf &lt;- normalizePath(&quot;apps/data/bundle/1000G_omni2.5.b37.vcf&quot;) json2$JointGenotyping.omni_resource_vcf_index &lt;- normalizePath(&quot;apps/data/bundle/1000G_omni2.5.b37.vcf.idx&quot;) json2$JointGenotyping.mills_resource_vcf &lt;- normalizePath(&quot;apps/data/bundle/Mills_and_1000G_gold_standard.indels.b37.vcf&quot;) json2$JointGenotyping.mills_resource_vcf_index &lt;- normalizePath(&quot;apps/data/bundle/Mills_and_1000G_gold_standard.indels.b37.vcf.idx&quot;) json2$JointGenotyping.axiomPoly_resource_vcf &lt;- normalizePath(&quot;apps/data/bundle/Axiom_Exome_Plus.genotypes.all_populations.poly.vcf.gz&quot;) json2$JointGenotyping.axiomPoly_resource_vcf_index &lt;- normalizePath(&quot;apps/data/bundle/Axiom_Exome_Plus.genotypes.all_populations.poly.vcf.gz.tbi&quot;) json2$JointGenotyping.hapmap_resource_vcf &lt;- normalizePath(&quot;apps/data/bundle/hapmap_3.3.b37.vcf&quot;) json2$JointGenotyping.hapmap_resource_vcf_index &lt;- normalizePath(&quot;apps/data/bundle/hapmap_3.3.b37.vcf.idx&quot;) writeLines(toJSON(json2, pretty = TRUE, auto_unbox = T), &quot;apps/variants/vcf/tmpl2.json&quot;) The joint calling step takes the inputs from the previous step and run together. ## prepare inputs sampleName &lt;- paste(names(bams), collapse = &quot;,&quot;) gvcf &lt;- paste(normalizePath(list.files(&quot;apps/variants/vcf&quot;, &quot;.gz$&quot;, recursive = TRUE, full.names = TRUE)), collapse = &quot;,&quot;) inputList &lt;- list(sampleName = list(res = sampleName), gvcf = list(res = gvcf)) paramList &lt;- list(callsetName = &quot;germline&quot;, intervals = normalizePath(&quot;apps/variants/vcf/region.interval_list&quot;), unpadded_intervals = normalizePath(&quot;apps/variants/vcf/intval.unpad.txt&quot;), tmpl = normalizePath(&quot;apps/variants/vcf/tmpl2.json&quot;), wdl = wdl2, cromwell = normalizePath(&quot;apps/cromwell-45.jar&quot;)) res4 &lt;- runCWLBatch(jdCall, outdir = &quot;apps/variants/vcf&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 1, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;jdCall&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;, cwlTemp=T) Here are the final results: dir_info(&quot;apps/variants/vcf/res/output&quot;, recurse = TRUE) %&gt;% select(path, size) ## # A tibble: 5 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::byte&gt; ## 1 apps/variants/vcf/res/output/germline.variant_calling_detail_‚Ä¶ 1.9K ## 2 apps/variants/vcf/res/output/germline.variant_calling_summary‚Ä¶ 1.63K ## 3 apps/variants/vcf/res/output/germline.vcf.gz 9.4M ## 4 apps/variants/vcf/res/output/germline.vcf.gz.tbi 37.64K ## 5 apps/variants/vcf/res/output/out.intervals 27 6.3 Somatic mutation calling We have collected many somatic mutation callers, including MuTect2, strelka2, MuSe, VarDict, SomaticSniper, LoFreq, VarScan2, lancet and neusomatic. Recent research papers have reported that the combination of multiple callers could improve the sensitivity and specificity. 6.3.1 MuTect2 The MuTect2 was built based on the latest best practise from GATK 4. https://software.broadinstitute.org/gatk/best-practices/workflow?id=11146 The required resources files can be downloaded from its google storage. &lt;gs://gatk-best-practices&gt; Call variants on normal samples bams &lt;- list.files(&quot;apps/variants/BAM&quot;, &quot;.bam$&quot;, recursive = TRUE, full.names = TRUE) nbam &lt;- as.list(bams[1:2]) names(nbam) &lt;- c(&quot;normal19&quot;, &quot;normal20&quot;) ovcf &lt;- as.list(paste0(names(nbam), &quot;.vcf&quot;)) inputList &lt;- list(tbam = nbam, out = ovcf) paramList &lt;- list(Ref = &quot;apps/data/hs37d5.fa&quot;, interval = &quot;apps/variants/vcf/intval.bed&quot;) ## avoid a bug in GenomicsDBImport arguments(Mutect2) &lt;- list(&quot;-max-mnp-distance&quot;, &quot;0&quot;) res5 &lt;- runCWLBatch(Mutect2, outdir = &quot;apps/variants/mutect2&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;mutect2&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) dir_info(&quot;apps/variants/mutect2&quot;, regexp = &quot;normal&quot;, recurse = TRUE) %&gt;% select(path, size) ## # A tibble: 12 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::byte&gt; ## 1 apps/variants/mutect2/normal19 4K ## 2 apps/variants/mutect2/normal19/normal19.vcf 15.96M ## 3 apps/variants/mutect2/normal19/normal19.vcf.idx 117.92K ## 4 apps/variants/mutect2/normal19/normal19.vcf.stats 37 ## 5 apps/variants/mutect2/normal20 4K ## 6 apps/variants/mutect2/normal20/normal20.vcf 14.59M ## 7 apps/variants/mutect2/normal20/normal20.vcf.idx 248.43K ## 8 apps/variants/mutect2/normal20/normal20.vcf.stats 37 ## 9 apps/variants/mutect2/pt19/normal19.tumor19.ctfiltered.obfil‚Ä¶ 542.26K ## 10 apps/variants/mutect2/pt19/normal19.tumor19.ctfiltered.obfil‚Ä¶ 1.04M ## 11 apps/variants/mutect2/pt20/normal20.tumor20.ctfiltered.obfil‚Ä¶ 517.15K ## 12 apps/variants/mutect2/pt20/normal20.tumor20.ctfiltered.obfil‚Ä¶ 990.28K Note that, we need to add ‚Äú-max-mnp-distance 0‚Äù to the arguments according to the Mutect2 documents to avoid a bug in ‚ÄúGenomicsDBImport‚Äù step. Create a panel of normals (PoN) GPoN$nvcf &lt;- as.list(list.files(&quot;apps/variants/mutect2/&quot;, &quot;.vcf$&quot;, recursive = TRUE, full.names = TRUE)) GPoN$Ref &lt;- &quot;apps/data/hs37d5.fa&quot; GPoN$intervals &lt;- &quot;apps/variants/vcf/intval.bed&quot; GPoN$pvcf &lt;- &quot;pon.vcf&quot; ##GPoN$gresource &lt;- &quot;apps/data/Mutect2/af-only-gnomad.raw.sites.b37.vcf&quot; runCWL(GPoN, outdir = &quot;apps/variants/mutect2/&quot;, stderr = &quot;&quot;, Args = &quot;--relax-path-checks&quot;) Here we add ‚Äú‚Äìrelax-path-checks‚Äù arugment to the ‚Äúcwltool‚Äù because the temporary files have special characters in their file names. Mutect2 pipeline tbam &lt;- as.list(bams[3:4]) nbam &lt;- as.list(bams[1:2]) nid &lt;- as.list(sub(&quot;.bam&quot;, &quot;&quot;, basename(bams))[1:2]) tid &lt;- as.list(sub(&quot;.bam&quot;, &quot;&quot;, basename(bams))[3:4]) names(tbam) &lt;- names(nbam) &lt;- c(&quot;pt19&quot;, &quot;pt20&quot;) inputList &lt;- list(tbam = tbam, nbam = nbam, normal = nid, tumor = tid) paramList &lt;- list(Ref = &quot;apps/data/hs37d5.fa&quot;, gresource = &quot;apps/data/Mutect2/af-only-gnomad.raw.sites.b37.vcf&quot;, pon = &quot;apps/variants/mutect2/pon.vcf&quot;, interval = &quot;apps/variants/vcf/intval.bed&quot;, comvcf = &quot;apps/data/Mutect2/GetPileupSummaries/small_exac_common_3_b37.vcf&quot;) res6 &lt;- runCWLBatch(Mutect2PL, outdir = &quot;apps/variants/mutect2&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(threads = 16, queue = &quot;all.q&quot;, jobname = &quot;mutect2&quot;), log = TRUE, logdir = &quot;.&quot;, progressbar = TRUE), stderr = &quot;&quot;) 6.3.2 MuSE 6.3.3 Strelka2 6.3.4 SomaticSniper 6.3.5 VarDict 6.3.6 LoFreq 6.3.7 VarScan2 6.3.8 Lancet 6.3.9 Neusomatic "],
["rna-seq-alignment-and-quantification.html", "Chapter 7 RNA-Seq alignment and quantification 7.1 bulk mRNA 7.2 transcriptome quantification 7.3 single cell RNAseq 7.4 miRNA", " Chapter 7 RNA-Seq alignment and quantification library(RcwlPipelines) library(BiocParallel) library(fs) 7.1 bulk mRNA 7.2 transcriptome quantification 7.3 single cell RNAseq 7.4 miRNA The miRDeep2 is one of the popular tools for discovering known and novel miRNAs from small RNA sequencing data. We wrapped the mapping and quantification steps into miRDeep2PL. Here is the instructions for miRDeep2: https://github.com/rajewsky-lab/mirdeep2. plotCWL(miRDeep2PL) We use the data from mirdeep2 github repository as an example. https://github.com/rajewsky-lab/mirdeep2/tree/master/tutorial_dir list.files(&quot;apps/miRNA/tutorial_dir&quot;) ## [1] &quot;cel_cluster.fa&quot; &quot;mature_ref_other_species.fa&quot; ## [3] &quot;mature_ref_this_species.fa&quot; &quot;precursors_ref_this_species.fa&quot; ## [5] &quot;reads_collapsed.fa&quot; &quot;reads.fa&quot; ## [7] &quot;run_tut.sh&quot; &quot;sample_result.html&quot; 7.4.1 Prepare reference First, we need to build indexes for the miRNA reference with bowtie-build. This is only required to be performed once for each refernce genome. bowtie_build$ref &lt;- &quot;apps/miRNA/tutorial_dir/cel_cluster.fa&quot; bowtie_build$outPrefix &lt;- &quot;cel_cluster&quot; idxRes &lt;- runCWL(bowtie_build, outdir = &quot;apps/miRNA/output/genome&quot;, stderr = &quot;&quot;) file.copy(&quot;apps/miRNA/tutorial_dir/cel_cluster.fa&quot;, &quot;apps/miRNA/output/genome/cel_cluster.fa&quot;) Here are the indexed reference files. dir_info(&quot;apps/miRNA/output/genome&quot;) %&gt;% select(path, size) ## # A tibble: 7 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::bytes&gt; ## 1 apps/miRNA/output/genome/cel_cluster.1.ebwt 4M ## 2 apps/miRNA/output/genome/cel_cluster.2.ebwt 812 ## 3 apps/miRNA/output/genome/cel_cluster.3.ebwt 26 ## 4 apps/miRNA/output/genome/cel_cluster.4.ebwt 1.57K ## 5 apps/miRNA/output/genome/cel_cluster.fa 6.47K ## 6 apps/miRNA/output/genome/cel_cluster.rev.1.ebwt 4M ## 7 apps/miRNA/output/genome/cel_cluster.rev.2.ebwt 812 7.4.2 Run miRDeep2 pipeline First we need to prepare the inputs into ‚ÄòinputList‚Äô and ‚ÄòparamList‚Äô for parallel execution. inputs(miRDeep2PL) ## inputs: ## reads (File): ## format (string): -c ## adapter (string): ## len (int): 18 ## genome (File): ## miRef ( File|string ): ## miOther ( File|string ): ## precursors ( File|string ): ## species (string): To mimic multiple samples analysis, here we just repeat to use the input reads. reads &lt;- list(sample1 = &quot;apps/miRNA/tutorial_dir/reads.fa&quot;, sample2 = &quot;apps/miRNA/tutorial_dir/reads.fa&quot;) inputList &lt;- list(reads = reads) paramList &lt;- list(adapter = &quot;TCGTATGCCGTCTTCTGCTTGT&quot;, genome = &quot;apps/miRNA/output/genome/cel_cluster.fa&quot;, miRef = &quot;apps/miRNA/tutorial_dir/mature_ref_this_species.fa&quot;, miOther = &quot;apps/miRNA/tutorial_dir/mature_ref_other_species.fa&quot;, precursors = &quot;apps/miRNA/tutorial_dir/precursors_ref_this_species.fa&quot;, species = &quot;C.elegans&quot;) Let‚Äôs run the pipeline with two computing nodes. mirRes &lt;- runCWLBatch(miRDeep2PL, outdir = &quot;apps/miRNA/output/&quot;, inputList, paramList, BPPARAM = BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = &quot;apps/data/sge.tmpl&quot;, resources = list(jobname = &quot;miRNA&quot;, queue = &quot;all.q&quot;, threads = 2), log=TRUE, logdir=&quot;.&quot;, progressbar = T), stderr = &quot;&quot;) Here are the results: dir_info(&quot;apps/miRNA/output/sample1&quot;) %&gt;% select(path, size) ## # A tibble: 10 x 2 ## path size ## &lt;fs::path&gt; &lt;fs::byte&gt; ## 1 apps/miRNA/output/sample1/expression_26_09_2019_t_20_10_36.h‚Ä¶ 21.15K ## 2 apps/miRNA/output/sample1/expression_analyses 4K ## 3 apps/miRNA/output/sample1/miRNAs_expressed_all_samples_26_09‚Ä¶ 441 ## 4 apps/miRNA/output/sample1/mirna_results_26_09_2019_t_20_10_36 4K ## 5 apps/miRNA/output/sample1/pdfs_26_09_2019_t_20_10_36 4K ## 6 apps/miRNA/output/sample1/reads_collapsed.arf 61.36K ## 7 apps/miRNA/output/sample1/reads_collapsed.fa 59.31K ## 8 apps/miRNA/output/sample1/result_26_09_2019_t_20_10_36.bed 747 ## 9 apps/miRNA/output/sample1/result_26_09_2019_t_20_10_36.csv 4.39K ## 10 apps/miRNA/output/sample1/result_26_09_2019_t_20_10_36.html 42.73K "],
["references.html", "References", " References "]
]
